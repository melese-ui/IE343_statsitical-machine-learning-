{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtffUIULg32p"
      },
      "source": [
        "# Homework 5 (Full mark: 100pt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2c6-9lvyg32y"
      },
      "source": [
        "You can use ``Google Colab`` if you would like to use GPU.\n",
        "- https://colab.research.google.com/notebooks/welcome.ipynb\n",
        "- https://theorydb.github.io/dev/2019/08/23/dev-ml-colab/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8IaMHuzg32y"
      },
      "source": [
        "# 1. Regression (50pt)\n",
        "\n",
        "**For this question, using PyTorch, implement the 1) ridge regression and 2) Lasso. You can refer to the tutorial link below for how to implement linear regression. Note that the ridge regression is the linear regression with L2 penalty, and the Lasso is the linear regression with L1 penalty. You should use ````Boston```` dataset as shown in the code below. You should not only write the code for the models, but also train them and show the test MSE.**\n",
        "- https://github.com/yunjey/pytorch-tutorial/blob/master/tutorials/01-basics/linear_regression/main.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krwPRHlsg32z"
      },
      "source": [
        "<div>\n",
        "<img src=\"figures/regressions.png\" width=\"700\"/>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6ttF7iEh8LN",
        "outputId": "960d15d2-aa93-48d2-c5b4-dea5f992cadf"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "OxBhvENDg32z"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "# To fix the random seed\n",
        "torch.manual_seed(0)\n",
        "torch.cuda.manual_seed_all(0)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "# load data\n",
        "boston = pd.read_csv( 'drive/MyDrive//data/Boston.csv').drop('Unnamed: 0', axis=1)\n",
        "data = torch.FloatTensor(boston.values)\n",
        "X = data[:,:-1] # Input (X)\n",
        "y = data[:,-1].reshape(-1, 1) # Ground Truth (y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qk-ANwzzg320",
        "outputId": "ccdcee86-0d9f-4906-d796-cb9301713159"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000, Ridge Training Loss: 627.1058, Ridge Test MSE: 525.3033\n",
            "Epoch 2/1000, Ridge Training Loss: 618.6272, Ridge Test MSE: 518.0363\n",
            "Epoch 3/1000, Ridge Training Loss: 610.3033, Ridge Test MSE: 510.9347\n",
            "Epoch 4/1000, Ridge Training Loss: 602.1368, Ridge Test MSE: 504.0005\n",
            "Epoch 5/1000, Ridge Training Loss: 594.1301, Ridge Test MSE: 497.2353\n",
            "Epoch 6/1000, Ridge Training Loss: 586.2856, Ridge Test MSE: 490.6405\n",
            "Epoch 7/1000, Ridge Training Loss: 578.6050, Ridge Test MSE: 484.2177\n",
            "Epoch 8/1000, Ridge Training Loss: 571.0904, Ridge Test MSE: 477.9677\n",
            "Epoch 9/1000, Ridge Training Loss: 563.7432, Ridge Test MSE: 471.8914\n",
            "Epoch 10/1000, Ridge Training Loss: 556.5649, Ridge Test MSE: 465.9891\n",
            "Epoch 11/1000, Ridge Training Loss: 549.5566, Ridge Test MSE: 460.2611\n",
            "Epoch 12/1000, Ridge Training Loss: 542.7192, Ridge Test MSE: 454.7074\n",
            "Epoch 13/1000, Ridge Training Loss: 536.0532, Ridge Test MSE: 449.3275\n",
            "Epoch 14/1000, Ridge Training Loss: 529.5591, Ridge Test MSE: 444.1208\n",
            "Epoch 15/1000, Ridge Training Loss: 523.2367, Ridge Test MSE: 439.0863\n",
            "Epoch 16/1000, Ridge Training Loss: 517.0862, Ridge Test MSE: 434.2228\n",
            "Epoch 17/1000, Ridge Training Loss: 511.1069, Ridge Test MSE: 429.5287\n",
            "Epoch 18/1000, Ridge Training Loss: 505.2980, Ridge Test MSE: 425.0020\n",
            "Epoch 19/1000, Ridge Training Loss: 499.6585, Ridge Test MSE: 420.6407\n",
            "Epoch 20/1000, Ridge Training Loss: 494.1872, Ridge Test MSE: 416.4423\n",
            "Epoch 21/1000, Ridge Training Loss: 488.8822, Ridge Test MSE: 412.4040\n",
            "Epoch 22/1000, Ridge Training Loss: 483.7420, Ridge Test MSE: 408.5227\n",
            "Epoch 23/1000, Ridge Training Loss: 478.7643, Ridge Test MSE: 404.7953\n",
            "Epoch 24/1000, Ridge Training Loss: 473.9466, Ridge Test MSE: 401.2180\n",
            "Epoch 25/1000, Ridge Training Loss: 469.2863, Ridge Test MSE: 397.7873\n",
            "Epoch 26/1000, Ridge Training Loss: 464.7805, Ridge Test MSE: 394.4991\n",
            "Epoch 27/1000, Ridge Training Loss: 460.4262, Ridge Test MSE: 391.3492\n",
            "Epoch 28/1000, Ridge Training Loss: 456.2200, Ridge Test MSE: 388.3333\n",
            "Epoch 29/1000, Ridge Training Loss: 452.1585, Ridge Test MSE: 385.4468\n",
            "Epoch 30/1000, Ridge Training Loss: 448.2379, Ridge Test MSE: 382.6854\n",
            "Epoch 31/1000, Ridge Training Loss: 444.4547, Ridge Test MSE: 380.0443\n",
            "Epoch 32/1000, Ridge Training Loss: 440.8047, Ridge Test MSE: 377.5187\n",
            "Epoch 33/1000, Ridge Training Loss: 437.2842, Ridge Test MSE: 375.1038\n",
            "Epoch 34/1000, Ridge Training Loss: 433.8888, Ridge Test MSE: 372.7948\n",
            "Epoch 35/1000, Ridge Training Loss: 430.6146, Ridge Test MSE: 370.5867\n",
            "Epoch 36/1000, Ridge Training Loss: 427.4573, Ridge Test MSE: 368.4749\n",
            "Epoch 37/1000, Ridge Training Loss: 424.4126, Ridge Test MSE: 366.4542\n",
            "Epoch 38/1000, Ridge Training Loss: 421.4761, Ridge Test MSE: 364.5198\n",
            "Epoch 39/1000, Ridge Training Loss: 418.6437, Ridge Test MSE: 362.6671\n",
            "Epoch 40/1000, Ridge Training Loss: 415.9110, Ridge Test MSE: 360.8911\n",
            "Epoch 41/1000, Ridge Training Loss: 413.2737, Ridge Test MSE: 359.1872\n",
            "Epoch 42/1000, Ridge Training Loss: 410.7276, Ridge Test MSE: 357.5506\n",
            "Epoch 43/1000, Ridge Training Loss: 408.2685, Ridge Test MSE: 355.9769\n",
            "Epoch 44/1000, Ridge Training Loss: 405.8920, Ridge Test MSE: 354.4614\n",
            "Epoch 45/1000, Ridge Training Loss: 403.5940, Ridge Test MSE: 352.9999\n",
            "Epoch 46/1000, Ridge Training Loss: 401.3706, Ridge Test MSE: 351.5880\n",
            "Epoch 47/1000, Ridge Training Loss: 399.2175, Ridge Test MSE: 350.2216\n",
            "Epoch 48/1000, Ridge Training Loss: 397.1310, Ridge Test MSE: 348.8966\n",
            "Epoch 49/1000, Ridge Training Loss: 395.1071, Ridge Test MSE: 347.6091\n",
            "Epoch 50/1000, Ridge Training Loss: 393.1422, Ridge Test MSE: 346.3556\n",
            "Epoch 51/1000, Ridge Training Loss: 391.2326, Ridge Test MSE: 345.1322\n",
            "Epoch 52/1000, Ridge Training Loss: 389.3747, Ridge Test MSE: 343.9357\n",
            "Epoch 53/1000, Ridge Training Loss: 387.5653, Ridge Test MSE: 342.7627\n",
            "Epoch 54/1000, Ridge Training Loss: 385.8009, Ridge Test MSE: 341.6102\n",
            "Epoch 55/1000, Ridge Training Loss: 384.0785, Ridge Test MSE: 340.4752\n",
            "Epoch 56/1000, Ridge Training Loss: 382.3950, Ridge Test MSE: 339.3550\n",
            "Epoch 57/1000, Ridge Training Loss: 380.7476, Ridge Test MSE: 338.2470\n",
            "Epoch 58/1000, Ridge Training Loss: 379.1335, Ridge Test MSE: 337.1489\n",
            "Epoch 59/1000, Ridge Training Loss: 377.5502, Ridge Test MSE: 336.0583\n",
            "Epoch 60/1000, Ridge Training Loss: 375.9951, Ridge Test MSE: 334.9734\n",
            "Epoch 61/1000, Ridge Training Loss: 374.4659, Ridge Test MSE: 333.8922\n",
            "Epoch 62/1000, Ridge Training Loss: 372.9606, Ridge Test MSE: 332.8129\n",
            "Epoch 63/1000, Ridge Training Loss: 371.4769, Ridge Test MSE: 331.7339\n",
            "Epoch 64/1000, Ridge Training Loss: 370.0131, Ridge Test MSE: 330.6540\n",
            "Epoch 65/1000, Ridge Training Loss: 368.5673, Ridge Test MSE: 329.5719\n",
            "Epoch 66/1000, Ridge Training Loss: 367.1378, Ridge Test MSE: 328.4864\n",
            "Epoch 67/1000, Ridge Training Loss: 365.7233, Ridge Test MSE: 327.3966\n",
            "Epoch 68/1000, Ridge Training Loss: 364.3220, Ridge Test MSE: 326.3016\n",
            "Epoch 69/1000, Ridge Training Loss: 362.9331, Ridge Test MSE: 325.2008\n",
            "Epoch 70/1000, Ridge Training Loss: 361.5549, Ridge Test MSE: 324.0936\n",
            "Epoch 71/1000, Ridge Training Loss: 360.1866, Ridge Test MSE: 322.9794\n",
            "Epoch 72/1000, Ridge Training Loss: 358.8272, Ridge Test MSE: 321.8578\n",
            "Epoch 73/1000, Ridge Training Loss: 357.4758, Ridge Test MSE: 320.7287\n",
            "Epoch 74/1000, Ridge Training Loss: 356.1315, Ridge Test MSE: 319.5918\n",
            "Epoch 75/1000, Ridge Training Loss: 354.7937, Ridge Test MSE: 318.4469\n",
            "Epoch 76/1000, Ridge Training Loss: 353.4616, Ridge Test MSE: 317.2941\n",
            "Epoch 77/1000, Ridge Training Loss: 352.1347, Ridge Test MSE: 316.1334\n",
            "Epoch 78/1000, Ridge Training Loss: 350.8126, Ridge Test MSE: 314.9647\n",
            "Epoch 79/1000, Ridge Training Loss: 349.4948, Ridge Test MSE: 313.7884\n",
            "Epoch 80/1000, Ridge Training Loss: 348.1809, Ridge Test MSE: 312.6045\n",
            "Epoch 81/1000, Ridge Training Loss: 346.8703, Ridge Test MSE: 311.4133\n",
            "Epoch 82/1000, Ridge Training Loss: 345.5631, Ridge Test MSE: 310.2150\n",
            "Epoch 83/1000, Ridge Training Loss: 344.2589, Ridge Test MSE: 309.0100\n",
            "Epoch 84/1000, Ridge Training Loss: 342.9576, Ridge Test MSE: 307.7985\n",
            "Epoch 85/1000, Ridge Training Loss: 341.6587, Ridge Test MSE: 306.5809\n",
            "Epoch 86/1000, Ridge Training Loss: 340.3624, Ridge Test MSE: 305.3577\n",
            "Epoch 87/1000, Ridge Training Loss: 339.0684, Ridge Test MSE: 304.1289\n",
            "Epoch 88/1000, Ridge Training Loss: 337.7767, Ridge Test MSE: 302.8953\n",
            "Epoch 89/1000, Ridge Training Loss: 336.4872, Ridge Test MSE: 301.6570\n",
            "Epoch 90/1000, Ridge Training Loss: 335.2000, Ridge Test MSE: 300.4145\n",
            "Epoch 91/1000, Ridge Training Loss: 333.9148, Ridge Test MSE: 299.1682\n",
            "Epoch 92/1000, Ridge Training Loss: 332.6317, Ridge Test MSE: 297.9185\n",
            "Epoch 93/1000, Ridge Training Loss: 331.3507, Ridge Test MSE: 296.6657\n",
            "Epoch 94/1000, Ridge Training Loss: 330.0719, Ridge Test MSE: 295.4104\n",
            "Epoch 95/1000, Ridge Training Loss: 328.7952, Ridge Test MSE: 294.1527\n",
            "Epoch 96/1000, Ridge Training Loss: 327.5207, Ridge Test MSE: 292.8932\n",
            "Epoch 97/1000, Ridge Training Loss: 326.2484, Ridge Test MSE: 291.6321\n",
            "Epoch 98/1000, Ridge Training Loss: 324.9783, Ridge Test MSE: 290.3698\n",
            "Epoch 99/1000, Ridge Training Loss: 323.7105, Ridge Test MSE: 289.1068\n",
            "Epoch 100/1000, Ridge Training Loss: 322.4450, Ridge Test MSE: 287.8432\n",
            "Epoch 101/1000, Ridge Training Loss: 321.1819, Ridge Test MSE: 286.5793\n",
            "Epoch 102/1000, Ridge Training Loss: 319.9212, Ridge Test MSE: 285.3157\n",
            "Epoch 103/1000, Ridge Training Loss: 318.6629, Ridge Test MSE: 284.0525\n",
            "Epoch 104/1000, Ridge Training Loss: 317.4073, Ridge Test MSE: 282.7898\n",
            "Epoch 105/1000, Ridge Training Loss: 316.1540, Ridge Test MSE: 281.5282\n",
            "Epoch 106/1000, Ridge Training Loss: 314.9035, Ridge Test MSE: 280.2678\n",
            "Epoch 107/1000, Ridge Training Loss: 313.6556, Ridge Test MSE: 279.0088\n",
            "Epoch 108/1000, Ridge Training Loss: 312.4105, Ridge Test MSE: 277.7515\n",
            "Epoch 109/1000, Ridge Training Loss: 311.1681, Ridge Test MSE: 276.4961\n",
            "Epoch 110/1000, Ridge Training Loss: 309.9285, Ridge Test MSE: 275.2427\n",
            "Epoch 111/1000, Ridge Training Loss: 308.6917, Ridge Test MSE: 273.9916\n",
            "Epoch 112/1000, Ridge Training Loss: 307.4579, Ridge Test MSE: 272.7430\n",
            "Epoch 113/1000, Ridge Training Loss: 306.2270, Ridge Test MSE: 271.4971\n",
            "Epoch 114/1000, Ridge Training Loss: 304.9991, Ridge Test MSE: 270.2539\n",
            "Epoch 115/1000, Ridge Training Loss: 303.7741, Ridge Test MSE: 269.0136\n",
            "Epoch 116/1000, Ridge Training Loss: 302.5523, Ridge Test MSE: 267.7764\n",
            "Epoch 117/1000, Ridge Training Loss: 301.3336, Ridge Test MSE: 266.5424\n",
            "Epoch 118/1000, Ridge Training Loss: 300.1179, Ridge Test MSE: 265.3117\n",
            "Epoch 119/1000, Ridge Training Loss: 298.9055, Ridge Test MSE: 264.0844\n",
            "Epoch 120/1000, Ridge Training Loss: 297.6964, Ridge Test MSE: 262.8607\n",
            "Epoch 121/1000, Ridge Training Loss: 296.4904, Ridge Test MSE: 261.6405\n",
            "Epoch 122/1000, Ridge Training Loss: 295.2876, Ridge Test MSE: 260.4241\n",
            "Epoch 123/1000, Ridge Training Loss: 294.0882, Ridge Test MSE: 259.2114\n",
            "Epoch 124/1000, Ridge Training Loss: 292.8921, Ridge Test MSE: 258.0027\n",
            "Epoch 125/1000, Ridge Training Loss: 291.6994, Ridge Test MSE: 256.7978\n",
            "Epoch 126/1000, Ridge Training Loss: 290.5101, Ridge Test MSE: 255.5968\n",
            "Epoch 127/1000, Ridge Training Loss: 289.3241, Ridge Test MSE: 254.4000\n",
            "Epoch 128/1000, Ridge Training Loss: 288.1417, Ridge Test MSE: 253.2071\n",
            "Epoch 129/1000, Ridge Training Loss: 286.9626, Ridge Test MSE: 252.0184\n",
            "Epoch 130/1000, Ridge Training Loss: 285.7871, Ridge Test MSE: 250.8339\n",
            "Epoch 131/1000, Ridge Training Loss: 284.6151, Ridge Test MSE: 249.6536\n",
            "Epoch 132/1000, Ridge Training Loss: 283.4466, Ridge Test MSE: 248.4774\n",
            "Epoch 133/1000, Ridge Training Loss: 282.2817, Ridge Test MSE: 247.3056\n",
            "Epoch 134/1000, Ridge Training Loss: 281.1204, Ridge Test MSE: 246.1379\n",
            "Epoch 135/1000, Ridge Training Loss: 279.9626, Ridge Test MSE: 244.9747\n",
            "Epoch 136/1000, Ridge Training Loss: 278.8086, Ridge Test MSE: 243.8158\n",
            "Epoch 137/1000, Ridge Training Loss: 277.6581, Ridge Test MSE: 242.6611\n",
            "Epoch 138/1000, Ridge Training Loss: 276.5113, Ridge Test MSE: 241.5108\n",
            "Epoch 139/1000, Ridge Training Loss: 275.3682, Ridge Test MSE: 240.3649\n",
            "Epoch 140/1000, Ridge Training Loss: 274.2287, Ridge Test MSE: 239.2235\n",
            "Epoch 141/1000, Ridge Training Loss: 273.0931, Ridge Test MSE: 238.0863\n",
            "Epoch 142/1000, Ridge Training Loss: 271.9611, Ridge Test MSE: 236.9536\n",
            "Epoch 143/1000, Ridge Training Loss: 270.8329, Ridge Test MSE: 235.8253\n",
            "Epoch 144/1000, Ridge Training Loss: 269.7085, Ridge Test MSE: 234.7013\n",
            "Epoch 145/1000, Ridge Training Loss: 268.5879, Ridge Test MSE: 233.5817\n",
            "Epoch 146/1000, Ridge Training Loss: 267.4710, Ridge Test MSE: 232.4666\n",
            "Epoch 147/1000, Ridge Training Loss: 266.3581, Ridge Test MSE: 231.3558\n",
            "Epoch 148/1000, Ridge Training Loss: 265.2489, Ridge Test MSE: 230.2495\n",
            "Epoch 149/1000, Ridge Training Loss: 264.1436, Ridge Test MSE: 229.1476\n",
            "Epoch 150/1000, Ridge Training Loss: 263.0421, Ridge Test MSE: 228.0500\n",
            "Epoch 151/1000, Ridge Training Loss: 261.9445, Ridge Test MSE: 226.9569\n",
            "Epoch 152/1000, Ridge Training Loss: 260.8508, Ridge Test MSE: 225.8681\n",
            "Epoch 153/1000, Ridge Training Loss: 259.7610, Ridge Test MSE: 224.7839\n",
            "Epoch 154/1000, Ridge Training Loss: 258.6751, Ridge Test MSE: 223.7039\n",
            "Epoch 155/1000, Ridge Training Loss: 257.5932, Ridge Test MSE: 222.6284\n",
            "Epoch 156/1000, Ridge Training Loss: 256.5152, Ridge Test MSE: 221.5572\n",
            "Epoch 157/1000, Ridge Training Loss: 255.4411, Ridge Test MSE: 220.4904\n",
            "Epoch 158/1000, Ridge Training Loss: 254.3710, Ridge Test MSE: 219.4280\n",
            "Epoch 159/1000, Ridge Training Loss: 253.3049, Ridge Test MSE: 218.3700\n",
            "Epoch 160/1000, Ridge Training Loss: 252.2427, Ridge Test MSE: 217.3163\n",
            "Epoch 161/1000, Ridge Training Loss: 251.1845, Ridge Test MSE: 216.2671\n",
            "Epoch 162/1000, Ridge Training Loss: 250.1303, Ridge Test MSE: 215.2222\n",
            "Epoch 163/1000, Ridge Training Loss: 249.0802, Ridge Test MSE: 214.1816\n",
            "Epoch 164/1000, Ridge Training Loss: 248.0340, Ridge Test MSE: 213.1455\n",
            "Epoch 165/1000, Ridge Training Loss: 246.9919, Ridge Test MSE: 212.1136\n",
            "Epoch 166/1000, Ridge Training Loss: 245.9538, Ridge Test MSE: 211.0862\n",
            "Epoch 167/1000, Ridge Training Loss: 244.9197, Ridge Test MSE: 210.0631\n",
            "Epoch 168/1000, Ridge Training Loss: 243.8897, Ridge Test MSE: 209.0443\n",
            "Epoch 169/1000, Ridge Training Loss: 242.8637, Ridge Test MSE: 208.0299\n",
            "Epoch 170/1000, Ridge Training Loss: 241.8418, Ridge Test MSE: 207.0198\n",
            "Epoch 171/1000, Ridge Training Loss: 240.8239, Ridge Test MSE: 206.0141\n",
            "Epoch 172/1000, Ridge Training Loss: 239.8101, Ridge Test MSE: 205.0127\n",
            "Epoch 173/1000, Ridge Training Loss: 238.8004, Ridge Test MSE: 204.0157\n",
            "Epoch 174/1000, Ridge Training Loss: 237.7947, Ridge Test MSE: 203.0230\n",
            "Epoch 175/1000, Ridge Training Loss: 236.7932, Ridge Test MSE: 202.0346\n",
            "Epoch 176/1000, Ridge Training Loss: 235.7957, Ridge Test MSE: 201.0506\n",
            "Epoch 177/1000, Ridge Training Loss: 234.8023, Ridge Test MSE: 200.0708\n",
            "Epoch 178/1000, Ridge Training Loss: 233.8129, Ridge Test MSE: 199.0955\n",
            "Epoch 179/1000, Ridge Training Loss: 232.8277, Ridge Test MSE: 198.1244\n",
            "Epoch 180/1000, Ridge Training Loss: 231.8466, Ridge Test MSE: 197.1577\n",
            "Epoch 181/1000, Ridge Training Loss: 230.8695, Ridge Test MSE: 196.1952\n",
            "Epoch 182/1000, Ridge Training Loss: 229.8966, Ridge Test MSE: 195.2372\n",
            "Epoch 183/1000, Ridge Training Loss: 228.9277, Ridge Test MSE: 194.2833\n",
            "Epoch 184/1000, Ridge Training Loss: 227.9629, Ridge Test MSE: 193.3339\n",
            "Epoch 185/1000, Ridge Training Loss: 227.0023, Ridge Test MSE: 192.3887\n",
            "Epoch 186/1000, Ridge Training Loss: 226.0457, Ridge Test MSE: 191.4479\n",
            "Epoch 187/1000, Ridge Training Loss: 225.0933, Ridge Test MSE: 190.5114\n",
            "Epoch 188/1000, Ridge Training Loss: 224.1449, Ridge Test MSE: 189.5791\n",
            "Epoch 189/1000, Ridge Training Loss: 223.2007, Ridge Test MSE: 188.6512\n",
            "Epoch 190/1000, Ridge Training Loss: 222.2605, Ridge Test MSE: 187.7276\n",
            "Epoch 191/1000, Ridge Training Loss: 221.3245, Ridge Test MSE: 186.8083\n",
            "Epoch 192/1000, Ridge Training Loss: 220.3925, Ridge Test MSE: 185.8933\n",
            "Epoch 193/1000, Ridge Training Loss: 219.4647, Ridge Test MSE: 184.9827\n",
            "Epoch 194/1000, Ridge Training Loss: 218.5410, Ridge Test MSE: 184.0762\n",
            "Epoch 195/1000, Ridge Training Loss: 217.6213, Ridge Test MSE: 183.1741\n",
            "Epoch 196/1000, Ridge Training Loss: 216.7057, Ridge Test MSE: 182.2763\n",
            "Epoch 197/1000, Ridge Training Loss: 215.7943, Ridge Test MSE: 181.3828\n",
            "Epoch 198/1000, Ridge Training Loss: 214.8869, Ridge Test MSE: 180.4935\n",
            "Epoch 199/1000, Ridge Training Loss: 213.9836, Ridge Test MSE: 179.6085\n",
            "Epoch 200/1000, Ridge Training Loss: 213.0844, Ridge Test MSE: 178.7279\n",
            "Epoch 201/1000, Ridge Training Loss: 212.1893, Ridge Test MSE: 177.8515\n",
            "Epoch 202/1000, Ridge Training Loss: 211.2982, Ridge Test MSE: 176.9793\n",
            "Epoch 203/1000, Ridge Training Loss: 210.4112, Ridge Test MSE: 176.1115\n",
            "Epoch 204/1000, Ridge Training Loss: 209.5283, Ridge Test MSE: 175.2479\n",
            "Epoch 205/1000, Ridge Training Loss: 208.6494, Ridge Test MSE: 174.3885\n",
            "Epoch 206/1000, Ridge Training Loss: 207.7746, Ridge Test MSE: 173.5334\n",
            "Epoch 207/1000, Ridge Training Loss: 206.9039, Ridge Test MSE: 172.6826\n",
            "Epoch 208/1000, Ridge Training Loss: 206.0372, Ridge Test MSE: 171.8360\n",
            "Epoch 209/1000, Ridge Training Loss: 205.1746, Ridge Test MSE: 170.9936\n",
            "Epoch 210/1000, Ridge Training Loss: 204.3160, Ridge Test MSE: 170.1555\n",
            "Epoch 211/1000, Ridge Training Loss: 203.4614, Ridge Test MSE: 169.3216\n",
            "Epoch 212/1000, Ridge Training Loss: 202.6109, Ridge Test MSE: 168.4920\n",
            "Epoch 213/1000, Ridge Training Loss: 201.7643, Ridge Test MSE: 167.6665\n",
            "Epoch 214/1000, Ridge Training Loss: 200.9219, Ridge Test MSE: 166.8453\n",
            "Epoch 215/1000, Ridge Training Loss: 200.0834, Ridge Test MSE: 166.0283\n",
            "Epoch 216/1000, Ridge Training Loss: 199.2489, Ridge Test MSE: 165.2154\n",
            "Epoch 217/1000, Ridge Training Loss: 198.4184, Ridge Test MSE: 164.4068\n",
            "Epoch 218/1000, Ridge Training Loss: 197.5920, Ridge Test MSE: 163.6024\n",
            "Epoch 219/1000, Ridge Training Loss: 196.7695, Ridge Test MSE: 162.8021\n",
            "Epoch 220/1000, Ridge Training Loss: 195.9510, Ridge Test MSE: 162.0060\n",
            "Epoch 221/1000, Ridge Training Loss: 195.1365, Ridge Test MSE: 161.2141\n",
            "Epoch 222/1000, Ridge Training Loss: 194.3259, Ridge Test MSE: 160.4264\n",
            "Epoch 223/1000, Ridge Training Loss: 193.5193, Ridge Test MSE: 159.6427\n",
            "Epoch 224/1000, Ridge Training Loss: 192.7167, Ridge Test MSE: 158.8633\n",
            "Epoch 225/1000, Ridge Training Loss: 191.9180, Ridge Test MSE: 158.0879\n",
            "Epoch 226/1000, Ridge Training Loss: 191.1232, Ridge Test MSE: 157.3167\n",
            "Epoch 227/1000, Ridge Training Loss: 190.3324, Ridge Test MSE: 156.5496\n",
            "Epoch 228/1000, Ridge Training Loss: 189.5455, Ridge Test MSE: 155.7867\n",
            "Epoch 229/1000, Ridge Training Loss: 188.7625, Ridge Test MSE: 155.0278\n",
            "Epoch 230/1000, Ridge Training Loss: 187.9834, Ridge Test MSE: 154.2730\n",
            "Epoch 231/1000, Ridge Training Loss: 187.2082, Ridge Test MSE: 153.5223\n",
            "Epoch 232/1000, Ridge Training Loss: 186.4369, Ridge Test MSE: 152.7756\n",
            "Epoch 233/1000, Ridge Training Loss: 185.6695, Ridge Test MSE: 152.0331\n",
            "Epoch 234/1000, Ridge Training Loss: 184.9059, Ridge Test MSE: 151.2945\n",
            "Epoch 235/1000, Ridge Training Loss: 184.1463, Ridge Test MSE: 150.5601\n",
            "Epoch 236/1000, Ridge Training Loss: 183.3904, Ridge Test MSE: 149.8297\n",
            "Epoch 237/1000, Ridge Training Loss: 182.6384, Ridge Test MSE: 149.1032\n",
            "Epoch 238/1000, Ridge Training Loss: 181.8903, Ridge Test MSE: 148.3808\n",
            "Epoch 239/1000, Ridge Training Loss: 181.1459, Ridge Test MSE: 147.6624\n",
            "Epoch 240/1000, Ridge Training Loss: 180.4054, Ridge Test MSE: 146.9480\n",
            "Epoch 241/1000, Ridge Training Loss: 179.6687, Ridge Test MSE: 146.2376\n",
            "Epoch 242/1000, Ridge Training Loss: 178.9358, Ridge Test MSE: 145.5312\n",
            "Epoch 243/1000, Ridge Training Loss: 178.2067, Ridge Test MSE: 144.8287\n",
            "Epoch 244/1000, Ridge Training Loss: 177.4813, Ridge Test MSE: 144.1301\n",
            "Epoch 245/1000, Ridge Training Loss: 176.7597, Ridge Test MSE: 143.4355\n",
            "Epoch 246/1000, Ridge Training Loss: 176.0419, Ridge Test MSE: 142.7449\n",
            "Epoch 247/1000, Ridge Training Loss: 175.3278, Ridge Test MSE: 142.0581\n",
            "Epoch 248/1000, Ridge Training Loss: 174.6175, Ridge Test MSE: 141.3753\n",
            "Epoch 249/1000, Ridge Training Loss: 173.9109, Ridge Test MSE: 140.6963\n",
            "Epoch 250/1000, Ridge Training Loss: 173.2080, Ridge Test MSE: 140.0212\n",
            "Epoch 251/1000, Ridge Training Loss: 172.5088, Ridge Test MSE: 139.3501\n",
            "Epoch 252/1000, Ridge Training Loss: 171.8133, Ridge Test MSE: 138.6827\n",
            "Epoch 253/1000, Ridge Training Loss: 171.1214, Ridge Test MSE: 138.0192\n",
            "Epoch 254/1000, Ridge Training Loss: 170.4333, Ridge Test MSE: 137.3596\n",
            "Epoch 255/1000, Ridge Training Loss: 169.7488, Ridge Test MSE: 136.7038\n",
            "Epoch 256/1000, Ridge Training Loss: 169.0680, Ridge Test MSE: 136.0518\n",
            "Epoch 257/1000, Ridge Training Loss: 168.3908, Ridge Test MSE: 135.4035\n",
            "Epoch 258/1000, Ridge Training Loss: 167.7172, Ridge Test MSE: 134.7591\n",
            "Epoch 259/1000, Ridge Training Loss: 167.0473, Ridge Test MSE: 134.1185\n",
            "Epoch 260/1000, Ridge Training Loss: 166.3810, Ridge Test MSE: 133.4816\n",
            "Epoch 261/1000, Ridge Training Loss: 165.7182, Ridge Test MSE: 132.8484\n",
            "Epoch 262/1000, Ridge Training Loss: 165.0590, Ridge Test MSE: 132.2190\n",
            "Epoch 263/1000, Ridge Training Loss: 164.4035, Ridge Test MSE: 131.5934\n",
            "Epoch 264/1000, Ridge Training Loss: 163.7514, Ridge Test MSE: 130.9714\n",
            "Epoch 265/1000, Ridge Training Loss: 163.1030, Ridge Test MSE: 130.3532\n",
            "Epoch 266/1000, Ridge Training Loss: 162.4580, Ridge Test MSE: 129.7386\n",
            "Epoch 267/1000, Ridge Training Loss: 161.8166, Ridge Test MSE: 129.1277\n",
            "Epoch 268/1000, Ridge Training Loss: 161.1787, Ridge Test MSE: 128.5205\n",
            "Epoch 269/1000, Ridge Training Loss: 160.5443, Ridge Test MSE: 127.9169\n",
            "Epoch 270/1000, Ridge Training Loss: 159.9134, Ridge Test MSE: 127.3170\n",
            "Epoch 271/1000, Ridge Training Loss: 159.2859, Ridge Test MSE: 126.7206\n",
            "Epoch 272/1000, Ridge Training Loss: 158.6620, Ridge Test MSE: 126.1279\n",
            "Epoch 273/1000, Ridge Training Loss: 158.0415, Ridge Test MSE: 125.5388\n",
            "Epoch 274/1000, Ridge Training Loss: 157.4244, Ridge Test MSE: 124.9533\n",
            "Epoch 275/1000, Ridge Training Loss: 156.8107, Ridge Test MSE: 124.3714\n",
            "Epoch 276/1000, Ridge Training Loss: 156.2005, Ridge Test MSE: 123.7930\n",
            "Epoch 277/1000, Ridge Training Loss: 155.5937, Ridge Test MSE: 123.2181\n",
            "Epoch 278/1000, Ridge Training Loss: 154.9903, Ridge Test MSE: 122.6468\n",
            "Epoch 279/1000, Ridge Training Loss: 154.3902, Ridge Test MSE: 122.0790\n",
            "Epoch 280/1000, Ridge Training Loss: 153.7935, Ridge Test MSE: 121.5147\n",
            "Epoch 281/1000, Ridge Training Loss: 153.2002, Ridge Test MSE: 120.9539\n",
            "Epoch 282/1000, Ridge Training Loss: 152.6102, Ridge Test MSE: 120.3965\n",
            "Epoch 283/1000, Ridge Training Loss: 152.0235, Ridge Test MSE: 119.8427\n",
            "Epoch 284/1000, Ridge Training Loss: 151.4402, Ridge Test MSE: 119.2923\n",
            "Epoch 285/1000, Ridge Training Loss: 150.8602, Ridge Test MSE: 118.7453\n",
            "Epoch 286/1000, Ridge Training Loss: 150.2835, Ridge Test MSE: 118.2017\n",
            "Epoch 287/1000, Ridge Training Loss: 149.7100, Ridge Test MSE: 117.6616\n",
            "Epoch 288/1000, Ridge Training Loss: 149.1398, Ridge Test MSE: 117.1248\n",
            "Epoch 289/1000, Ridge Training Loss: 148.5729, Ridge Test MSE: 116.5915\n",
            "Epoch 290/1000, Ridge Training Loss: 148.0092, Ridge Test MSE: 116.0615\n",
            "Epoch 291/1000, Ridge Training Loss: 147.4487, Ridge Test MSE: 115.5348\n",
            "Epoch 292/1000, Ridge Training Loss: 146.8915, Ridge Test MSE: 115.0115\n",
            "Epoch 293/1000, Ridge Training Loss: 146.3374, Ridge Test MSE: 114.4915\n",
            "Epoch 294/1000, Ridge Training Loss: 145.7865, Ridge Test MSE: 113.9749\n",
            "Epoch 295/1000, Ridge Training Loss: 145.2389, Ridge Test MSE: 113.4615\n",
            "Epoch 296/1000, Ridge Training Loss: 144.6944, Ridge Test MSE: 112.9514\n",
            "Epoch 297/1000, Ridge Training Loss: 144.1530, Ridge Test MSE: 112.4446\n",
            "Epoch 298/1000, Ridge Training Loss: 143.6148, Ridge Test MSE: 111.9411\n",
            "Epoch 299/1000, Ridge Training Loss: 143.0797, Ridge Test MSE: 111.4408\n",
            "Epoch 300/1000, Ridge Training Loss: 142.5477, Ridge Test MSE: 110.9437\n",
            "Epoch 301/1000, Ridge Training Loss: 142.0188, Ridge Test MSE: 110.4499\n",
            "Epoch 302/1000, Ridge Training Loss: 141.4930, Ridge Test MSE: 109.9592\n",
            "Epoch 303/1000, Ridge Training Loss: 140.9703, Ridge Test MSE: 109.4717\n",
            "Epoch 304/1000, Ridge Training Loss: 140.4506, Ridge Test MSE: 108.9874\n",
            "Epoch 305/1000, Ridge Training Loss: 139.9340, Ridge Test MSE: 108.5063\n",
            "Epoch 306/1000, Ridge Training Loss: 139.4204, Ridge Test MSE: 108.0283\n",
            "Epoch 307/1000, Ridge Training Loss: 138.9099, Ridge Test MSE: 107.5535\n",
            "Epoch 308/1000, Ridge Training Loss: 138.4023, Ridge Test MSE: 107.0818\n",
            "Epoch 309/1000, Ridge Training Loss: 137.8978, Ridge Test MSE: 106.6131\n",
            "Epoch 310/1000, Ridge Training Loss: 137.3962, Ridge Test MSE: 106.1476\n",
            "Epoch 311/1000, Ridge Training Loss: 136.8976, Ridge Test MSE: 105.6851\n",
            "Epoch 312/1000, Ridge Training Loss: 136.4019, Ridge Test MSE: 105.2257\n",
            "Epoch 313/1000, Ridge Training Loss: 135.9092, Ridge Test MSE: 104.7693\n",
            "Epoch 314/1000, Ridge Training Loss: 135.4194, Ridge Test MSE: 104.3160\n",
            "Epoch 315/1000, Ridge Training Loss: 134.9326, Ridge Test MSE: 103.8657\n",
            "Epoch 316/1000, Ridge Training Loss: 134.4486, Ridge Test MSE: 103.4184\n",
            "Epoch 317/1000, Ridge Training Loss: 133.9676, Ridge Test MSE: 102.9741\n",
            "Epoch 318/1000, Ridge Training Loss: 133.4893, Ridge Test MSE: 102.5328\n",
            "Epoch 319/1000, Ridge Training Loss: 133.0140, Ridge Test MSE: 102.0944\n",
            "Epoch 320/1000, Ridge Training Loss: 132.5415, Ridge Test MSE: 101.6590\n",
            "Epoch 321/1000, Ridge Training Loss: 132.0719, Ridge Test MSE: 101.2266\n",
            "Epoch 322/1000, Ridge Training Loss: 131.6051, Ridge Test MSE: 100.7970\n",
            "Epoch 323/1000, Ridge Training Loss: 131.1411, Ridge Test MSE: 100.3704\n",
            "Epoch 324/1000, Ridge Training Loss: 130.6799, Ridge Test MSE: 99.9466\n",
            "Epoch 325/1000, Ridge Training Loss: 130.2215, Ridge Test MSE: 99.5258\n",
            "Epoch 326/1000, Ridge Training Loss: 129.7659, Ridge Test MSE: 99.1078\n",
            "Epoch 327/1000, Ridge Training Loss: 129.3130, Ridge Test MSE: 98.6926\n",
            "Epoch 328/1000, Ridge Training Loss: 128.8629, Ridge Test MSE: 98.2803\n",
            "Epoch 329/1000, Ridge Training Loss: 128.4155, Ridge Test MSE: 97.8708\n",
            "Epoch 330/1000, Ridge Training Loss: 127.9708, Ridge Test MSE: 97.4642\n",
            "Epoch 331/1000, Ridge Training Loss: 127.5288, Ridge Test MSE: 97.0603\n",
            "Epoch 332/1000, Ridge Training Loss: 127.0895, Ridge Test MSE: 96.6592\n",
            "Epoch 333/1000, Ridge Training Loss: 126.6530, Ridge Test MSE: 96.2609\n",
            "Epoch 334/1000, Ridge Training Loss: 126.2190, Ridge Test MSE: 95.8653\n",
            "Epoch 335/1000, Ridge Training Loss: 125.7878, Ridge Test MSE: 95.4724\n",
            "Epoch 336/1000, Ridge Training Loss: 125.3591, Ridge Test MSE: 95.0823\n",
            "Epoch 337/1000, Ridge Training Loss: 124.9331, Ridge Test MSE: 94.6950\n",
            "Epoch 338/1000, Ridge Training Loss: 124.5098, Ridge Test MSE: 94.3103\n",
            "Epoch 339/1000, Ridge Training Loss: 124.0890, Ridge Test MSE: 93.9283\n",
            "Epoch 340/1000, Ridge Training Loss: 123.6708, Ridge Test MSE: 93.5489\n",
            "Epoch 341/1000, Ridge Training Loss: 123.2552, Ridge Test MSE: 93.1723\n",
            "Epoch 342/1000, Ridge Training Loss: 122.8421, Ridge Test MSE: 92.7982\n",
            "Epoch 343/1000, Ridge Training Loss: 122.4317, Ridge Test MSE: 92.4268\n",
            "Epoch 344/1000, Ridge Training Loss: 122.0237, Ridge Test MSE: 92.0581\n",
            "Epoch 345/1000, Ridge Training Loss: 121.6183, Ridge Test MSE: 91.6919\n",
            "Epoch 346/1000, Ridge Training Loss: 121.2154, Ridge Test MSE: 91.3283\n",
            "Epoch 347/1000, Ridge Training Loss: 120.8150, Ridge Test MSE: 90.9673\n",
            "Epoch 348/1000, Ridge Training Loss: 120.4170, Ridge Test MSE: 90.6088\n",
            "Epoch 349/1000, Ridge Training Loss: 120.0216, Ridge Test MSE: 90.2529\n",
            "Epoch 350/1000, Ridge Training Loss: 119.6286, Ridge Test MSE: 89.8996\n",
            "Epoch 351/1000, Ridge Training Loss: 119.2381, Ridge Test MSE: 89.5487\n",
            "Epoch 352/1000, Ridge Training Loss: 118.8500, Ridge Test MSE: 89.2004\n",
            "Epoch 353/1000, Ridge Training Loss: 118.4643, Ridge Test MSE: 88.8546\n",
            "Epoch 354/1000, Ridge Training Loss: 118.0811, Ridge Test MSE: 88.5112\n",
            "Epoch 355/1000, Ridge Training Loss: 117.7002, Ridge Test MSE: 88.1703\n",
            "Epoch 356/1000, Ridge Training Loss: 117.3217, Ridge Test MSE: 87.8319\n",
            "Epoch 357/1000, Ridge Training Loss: 116.9456, Ridge Test MSE: 87.4959\n",
            "Epoch 358/1000, Ridge Training Loss: 116.5719, Ridge Test MSE: 87.1623\n",
            "Epoch 359/1000, Ridge Training Loss: 116.2005, Ridge Test MSE: 86.8312\n",
            "Epoch 360/1000, Ridge Training Loss: 115.8315, Ridge Test MSE: 86.5024\n",
            "Epoch 361/1000, Ridge Training Loss: 115.4648, Ridge Test MSE: 86.1761\n",
            "Epoch 362/1000, Ridge Training Loss: 115.1003, Ridge Test MSE: 85.8521\n",
            "Epoch 363/1000, Ridge Training Loss: 114.7382, Ridge Test MSE: 85.5304\n",
            "Epoch 364/1000, Ridge Training Loss: 114.3784, Ridge Test MSE: 85.2112\n",
            "Epoch 365/1000, Ridge Training Loss: 114.0209, Ridge Test MSE: 84.8942\n",
            "Epoch 366/1000, Ridge Training Loss: 113.6656, Ridge Test MSE: 84.5796\n",
            "Epoch 367/1000, Ridge Training Loss: 113.3126, Ridge Test MSE: 84.2673\n",
            "Epoch 368/1000, Ridge Training Loss: 112.9618, Ridge Test MSE: 83.9573\n",
            "Epoch 369/1000, Ridge Training Loss: 112.6132, Ridge Test MSE: 83.6496\n",
            "Epoch 370/1000, Ridge Training Loss: 112.2668, Ridge Test MSE: 83.3441\n",
            "Epoch 371/1000, Ridge Training Loss: 111.9227, Ridge Test MSE: 83.0409\n",
            "Epoch 372/1000, Ridge Training Loss: 111.5807, Ridge Test MSE: 82.7400\n",
            "Epoch 373/1000, Ridge Training Loss: 111.2410, Ridge Test MSE: 82.4412\n",
            "Epoch 374/1000, Ridge Training Loss: 110.9034, Ridge Test MSE: 82.1447\n",
            "Epoch 375/1000, Ridge Training Loss: 110.5679, Ridge Test MSE: 81.8504\n",
            "Epoch 376/1000, Ridge Training Loss: 110.2346, Ridge Test MSE: 81.5583\n",
            "Epoch 377/1000, Ridge Training Loss: 109.9034, Ridge Test MSE: 81.2684\n",
            "Epoch 378/1000, Ridge Training Loss: 109.5743, Ridge Test MSE: 80.9807\n",
            "Epoch 379/1000, Ridge Training Loss: 109.2474, Ridge Test MSE: 80.6951\n",
            "Epoch 380/1000, Ridge Training Loss: 108.9225, Ridge Test MSE: 80.4116\n",
            "Epoch 381/1000, Ridge Training Loss: 108.5997, Ridge Test MSE: 80.1303\n",
            "Epoch 382/1000, Ridge Training Loss: 108.2790, Ridge Test MSE: 79.8511\n",
            "Epoch 383/1000, Ridge Training Loss: 107.9603, Ridge Test MSE: 79.5740\n",
            "Epoch 384/1000, Ridge Training Loss: 107.6437, Ridge Test MSE: 79.2990\n",
            "Epoch 385/1000, Ridge Training Loss: 107.3292, Ridge Test MSE: 79.0261\n",
            "Epoch 386/1000, Ridge Training Loss: 107.0166, Ridge Test MSE: 78.7552\n",
            "Epoch 387/1000, Ridge Training Loss: 106.7061, Ridge Test MSE: 78.4864\n",
            "Epoch 388/1000, Ridge Training Loss: 106.3976, Ridge Test MSE: 78.2197\n",
            "Epoch 389/1000, Ridge Training Loss: 106.0910, Ridge Test MSE: 77.9549\n",
            "Epoch 390/1000, Ridge Training Loss: 105.7865, Ridge Test MSE: 77.6922\n",
            "Epoch 391/1000, Ridge Training Loss: 105.4839, Ridge Test MSE: 77.4315\n",
            "Epoch 392/1000, Ridge Training Loss: 105.1832, Ridge Test MSE: 77.1728\n",
            "Epoch 393/1000, Ridge Training Loss: 104.8845, Ridge Test MSE: 76.9161\n",
            "Epoch 394/1000, Ridge Training Loss: 104.5878, Ridge Test MSE: 76.6613\n",
            "Epoch 395/1000, Ridge Training Loss: 104.2929, Ridge Test MSE: 76.4085\n",
            "Epoch 396/1000, Ridge Training Loss: 104.0000, Ridge Test MSE: 76.1577\n",
            "Epoch 397/1000, Ridge Training Loss: 103.7090, Ridge Test MSE: 75.9088\n",
            "Epoch 398/1000, Ridge Training Loss: 103.4198, Ridge Test MSE: 75.6618\n",
            "Epoch 399/1000, Ridge Training Loss: 103.1326, Ridge Test MSE: 75.4167\n",
            "Epoch 400/1000, Ridge Training Loss: 102.8472, Ridge Test MSE: 75.1736\n",
            "Epoch 401/1000, Ridge Training Loss: 102.5637, Ridge Test MSE: 74.9323\n",
            "Epoch 402/1000, Ridge Training Loss: 102.2820, Ridge Test MSE: 74.6929\n",
            "Epoch 403/1000, Ridge Training Loss: 102.0021, Ridge Test MSE: 74.4553\n",
            "Epoch 404/1000, Ridge Training Loss: 101.7241, Ridge Test MSE: 74.2196\n",
            "Epoch 405/1000, Ridge Training Loss: 101.4479, Ridge Test MSE: 73.9858\n",
            "Epoch 406/1000, Ridge Training Loss: 101.1734, Ridge Test MSE: 73.7538\n",
            "Epoch 407/1000, Ridge Training Loss: 100.9008, Ridge Test MSE: 73.5236\n",
            "Epoch 408/1000, Ridge Training Loss: 100.6299, Ridge Test MSE: 73.2952\n",
            "Epoch 409/1000, Ridge Training Loss: 100.3608, Ridge Test MSE: 73.0686\n",
            "Epoch 410/1000, Ridge Training Loss: 100.0935, Ridge Test MSE: 72.8438\n",
            "Epoch 411/1000, Ridge Training Loss: 99.8279, Ridge Test MSE: 72.6207\n",
            "Epoch 412/1000, Ridge Training Loss: 99.5641, Ridge Test MSE: 72.3995\n",
            "Epoch 413/1000, Ridge Training Loss: 99.3020, Ridge Test MSE: 72.1799\n",
            "Epoch 414/1000, Ridge Training Loss: 99.0416, Ridge Test MSE: 71.9621\n",
            "Epoch 415/1000, Ridge Training Loss: 98.7829, Ridge Test MSE: 71.7461\n",
            "Epoch 416/1000, Ridge Training Loss: 98.5259, Ridge Test MSE: 71.5317\n",
            "Epoch 417/1000, Ridge Training Loss: 98.2706, Ridge Test MSE: 71.3191\n",
            "Epoch 418/1000, Ridge Training Loss: 98.0169, Ridge Test MSE: 71.1082\n",
            "Epoch 419/1000, Ridge Training Loss: 97.7650, Ridge Test MSE: 70.8989\n",
            "Epoch 420/1000, Ridge Training Loss: 97.5146, Ridge Test MSE: 70.6913\n",
            "Epoch 421/1000, Ridge Training Loss: 97.2659, Ridge Test MSE: 70.4855\n",
            "Epoch 422/1000, Ridge Training Loss: 97.0189, Ridge Test MSE: 70.2812\n",
            "Epoch 423/1000, Ridge Training Loss: 96.7735, Ridge Test MSE: 70.0786\n",
            "Epoch 424/1000, Ridge Training Loss: 96.5297, Ridge Test MSE: 69.8776\n",
            "Epoch 425/1000, Ridge Training Loss: 96.2875, Ridge Test MSE: 69.6782\n",
            "Epoch 426/1000, Ridge Training Loss: 96.0469, Ridge Test MSE: 69.4805\n",
            "Epoch 427/1000, Ridge Training Loss: 95.8079, Ridge Test MSE: 69.2843\n",
            "Epoch 428/1000, Ridge Training Loss: 95.5704, Ridge Test MSE: 69.0897\n",
            "Epoch 429/1000, Ridge Training Loss: 95.3345, Ridge Test MSE: 68.8967\n",
            "Epoch 430/1000, Ridge Training Loss: 95.1002, Ridge Test MSE: 68.7053\n",
            "Epoch 431/1000, Ridge Training Loss: 94.8674, Ridge Test MSE: 68.5155\n",
            "Epoch 432/1000, Ridge Training Loss: 94.6362, Ridge Test MSE: 68.3271\n",
            "Epoch 433/1000, Ridge Training Loss: 94.4064, Ridge Test MSE: 68.1404\n",
            "Epoch 434/1000, Ridge Training Loss: 94.1782, Ridge Test MSE: 67.9551\n",
            "Epoch 435/1000, Ridge Training Loss: 93.9515, Ridge Test MSE: 67.7714\n",
            "Epoch 436/1000, Ridge Training Loss: 93.7263, Ridge Test MSE: 67.5891\n",
            "Epoch 437/1000, Ridge Training Loss: 93.5026, Ridge Test MSE: 67.4084\n",
            "Epoch 438/1000, Ridge Training Loss: 93.2804, Ridge Test MSE: 67.2291\n",
            "Epoch 439/1000, Ridge Training Loss: 93.0596, Ridge Test MSE: 67.0514\n",
            "Epoch 440/1000, Ridge Training Loss: 92.8403, Ridge Test MSE: 66.8751\n",
            "Epoch 441/1000, Ridge Training Loss: 92.6224, Ridge Test MSE: 66.7002\n",
            "Epoch 442/1000, Ridge Training Loss: 92.4060, Ridge Test MSE: 66.5268\n",
            "Epoch 443/1000, Ridge Training Loss: 92.1910, Ridge Test MSE: 66.3549\n",
            "Epoch 444/1000, Ridge Training Loss: 91.9775, Ridge Test MSE: 66.1843\n",
            "Epoch 445/1000, Ridge Training Loss: 91.7653, Ridge Test MSE: 66.0152\n",
            "Epoch 446/1000, Ridge Training Loss: 91.5546, Ridge Test MSE: 65.8475\n",
            "Epoch 447/1000, Ridge Training Loss: 91.3452, Ridge Test MSE: 65.6812\n",
            "Epoch 448/1000, Ridge Training Loss: 91.1373, Ridge Test MSE: 65.5163\n",
            "Epoch 449/1000, Ridge Training Loss: 90.9307, Ridge Test MSE: 65.3527\n",
            "Epoch 450/1000, Ridge Training Loss: 90.7255, Ridge Test MSE: 65.1906\n",
            "Epoch 451/1000, Ridge Training Loss: 90.5216, Ridge Test MSE: 65.0297\n",
            "Epoch 452/1000, Ridge Training Loss: 90.3191, Ridge Test MSE: 64.8703\n",
            "Epoch 453/1000, Ridge Training Loss: 90.1179, Ridge Test MSE: 64.7122\n",
            "Epoch 454/1000, Ridge Training Loss: 89.9181, Ridge Test MSE: 64.5554\n",
            "Epoch 455/1000, Ridge Training Loss: 89.7196, Ridge Test MSE: 64.3999\n",
            "Epoch 456/1000, Ridge Training Loss: 89.5224, Ridge Test MSE: 64.2458\n",
            "Epoch 457/1000, Ridge Training Loss: 89.3265, Ridge Test MSE: 64.0929\n",
            "Epoch 458/1000, Ridge Training Loss: 89.1319, Ridge Test MSE: 63.9414\n",
            "Epoch 459/1000, Ridge Training Loss: 88.9387, Ridge Test MSE: 63.7911\n",
            "Epoch 460/1000, Ridge Training Loss: 88.7467, Ridge Test MSE: 63.6422\n",
            "Epoch 461/1000, Ridge Training Loss: 88.5559, Ridge Test MSE: 63.4944\n",
            "Epoch 462/1000, Ridge Training Loss: 88.3664, Ridge Test MSE: 63.3480\n",
            "Epoch 463/1000, Ridge Training Loss: 88.1782, Ridge Test MSE: 63.2028\n",
            "Epoch 464/1000, Ridge Training Loss: 87.9913, Ridge Test MSE: 63.0588\n",
            "Epoch 465/1000, Ridge Training Loss: 87.8055, Ridge Test MSE: 62.9161\n",
            "Epoch 466/1000, Ridge Training Loss: 87.6210, Ridge Test MSE: 62.7746\n",
            "Epoch 467/1000, Ridge Training Loss: 87.4378, Ridge Test MSE: 62.6343\n",
            "Epoch 468/1000, Ridge Training Loss: 87.2557, Ridge Test MSE: 62.4953\n",
            "Epoch 469/1000, Ridge Training Loss: 87.0749, Ridge Test MSE: 62.3574\n",
            "Epoch 470/1000, Ridge Training Loss: 86.8952, Ridge Test MSE: 62.2207\n",
            "Epoch 471/1000, Ridge Training Loss: 86.7168, Ridge Test MSE: 62.0852\n",
            "Epoch 472/1000, Ridge Training Loss: 86.5395, Ridge Test MSE: 61.9509\n",
            "Epoch 473/1000, Ridge Training Loss: 86.3634, Ridge Test MSE: 61.8178\n",
            "Epoch 474/1000, Ridge Training Loss: 86.1885, Ridge Test MSE: 61.6858\n",
            "Epoch 475/1000, Ridge Training Loss: 86.0148, Ridge Test MSE: 61.5549\n",
            "Epoch 476/1000, Ridge Training Loss: 85.8422, Ridge Test MSE: 61.4252\n",
            "Epoch 477/1000, Ridge Training Loss: 85.6707, Ridge Test MSE: 61.2966\n",
            "Epoch 478/1000, Ridge Training Loss: 85.5004, Ridge Test MSE: 61.1692\n",
            "Epoch 479/1000, Ridge Training Loss: 85.3312, Ridge Test MSE: 61.0428\n",
            "Epoch 480/1000, Ridge Training Loss: 85.1631, Ridge Test MSE: 60.9176\n",
            "Epoch 481/1000, Ridge Training Loss: 84.9962, Ridge Test MSE: 60.7935\n",
            "Epoch 482/1000, Ridge Training Loss: 84.8303, Ridge Test MSE: 60.6704\n",
            "Epoch 483/1000, Ridge Training Loss: 84.6656, Ridge Test MSE: 60.5485\n",
            "Epoch 484/1000, Ridge Training Loss: 84.5019, Ridge Test MSE: 60.4276\n",
            "Epoch 485/1000, Ridge Training Loss: 84.3394, Ridge Test MSE: 60.3078\n",
            "Epoch 486/1000, Ridge Training Loss: 84.1779, Ridge Test MSE: 60.1891\n",
            "Epoch 487/1000, Ridge Training Loss: 84.0175, Ridge Test MSE: 60.0714\n",
            "Epoch 488/1000, Ridge Training Loss: 83.8581, Ridge Test MSE: 59.9547\n",
            "Epoch 489/1000, Ridge Training Loss: 83.6998, Ridge Test MSE: 59.8391\n",
            "Epoch 490/1000, Ridge Training Loss: 83.5425, Ridge Test MSE: 59.7245\n",
            "Epoch 491/1000, Ridge Training Loss: 83.3863, Ridge Test MSE: 59.6110\n",
            "Epoch 492/1000, Ridge Training Loss: 83.2311, Ridge Test MSE: 59.4984\n",
            "Epoch 493/1000, Ridge Training Loss: 83.0770, Ridge Test MSE: 59.3869\n",
            "Epoch 494/1000, Ridge Training Loss: 82.9239, Ridge Test MSE: 59.2764\n",
            "Epoch 495/1000, Ridge Training Loss: 82.7718, Ridge Test MSE: 59.1668\n",
            "Epoch 496/1000, Ridge Training Loss: 82.6207, Ridge Test MSE: 59.0583\n",
            "Epoch 497/1000, Ridge Training Loss: 82.4706, Ridge Test MSE: 58.9507\n",
            "Epoch 498/1000, Ridge Training Loss: 82.3214, Ridge Test MSE: 58.8441\n",
            "Epoch 499/1000, Ridge Training Loss: 82.1733, Ridge Test MSE: 58.7385\n",
            "Epoch 500/1000, Ridge Training Loss: 82.0262, Ridge Test MSE: 58.6338\n",
            "Epoch 501/1000, Ridge Training Loss: 81.8800, Ridge Test MSE: 58.5301\n",
            "Epoch 502/1000, Ridge Training Loss: 81.7348, Ridge Test MSE: 58.4273\n",
            "Epoch 503/1000, Ridge Training Loss: 81.5906, Ridge Test MSE: 58.3254\n",
            "Epoch 504/1000, Ridge Training Loss: 81.4473, Ridge Test MSE: 58.2245\n",
            "Epoch 505/1000, Ridge Training Loss: 81.3049, Ridge Test MSE: 58.1245\n",
            "Epoch 506/1000, Ridge Training Loss: 81.1635, Ridge Test MSE: 58.0254\n",
            "Epoch 507/1000, Ridge Training Loss: 81.0230, Ridge Test MSE: 57.9272\n",
            "Epoch 508/1000, Ridge Training Loss: 80.8835, Ridge Test MSE: 57.8300\n",
            "Epoch 509/1000, Ridge Training Loss: 80.7449, Ridge Test MSE: 57.7336\n",
            "Epoch 510/1000, Ridge Training Loss: 80.6071, Ridge Test MSE: 57.6381\n",
            "Epoch 511/1000, Ridge Training Loss: 80.4703, Ridge Test MSE: 57.5435\n",
            "Epoch 512/1000, Ridge Training Loss: 80.3344, Ridge Test MSE: 57.4497\n",
            "Epoch 513/1000, Ridge Training Loss: 80.1994, Ridge Test MSE: 57.3569\n",
            "Epoch 514/1000, Ridge Training Loss: 80.0653, Ridge Test MSE: 57.2648\n",
            "Epoch 515/1000, Ridge Training Loss: 79.9321, Ridge Test MSE: 57.1737\n",
            "Epoch 516/1000, Ridge Training Loss: 79.7997, Ridge Test MSE: 57.0834\n",
            "Epoch 517/1000, Ridge Training Loss: 79.6683, Ridge Test MSE: 56.9939\n",
            "Epoch 518/1000, Ridge Training Loss: 79.5376, Ridge Test MSE: 56.9053\n",
            "Epoch 519/1000, Ridge Training Loss: 79.4079, Ridge Test MSE: 56.8175\n",
            "Epoch 520/1000, Ridge Training Loss: 79.2790, Ridge Test MSE: 56.7305\n",
            "Epoch 521/1000, Ridge Training Loss: 79.1509, Ridge Test MSE: 56.6443\n",
            "Epoch 522/1000, Ridge Training Loss: 79.0237, Ridge Test MSE: 56.5590\n",
            "Epoch 523/1000, Ridge Training Loss: 78.8973, Ridge Test MSE: 56.4744\n",
            "Epoch 524/1000, Ridge Training Loss: 78.7717, Ridge Test MSE: 56.3906\n",
            "Epoch 525/1000, Ridge Training Loss: 78.6470, Ridge Test MSE: 56.3077\n",
            "Epoch 526/1000, Ridge Training Loss: 78.5231, Ridge Test MSE: 56.2255\n",
            "Epoch 527/1000, Ridge Training Loss: 78.4000, Ridge Test MSE: 56.1441\n",
            "Epoch 528/1000, Ridge Training Loss: 78.2777, Ridge Test MSE: 56.0635\n",
            "Epoch 529/1000, Ridge Training Loss: 78.1562, Ridge Test MSE: 55.9836\n",
            "Epoch 530/1000, Ridge Training Loss: 78.0355, Ridge Test MSE: 55.9045\n",
            "Epoch 531/1000, Ridge Training Loss: 77.9156, Ridge Test MSE: 55.8262\n",
            "Epoch 532/1000, Ridge Training Loss: 77.7965, Ridge Test MSE: 55.7486\n",
            "Epoch 533/1000, Ridge Training Loss: 77.6781, Ridge Test MSE: 55.6717\n",
            "Epoch 534/1000, Ridge Training Loss: 77.5605, Ridge Test MSE: 55.5956\n",
            "Epoch 535/1000, Ridge Training Loss: 77.4437, Ridge Test MSE: 55.5202\n",
            "Epoch 536/1000, Ridge Training Loss: 77.3277, Ridge Test MSE: 55.4456\n",
            "Epoch 537/1000, Ridge Training Loss: 77.2124, Ridge Test MSE: 55.3717\n",
            "Epoch 538/1000, Ridge Training Loss: 77.0978, Ridge Test MSE: 55.2984\n",
            "Epoch 539/1000, Ridge Training Loss: 76.9841, Ridge Test MSE: 55.2259\n",
            "Epoch 540/1000, Ridge Training Loss: 76.8710, Ridge Test MSE: 55.1541\n",
            "Epoch 541/1000, Ridge Training Loss: 76.7587, Ridge Test MSE: 55.0830\n",
            "Epoch 542/1000, Ridge Training Loss: 76.6471, Ridge Test MSE: 55.0126\n",
            "Epoch 543/1000, Ridge Training Loss: 76.5362, Ridge Test MSE: 54.9429\n",
            "Epoch 544/1000, Ridge Training Loss: 76.4261, Ridge Test MSE: 54.8739\n",
            "Epoch 545/1000, Ridge Training Loss: 76.3167, Ridge Test MSE: 54.8055\n",
            "Epoch 546/1000, Ridge Training Loss: 76.2080, Ridge Test MSE: 54.7378\n",
            "Epoch 547/1000, Ridge Training Loss: 76.1000, Ridge Test MSE: 54.6708\n",
            "Epoch 548/1000, Ridge Training Loss: 75.9927, Ridge Test MSE: 54.6044\n",
            "Epoch 549/1000, Ridge Training Loss: 75.8860, Ridge Test MSE: 54.5387\n",
            "Epoch 550/1000, Ridge Training Loss: 75.7801, Ridge Test MSE: 54.4736\n",
            "Epoch 551/1000, Ridge Training Loss: 75.6749, Ridge Test MSE: 54.4092\n",
            "Epoch 552/1000, Ridge Training Loss: 75.5703, Ridge Test MSE: 54.3454\n",
            "Epoch 553/1000, Ridge Training Loss: 75.4664, Ridge Test MSE: 54.2823\n",
            "Epoch 554/1000, Ridge Training Loss: 75.3632, Ridge Test MSE: 54.2198\n",
            "Epoch 555/1000, Ridge Training Loss: 75.2607, Ridge Test MSE: 54.1579\n",
            "Epoch 556/1000, Ridge Training Loss: 75.1588, Ridge Test MSE: 54.0966\n",
            "Epoch 557/1000, Ridge Training Loss: 75.0576, Ridge Test MSE: 54.0360\n",
            "Epoch 558/1000, Ridge Training Loss: 74.9570, Ridge Test MSE: 53.9759\n",
            "Epoch 559/1000, Ridge Training Loss: 74.8571, Ridge Test MSE: 53.9165\n",
            "Epoch 560/1000, Ridge Training Loss: 74.7578, Ridge Test MSE: 53.8577\n",
            "Epoch 561/1000, Ridge Training Loss: 74.6591, Ridge Test MSE: 53.7994\n",
            "Epoch 562/1000, Ridge Training Loss: 74.5611, Ridge Test MSE: 53.7418\n",
            "Epoch 563/1000, Ridge Training Loss: 74.4637, Ridge Test MSE: 53.6847\n",
            "Epoch 564/1000, Ridge Training Loss: 74.3670, Ridge Test MSE: 53.6282\n",
            "Epoch 565/1000, Ridge Training Loss: 74.2709, Ridge Test MSE: 53.5723\n",
            "Epoch 566/1000, Ridge Training Loss: 74.1753, Ridge Test MSE: 53.5170\n",
            "Epoch 567/1000, Ridge Training Loss: 74.0804, Ridge Test MSE: 53.4622\n",
            "Epoch 568/1000, Ridge Training Loss: 73.9861, Ridge Test MSE: 53.4080\n",
            "Epoch 569/1000, Ridge Training Loss: 73.8924, Ridge Test MSE: 53.3544\n",
            "Epoch 570/1000, Ridge Training Loss: 73.7993, Ridge Test MSE: 53.3013\n",
            "Epoch 571/1000, Ridge Training Loss: 73.7068, Ridge Test MSE: 53.2488\n",
            "Epoch 572/1000, Ridge Training Loss: 73.6149, Ridge Test MSE: 53.1967\n",
            "Epoch 573/1000, Ridge Training Loss: 73.5235, Ridge Test MSE: 53.1453\n",
            "Epoch 574/1000, Ridge Training Loss: 73.4328, Ridge Test MSE: 53.0944\n",
            "Epoch 575/1000, Ridge Training Loss: 73.3426, Ridge Test MSE: 53.0440\n",
            "Epoch 576/1000, Ridge Training Loss: 73.2530, Ridge Test MSE: 52.9941\n",
            "Epoch 577/1000, Ridge Training Loss: 73.1639, Ridge Test MSE: 52.9448\n",
            "Epoch 578/1000, Ridge Training Loss: 73.0755, Ridge Test MSE: 52.8960\n",
            "Epoch 579/1000, Ridge Training Loss: 72.9876, Ridge Test MSE: 52.8477\n",
            "Epoch 580/1000, Ridge Training Loss: 72.9002, Ridge Test MSE: 52.7999\n",
            "Epoch 581/1000, Ridge Training Loss: 72.8134, Ridge Test MSE: 52.7526\n",
            "Epoch 582/1000, Ridge Training Loss: 72.7271, Ridge Test MSE: 52.7058\n",
            "Epoch 583/1000, Ridge Training Loss: 72.6414, Ridge Test MSE: 52.6595\n",
            "Epoch 584/1000, Ridge Training Loss: 72.5563, Ridge Test MSE: 52.6137\n",
            "Epoch 585/1000, Ridge Training Loss: 72.4716, Ridge Test MSE: 52.5684\n",
            "Epoch 586/1000, Ridge Training Loss: 72.3876, Ridge Test MSE: 52.5235\n",
            "Epoch 587/1000, Ridge Training Loss: 72.3040, Ridge Test MSE: 52.4792\n",
            "Epoch 588/1000, Ridge Training Loss: 72.2209, Ridge Test MSE: 52.4353\n",
            "Epoch 589/1000, Ridge Training Loss: 72.1384, Ridge Test MSE: 52.3920\n",
            "Epoch 590/1000, Ridge Training Loss: 72.0564, Ridge Test MSE: 52.3490\n",
            "Epoch 591/1000, Ridge Training Loss: 71.9749, Ridge Test MSE: 52.3066\n",
            "Epoch 592/1000, Ridge Training Loss: 71.8940, Ridge Test MSE: 52.2646\n",
            "Epoch 593/1000, Ridge Training Loss: 71.8135, Ridge Test MSE: 52.2230\n",
            "Epoch 594/1000, Ridge Training Loss: 71.7335, Ridge Test MSE: 52.1820\n",
            "Epoch 595/1000, Ridge Training Loss: 71.6541, Ridge Test MSE: 52.1413\n",
            "Epoch 596/1000, Ridge Training Loss: 71.5751, Ridge Test MSE: 52.1012\n",
            "Epoch 597/1000, Ridge Training Loss: 71.4966, Ridge Test MSE: 52.0614\n",
            "Epoch 598/1000, Ridge Training Loss: 71.4186, Ridge Test MSE: 52.0221\n",
            "Epoch 599/1000, Ridge Training Loss: 71.3411, Ridge Test MSE: 51.9832\n",
            "Epoch 600/1000, Ridge Training Loss: 71.2641, Ridge Test MSE: 51.9448\n",
            "Epoch 601/1000, Ridge Training Loss: 71.1876, Ridge Test MSE: 51.9068\n",
            "Epoch 602/1000, Ridge Training Loss: 71.1115, Ridge Test MSE: 51.8692\n",
            "Epoch 603/1000, Ridge Training Loss: 71.0359, Ridge Test MSE: 51.8321\n",
            "Epoch 604/1000, Ridge Training Loss: 70.9608, Ridge Test MSE: 51.7953\n",
            "Epoch 605/1000, Ridge Training Loss: 70.8861, Ridge Test MSE: 51.7590\n",
            "Epoch 606/1000, Ridge Training Loss: 70.8119, Ridge Test MSE: 51.7231\n",
            "Epoch 607/1000, Ridge Training Loss: 70.7382, Ridge Test MSE: 51.6876\n",
            "Epoch 608/1000, Ridge Training Loss: 70.6649, Ridge Test MSE: 51.6525\n",
            "Epoch 609/1000, Ridge Training Loss: 70.5920, Ridge Test MSE: 51.6178\n",
            "Epoch 610/1000, Ridge Training Loss: 70.5197, Ridge Test MSE: 51.5834\n",
            "Epoch 611/1000, Ridge Training Loss: 70.4477, Ridge Test MSE: 51.5495\n",
            "Epoch 612/1000, Ridge Training Loss: 70.3762, Ridge Test MSE: 51.5160\n",
            "Epoch 613/1000, Ridge Training Loss: 70.3052, Ridge Test MSE: 51.4829\n",
            "Epoch 614/1000, Ridge Training Loss: 70.2346, Ridge Test MSE: 51.4501\n",
            "Epoch 615/1000, Ridge Training Loss: 70.1643, Ridge Test MSE: 51.4177\n",
            "Epoch 616/1000, Ridge Training Loss: 70.0946, Ridge Test MSE: 51.3858\n",
            "Epoch 617/1000, Ridge Training Loss: 70.0253, Ridge Test MSE: 51.3541\n",
            "Epoch 618/1000, Ridge Training Loss: 69.9563, Ridge Test MSE: 51.3229\n",
            "Epoch 619/1000, Ridge Training Loss: 69.8879, Ridge Test MSE: 51.2920\n",
            "Epoch 620/1000, Ridge Training Loss: 69.8198, Ridge Test MSE: 51.2615\n",
            "Epoch 621/1000, Ridge Training Loss: 69.7521, Ridge Test MSE: 51.2313\n",
            "Epoch 622/1000, Ridge Training Loss: 69.6849, Ridge Test MSE: 51.2015\n",
            "Epoch 623/1000, Ridge Training Loss: 69.6180, Ridge Test MSE: 51.1721\n",
            "Epoch 624/1000, Ridge Training Loss: 69.5516, Ridge Test MSE: 51.1430\n",
            "Epoch 625/1000, Ridge Training Loss: 69.4856, Ridge Test MSE: 51.1142\n",
            "Epoch 626/1000, Ridge Training Loss: 69.4199, Ridge Test MSE: 51.0858\n",
            "Epoch 627/1000, Ridge Training Loss: 69.3547, Ridge Test MSE: 51.0578\n",
            "Epoch 628/1000, Ridge Training Loss: 69.2898, Ridge Test MSE: 51.0301\n",
            "Epoch 629/1000, Ridge Training Loss: 69.2254, Ridge Test MSE: 51.0027\n",
            "Epoch 630/1000, Ridge Training Loss: 69.1613, Ridge Test MSE: 50.9757\n",
            "Epoch 631/1000, Ridge Training Loss: 69.0977, Ridge Test MSE: 50.9489\n",
            "Epoch 632/1000, Ridge Training Loss: 69.0344, Ridge Test MSE: 50.9226\n",
            "Epoch 633/1000, Ridge Training Loss: 68.9715, Ridge Test MSE: 50.8965\n",
            "Epoch 634/1000, Ridge Training Loss: 68.9089, Ridge Test MSE: 50.8708\n",
            "Epoch 635/1000, Ridge Training Loss: 68.8468, Ridge Test MSE: 50.8454\n",
            "Epoch 636/1000, Ridge Training Loss: 68.7850, Ridge Test MSE: 50.8203\n",
            "Epoch 637/1000, Ridge Training Loss: 68.7235, Ridge Test MSE: 50.7955\n",
            "Epoch 638/1000, Ridge Training Loss: 68.6625, Ridge Test MSE: 50.7710\n",
            "Epoch 639/1000, Ridge Training Loss: 68.6018, Ridge Test MSE: 50.7469\n",
            "Epoch 640/1000, Ridge Training Loss: 68.5415, Ridge Test MSE: 50.7230\n",
            "Epoch 641/1000, Ridge Training Loss: 68.4815, Ridge Test MSE: 50.6995\n",
            "Epoch 642/1000, Ridge Training Loss: 68.4219, Ridge Test MSE: 50.6762\n",
            "Epoch 643/1000, Ridge Training Loss: 68.3626, Ridge Test MSE: 50.6533\n",
            "Epoch 644/1000, Ridge Training Loss: 68.3037, Ridge Test MSE: 50.6306\n",
            "Epoch 645/1000, Ridge Training Loss: 68.2452, Ridge Test MSE: 50.6083\n",
            "Epoch 646/1000, Ridge Training Loss: 68.1870, Ridge Test MSE: 50.5862\n",
            "Epoch 647/1000, Ridge Training Loss: 68.1291, Ridge Test MSE: 50.5644\n",
            "Epoch 648/1000, Ridge Training Loss: 68.0716, Ridge Test MSE: 50.5429\n",
            "Epoch 649/1000, Ridge Training Loss: 68.0144, Ridge Test MSE: 50.5217\n",
            "Epoch 650/1000, Ridge Training Loss: 67.9575, Ridge Test MSE: 50.5008\n",
            "Epoch 651/1000, Ridge Training Loss: 67.9010, Ridge Test MSE: 50.4801\n",
            "Epoch 652/1000, Ridge Training Loss: 67.8448, Ridge Test MSE: 50.4598\n",
            "Epoch 653/1000, Ridge Training Loss: 67.7889, Ridge Test MSE: 50.4397\n",
            "Epoch 654/1000, Ridge Training Loss: 67.7334, Ridge Test MSE: 50.4198\n",
            "Epoch 655/1000, Ridge Training Loss: 67.6782, Ridge Test MSE: 50.4003\n",
            "Epoch 656/1000, Ridge Training Loss: 67.6233, Ridge Test MSE: 50.3810\n",
            "Epoch 657/1000, Ridge Training Loss: 67.5688, Ridge Test MSE: 50.3620\n",
            "Epoch 658/1000, Ridge Training Loss: 67.5145, Ridge Test MSE: 50.3432\n",
            "Epoch 659/1000, Ridge Training Loss: 67.4606, Ridge Test MSE: 50.3247\n",
            "Epoch 660/1000, Ridge Training Loss: 67.4070, Ridge Test MSE: 50.3064\n",
            "Epoch 661/1000, Ridge Training Loss: 67.3537, Ridge Test MSE: 50.2884\n",
            "Epoch 662/1000, Ridge Training Loss: 67.3007, Ridge Test MSE: 50.2707\n",
            "Epoch 663/1000, Ridge Training Loss: 67.2480, Ridge Test MSE: 50.2532\n",
            "Epoch 664/1000, Ridge Training Loss: 67.1956, Ridge Test MSE: 50.2360\n",
            "Epoch 665/1000, Ridge Training Loss: 67.1435, Ridge Test MSE: 50.2190\n",
            "Epoch 666/1000, Ridge Training Loss: 67.0917, Ridge Test MSE: 50.2022\n",
            "Epoch 667/1000, Ridge Training Loss: 67.0402, Ridge Test MSE: 50.1857\n",
            "Epoch 668/1000, Ridge Training Loss: 66.9890, Ridge Test MSE: 50.1694\n",
            "Epoch 669/1000, Ridge Training Loss: 66.9381, Ridge Test MSE: 50.1534\n",
            "Epoch 670/1000, Ridge Training Loss: 66.8875, Ridge Test MSE: 50.1376\n",
            "Epoch 671/1000, Ridge Training Loss: 66.8372, Ridge Test MSE: 50.1220\n",
            "Epoch 672/1000, Ridge Training Loss: 66.7872, Ridge Test MSE: 50.1067\n",
            "Epoch 673/1000, Ridge Training Loss: 66.7374, Ridge Test MSE: 50.0916\n",
            "Epoch 674/1000, Ridge Training Loss: 66.6880, Ridge Test MSE: 50.0767\n",
            "Epoch 675/1000, Ridge Training Loss: 66.6388, Ridge Test MSE: 50.0620\n",
            "Epoch 676/1000, Ridge Training Loss: 66.5899, Ridge Test MSE: 50.0476\n",
            "Epoch 677/1000, Ridge Training Loss: 66.5412, Ridge Test MSE: 50.0334\n",
            "Epoch 678/1000, Ridge Training Loss: 66.4929, Ridge Test MSE: 50.0194\n",
            "Epoch 679/1000, Ridge Training Loss: 66.4448, Ridge Test MSE: 50.0056\n",
            "Epoch 680/1000, Ridge Training Loss: 66.3970, Ridge Test MSE: 49.9920\n",
            "Epoch 681/1000, Ridge Training Loss: 66.3495, Ridge Test MSE: 49.9787\n",
            "Epoch 682/1000, Ridge Training Loss: 66.3022, Ridge Test MSE: 49.9655\n",
            "Epoch 683/1000, Ridge Training Loss: 66.2552, Ridge Test MSE: 49.9526\n",
            "Epoch 684/1000, Ridge Training Loss: 66.2085, Ridge Test MSE: 49.9399\n",
            "Epoch 685/1000, Ridge Training Loss: 66.1620, Ridge Test MSE: 49.9274\n",
            "Epoch 686/1000, Ridge Training Loss: 66.1158, Ridge Test MSE: 49.9150\n",
            "Epoch 687/1000, Ridge Training Loss: 66.0698, Ridge Test MSE: 49.9029\n",
            "Epoch 688/1000, Ridge Training Loss: 66.0241, Ridge Test MSE: 49.8910\n",
            "Epoch 689/1000, Ridge Training Loss: 65.9787, Ridge Test MSE: 49.8793\n",
            "Epoch 690/1000, Ridge Training Loss: 65.9335, Ridge Test MSE: 49.8678\n",
            "Epoch 691/1000, Ridge Training Loss: 65.8886, Ridge Test MSE: 49.8564\n",
            "Epoch 692/1000, Ridge Training Loss: 65.8439, Ridge Test MSE: 49.8453\n",
            "Epoch 693/1000, Ridge Training Loss: 65.7994, Ridge Test MSE: 49.8344\n",
            "Epoch 694/1000, Ridge Training Loss: 65.7552, Ridge Test MSE: 49.8236\n",
            "Epoch 695/1000, Ridge Training Loss: 65.7113, Ridge Test MSE: 49.8130\n",
            "Epoch 696/1000, Ridge Training Loss: 65.6676, Ridge Test MSE: 49.8026\n",
            "Epoch 697/1000, Ridge Training Loss: 65.6241, Ridge Test MSE: 49.7924\n",
            "Epoch 698/1000, Ridge Training Loss: 65.5809, Ridge Test MSE: 49.7824\n",
            "Epoch 699/1000, Ridge Training Loss: 65.5379, Ridge Test MSE: 49.7726\n",
            "Epoch 700/1000, Ridge Training Loss: 65.4951, Ridge Test MSE: 49.7629\n",
            "Epoch 701/1000, Ridge Training Loss: 65.4526, Ridge Test MSE: 49.7535\n",
            "Epoch 702/1000, Ridge Training Loss: 65.4103, Ridge Test MSE: 49.7441\n",
            "Epoch 703/1000, Ridge Training Loss: 65.3683, Ridge Test MSE: 49.7350\n",
            "Epoch 704/1000, Ridge Training Loss: 65.3265, Ridge Test MSE: 49.7261\n",
            "Epoch 705/1000, Ridge Training Loss: 65.2849, Ridge Test MSE: 49.7173\n",
            "Epoch 706/1000, Ridge Training Loss: 65.2435, Ridge Test MSE: 49.7086\n",
            "Epoch 707/1000, Ridge Training Loss: 65.2023, Ridge Test MSE: 49.7002\n",
            "Epoch 708/1000, Ridge Training Loss: 65.1614, Ridge Test MSE: 49.6919\n",
            "Epoch 709/1000, Ridge Training Loss: 65.1207, Ridge Test MSE: 49.6838\n",
            "Epoch 710/1000, Ridge Training Loss: 65.0802, Ridge Test MSE: 49.6758\n",
            "Epoch 711/1000, Ridge Training Loss: 65.0400, Ridge Test MSE: 49.6680\n",
            "Epoch 712/1000, Ridge Training Loss: 64.9999, Ridge Test MSE: 49.6604\n",
            "Epoch 713/1000, Ridge Training Loss: 64.9601, Ridge Test MSE: 49.6529\n",
            "Epoch 714/1000, Ridge Training Loss: 64.9205, Ridge Test MSE: 49.6456\n",
            "Epoch 715/1000, Ridge Training Loss: 64.8811, Ridge Test MSE: 49.6384\n",
            "Epoch 716/1000, Ridge Training Loss: 64.8419, Ridge Test MSE: 49.6314\n",
            "Epoch 717/1000, Ridge Training Loss: 64.8029, Ridge Test MSE: 49.6246\n",
            "Epoch 718/1000, Ridge Training Loss: 64.7641, Ridge Test MSE: 49.6179\n",
            "Epoch 719/1000, Ridge Training Loss: 64.7255, Ridge Test MSE: 49.6113\n",
            "Epoch 720/1000, Ridge Training Loss: 64.6872, Ridge Test MSE: 49.6049\n",
            "Epoch 721/1000, Ridge Training Loss: 64.6490, Ridge Test MSE: 49.5986\n",
            "Epoch 722/1000, Ridge Training Loss: 64.6111, Ridge Test MSE: 49.5925\n",
            "Epoch 723/1000, Ridge Training Loss: 64.5733, Ridge Test MSE: 49.5865\n",
            "Epoch 724/1000, Ridge Training Loss: 64.5357, Ridge Test MSE: 49.5807\n",
            "Epoch 725/1000, Ridge Training Loss: 64.4984, Ridge Test MSE: 49.5750\n",
            "Epoch 726/1000, Ridge Training Loss: 64.4612, Ridge Test MSE: 49.5694\n",
            "Epoch 727/1000, Ridge Training Loss: 64.4243, Ridge Test MSE: 49.5640\n",
            "Epoch 728/1000, Ridge Training Loss: 64.3875, Ridge Test MSE: 49.5588\n",
            "Epoch 729/1000, Ridge Training Loss: 64.3509, Ridge Test MSE: 49.5536\n",
            "Epoch 730/1000, Ridge Training Loss: 64.3145, Ridge Test MSE: 49.5486\n",
            "Epoch 731/1000, Ridge Training Loss: 64.2783, Ridge Test MSE: 49.5437\n",
            "Epoch 732/1000, Ridge Training Loss: 64.2423, Ridge Test MSE: 49.5390\n",
            "Epoch 733/1000, Ridge Training Loss: 64.2065, Ridge Test MSE: 49.5344\n",
            "Epoch 734/1000, Ridge Training Loss: 64.1709, Ridge Test MSE: 49.5299\n",
            "Epoch 735/1000, Ridge Training Loss: 64.1354, Ridge Test MSE: 49.5256\n",
            "Epoch 736/1000, Ridge Training Loss: 64.1001, Ridge Test MSE: 49.5213\n",
            "Epoch 737/1000, Ridge Training Loss: 64.0651, Ridge Test MSE: 49.5172\n",
            "Epoch 738/1000, Ridge Training Loss: 64.0302, Ridge Test MSE: 49.5133\n",
            "Epoch 739/1000, Ridge Training Loss: 63.9954, Ridge Test MSE: 49.5094\n",
            "Epoch 740/1000, Ridge Training Loss: 63.9609, Ridge Test MSE: 49.5057\n",
            "Epoch 741/1000, Ridge Training Loss: 63.9265, Ridge Test MSE: 49.5021\n",
            "Epoch 742/1000, Ridge Training Loss: 63.8923, Ridge Test MSE: 49.4986\n",
            "Epoch 743/1000, Ridge Training Loss: 63.8583, Ridge Test MSE: 49.4952\n",
            "Epoch 744/1000, Ridge Training Loss: 63.8245, Ridge Test MSE: 49.4920\n",
            "Epoch 745/1000, Ridge Training Loss: 63.7908, Ridge Test MSE: 49.4888\n",
            "Epoch 746/1000, Ridge Training Loss: 63.7573, Ridge Test MSE: 49.4858\n",
            "Epoch 747/1000, Ridge Training Loss: 63.7240, Ridge Test MSE: 49.4829\n",
            "Epoch 748/1000, Ridge Training Loss: 63.6909, Ridge Test MSE: 49.4801\n",
            "Epoch 749/1000, Ridge Training Loss: 63.6579, Ridge Test MSE: 49.4774\n",
            "Epoch 750/1000, Ridge Training Loss: 63.6251, Ridge Test MSE: 49.4748\n",
            "Epoch 751/1000, Ridge Training Loss: 63.5924, Ridge Test MSE: 49.4724\n",
            "Epoch 752/1000, Ridge Training Loss: 63.5599, Ridge Test MSE: 49.4700\n",
            "Epoch 753/1000, Ridge Training Loss: 63.5276, Ridge Test MSE: 49.4678\n",
            "Epoch 754/1000, Ridge Training Loss: 63.4955, Ridge Test MSE: 49.4657\n",
            "Epoch 755/1000, Ridge Training Loss: 63.4635, Ridge Test MSE: 49.4636\n",
            "Epoch 756/1000, Ridge Training Loss: 63.4316, Ridge Test MSE: 49.4617\n",
            "Epoch 757/1000, Ridge Training Loss: 63.4000, Ridge Test MSE: 49.4599\n",
            "Epoch 758/1000, Ridge Training Loss: 63.3684, Ridge Test MSE: 49.4581\n",
            "Epoch 759/1000, Ridge Training Loss: 63.3371, Ridge Test MSE: 49.4565\n",
            "Epoch 760/1000, Ridge Training Loss: 63.3059, Ridge Test MSE: 49.4550\n",
            "Epoch 761/1000, Ridge Training Loss: 63.2748, Ridge Test MSE: 49.4536\n",
            "Epoch 762/1000, Ridge Training Loss: 63.2439, Ridge Test MSE: 49.4523\n",
            "Epoch 763/1000, Ridge Training Loss: 63.2132, Ridge Test MSE: 49.4510\n",
            "Epoch 764/1000, Ridge Training Loss: 63.1826, Ridge Test MSE: 49.4499\n",
            "Epoch 765/1000, Ridge Training Loss: 63.1522, Ridge Test MSE: 49.4489\n",
            "Epoch 766/1000, Ridge Training Loss: 63.1219, Ridge Test MSE: 49.4479\n",
            "Epoch 767/1000, Ridge Training Loss: 63.0917, Ridge Test MSE: 49.4471\n",
            "Epoch 768/1000, Ridge Training Loss: 63.0617, Ridge Test MSE: 49.4463\n",
            "Epoch 769/1000, Ridge Training Loss: 63.0319, Ridge Test MSE: 49.4457\n",
            "Epoch 770/1000, Ridge Training Loss: 63.0022, Ridge Test MSE: 49.4451\n",
            "Epoch 771/1000, Ridge Training Loss: 62.9727, Ridge Test MSE: 49.4446\n",
            "Epoch 772/1000, Ridge Training Loss: 62.9432, Ridge Test MSE: 49.4442\n",
            "Epoch 773/1000, Ridge Training Loss: 62.9140, Ridge Test MSE: 49.4439\n",
            "Epoch 774/1000, Ridge Training Loss: 62.8849, Ridge Test MSE: 49.4437\n",
            "Epoch 775/1000, Ridge Training Loss: 62.8559, Ridge Test MSE: 49.4435\n",
            "Epoch 776/1000, Ridge Training Loss: 62.8271, Ridge Test MSE: 49.4435\n",
            "Epoch 777/1000, Ridge Training Loss: 62.7984, Ridge Test MSE: 49.4435\n",
            "Epoch 778/1000, Ridge Training Loss: 62.7698, Ridge Test MSE: 49.4436\n",
            "Epoch 779/1000, Ridge Training Loss: 62.7414, Ridge Test MSE: 49.4438\n",
            "Epoch 780/1000, Ridge Training Loss: 62.7131, Ridge Test MSE: 49.4441\n",
            "Epoch 781/1000, Ridge Training Loss: 62.6849, Ridge Test MSE: 49.4445\n",
            "Epoch 782/1000, Ridge Training Loss: 62.6569, Ridge Test MSE: 49.4449\n",
            "Epoch 783/1000, Ridge Training Loss: 62.6291, Ridge Test MSE: 49.4454\n",
            "Epoch 784/1000, Ridge Training Loss: 62.6013, Ridge Test MSE: 49.4460\n",
            "Epoch 785/1000, Ridge Training Loss: 62.5737, Ridge Test MSE: 49.4467\n",
            "Epoch 786/1000, Ridge Training Loss: 62.5462, Ridge Test MSE: 49.4475\n",
            "Epoch 787/1000, Ridge Training Loss: 62.5189, Ridge Test MSE: 49.4483\n",
            "Epoch 788/1000, Ridge Training Loss: 62.4916, Ridge Test MSE: 49.4492\n",
            "Epoch 789/1000, Ridge Training Loss: 62.4645, Ridge Test MSE: 49.4502\n",
            "Epoch 790/1000, Ridge Training Loss: 62.4376, Ridge Test MSE: 49.4512\n",
            "Epoch 791/1000, Ridge Training Loss: 62.4108, Ridge Test MSE: 49.4524\n",
            "Epoch 792/1000, Ridge Training Loss: 62.3840, Ridge Test MSE: 49.4536\n",
            "Epoch 793/1000, Ridge Training Loss: 62.3575, Ridge Test MSE: 49.4548\n",
            "Epoch 794/1000, Ridge Training Loss: 62.3310, Ridge Test MSE: 49.4562\n",
            "Epoch 795/1000, Ridge Training Loss: 62.3047, Ridge Test MSE: 49.4576\n",
            "Epoch 796/1000, Ridge Training Loss: 62.2785, Ridge Test MSE: 49.4591\n",
            "Epoch 797/1000, Ridge Training Loss: 62.2524, Ridge Test MSE: 49.4606\n",
            "Epoch 798/1000, Ridge Training Loss: 62.2264, Ridge Test MSE: 49.4622\n",
            "Epoch 799/1000, Ridge Training Loss: 62.2006, Ridge Test MSE: 49.4639\n",
            "Epoch 800/1000, Ridge Training Loss: 62.1748, Ridge Test MSE: 49.4656\n",
            "Epoch 801/1000, Ridge Training Loss: 62.1492, Ridge Test MSE: 49.4674\n",
            "Epoch 802/1000, Ridge Training Loss: 62.1237, Ridge Test MSE: 49.4693\n",
            "Epoch 803/1000, Ridge Training Loss: 62.0984, Ridge Test MSE: 49.4713\n",
            "Epoch 804/1000, Ridge Training Loss: 62.0731, Ridge Test MSE: 49.4733\n",
            "Epoch 805/1000, Ridge Training Loss: 62.0480, Ridge Test MSE: 49.4753\n",
            "Epoch 806/1000, Ridge Training Loss: 62.0230, Ridge Test MSE: 49.4774\n",
            "Epoch 807/1000, Ridge Training Loss: 61.9981, Ridge Test MSE: 49.4796\n",
            "Epoch 808/1000, Ridge Training Loss: 61.9733, Ridge Test MSE: 49.4819\n",
            "Epoch 809/1000, Ridge Training Loss: 61.9486, Ridge Test MSE: 49.4842\n",
            "Epoch 810/1000, Ridge Training Loss: 61.9240, Ridge Test MSE: 49.4865\n",
            "Epoch 811/1000, Ridge Training Loss: 61.8996, Ridge Test MSE: 49.4890\n",
            "Epoch 812/1000, Ridge Training Loss: 61.8752, Ridge Test MSE: 49.4914\n",
            "Epoch 813/1000, Ridge Training Loss: 61.8510, Ridge Test MSE: 49.4940\n",
            "Epoch 814/1000, Ridge Training Loss: 61.8269, Ridge Test MSE: 49.4966\n",
            "Epoch 815/1000, Ridge Training Loss: 61.8029, Ridge Test MSE: 49.4992\n",
            "Epoch 816/1000, Ridge Training Loss: 61.7790, Ridge Test MSE: 49.5019\n",
            "Epoch 817/1000, Ridge Training Loss: 61.7552, Ridge Test MSE: 49.5047\n",
            "Epoch 818/1000, Ridge Training Loss: 61.7315, Ridge Test MSE: 49.5075\n",
            "Epoch 819/1000, Ridge Training Loss: 61.7079, Ridge Test MSE: 49.5103\n",
            "Epoch 820/1000, Ridge Training Loss: 61.6844, Ridge Test MSE: 49.5133\n",
            "Epoch 821/1000, Ridge Training Loss: 61.6611, Ridge Test MSE: 49.5162\n",
            "Epoch 822/1000, Ridge Training Loss: 61.6378, Ridge Test MSE: 49.5192\n",
            "Epoch 823/1000, Ridge Training Loss: 61.6146, Ridge Test MSE: 49.5223\n",
            "Epoch 824/1000, Ridge Training Loss: 61.5916, Ridge Test MSE: 49.5254\n",
            "Epoch 825/1000, Ridge Training Loss: 61.5686, Ridge Test MSE: 49.5286\n",
            "Epoch 826/1000, Ridge Training Loss: 61.5458, Ridge Test MSE: 49.5318\n",
            "Epoch 827/1000, Ridge Training Loss: 61.5230, Ridge Test MSE: 49.5351\n",
            "Epoch 828/1000, Ridge Training Loss: 61.5004, Ridge Test MSE: 49.5384\n",
            "Epoch 829/1000, Ridge Training Loss: 61.4778, Ridge Test MSE: 49.5418\n",
            "Epoch 830/1000, Ridge Training Loss: 61.4554, Ridge Test MSE: 49.5452\n",
            "Epoch 831/1000, Ridge Training Loss: 61.4330, Ridge Test MSE: 49.5486\n",
            "Epoch 832/1000, Ridge Training Loss: 61.4108, Ridge Test MSE: 49.5521\n",
            "Epoch 833/1000, Ridge Training Loss: 61.3886, Ridge Test MSE: 49.5557\n",
            "Epoch 834/1000, Ridge Training Loss: 61.3665, Ridge Test MSE: 49.5592\n",
            "Epoch 835/1000, Ridge Training Loss: 61.3446, Ridge Test MSE: 49.5629\n",
            "Epoch 836/1000, Ridge Training Loss: 61.3227, Ridge Test MSE: 49.5666\n",
            "Epoch 837/1000, Ridge Training Loss: 61.3009, Ridge Test MSE: 49.5703\n",
            "Epoch 838/1000, Ridge Training Loss: 61.2792, Ridge Test MSE: 49.5740\n",
            "Epoch 839/1000, Ridge Training Loss: 61.2576, Ridge Test MSE: 49.5778\n",
            "Epoch 840/1000, Ridge Training Loss: 61.2361, Ridge Test MSE: 49.5817\n",
            "Epoch 841/1000, Ridge Training Loss: 61.2148, Ridge Test MSE: 49.5856\n",
            "Epoch 842/1000, Ridge Training Loss: 61.1934, Ridge Test MSE: 49.5895\n",
            "Epoch 843/1000, Ridge Training Loss: 61.1722, Ridge Test MSE: 49.5935\n",
            "Epoch 844/1000, Ridge Training Loss: 61.1511, Ridge Test MSE: 49.5975\n",
            "Epoch 845/1000, Ridge Training Loss: 61.1301, Ridge Test MSE: 49.6015\n",
            "Epoch 846/1000, Ridge Training Loss: 61.1091, Ridge Test MSE: 49.6056\n",
            "Epoch 847/1000, Ridge Training Loss: 61.0883, Ridge Test MSE: 49.6097\n",
            "Epoch 848/1000, Ridge Training Loss: 61.0675, Ridge Test MSE: 49.6139\n",
            "Epoch 849/1000, Ridge Training Loss: 61.0468, Ridge Test MSE: 49.6181\n",
            "Epoch 850/1000, Ridge Training Loss: 61.0262, Ridge Test MSE: 49.6223\n",
            "Epoch 851/1000, Ridge Training Loss: 61.0057, Ridge Test MSE: 49.6265\n",
            "Epoch 852/1000, Ridge Training Loss: 60.9853, Ridge Test MSE: 49.6308\n",
            "Epoch 853/1000, Ridge Training Loss: 60.9650, Ridge Test MSE: 49.6352\n",
            "Epoch 854/1000, Ridge Training Loss: 60.9447, Ridge Test MSE: 49.6395\n",
            "Epoch 855/1000, Ridge Training Loss: 60.9246, Ridge Test MSE: 49.6439\n",
            "Epoch 856/1000, Ridge Training Loss: 60.9045, Ridge Test MSE: 49.6484\n",
            "Epoch 857/1000, Ridge Training Loss: 60.8845, Ridge Test MSE: 49.6529\n",
            "Epoch 858/1000, Ridge Training Loss: 60.8646, Ridge Test MSE: 49.6573\n",
            "Epoch 859/1000, Ridge Training Loss: 60.8447, Ridge Test MSE: 49.6619\n",
            "Epoch 860/1000, Ridge Training Loss: 60.8250, Ridge Test MSE: 49.6664\n",
            "Epoch 861/1000, Ridge Training Loss: 60.8053, Ridge Test MSE: 49.6710\n",
            "Epoch 862/1000, Ridge Training Loss: 60.7858, Ridge Test MSE: 49.6757\n",
            "Epoch 863/1000, Ridge Training Loss: 60.7663, Ridge Test MSE: 49.6803\n",
            "Epoch 864/1000, Ridge Training Loss: 60.7468, Ridge Test MSE: 49.6850\n",
            "Epoch 865/1000, Ridge Training Loss: 60.7275, Ridge Test MSE: 49.6897\n",
            "Epoch 866/1000, Ridge Training Loss: 60.7082, Ridge Test MSE: 49.6945\n",
            "Epoch 867/1000, Ridge Training Loss: 60.6891, Ridge Test MSE: 49.6992\n",
            "Epoch 868/1000, Ridge Training Loss: 60.6699, Ridge Test MSE: 49.7040\n",
            "Epoch 869/1000, Ridge Training Loss: 60.6509, Ridge Test MSE: 49.7089\n",
            "Epoch 870/1000, Ridge Training Loss: 60.6320, Ridge Test MSE: 49.7137\n",
            "Epoch 871/1000, Ridge Training Loss: 60.6131, Ridge Test MSE: 49.7186\n",
            "Epoch 872/1000, Ridge Training Loss: 60.5943, Ridge Test MSE: 49.7235\n",
            "Epoch 873/1000, Ridge Training Loss: 60.5756, Ridge Test MSE: 49.7285\n",
            "Epoch 874/1000, Ridge Training Loss: 60.5569, Ridge Test MSE: 49.7334\n",
            "Epoch 875/1000, Ridge Training Loss: 60.5384, Ridge Test MSE: 49.7384\n",
            "Epoch 876/1000, Ridge Training Loss: 60.5199, Ridge Test MSE: 49.7434\n",
            "Epoch 877/1000, Ridge Training Loss: 60.5015, Ridge Test MSE: 49.7485\n",
            "Epoch 878/1000, Ridge Training Loss: 60.4831, Ridge Test MSE: 49.7535\n",
            "Epoch 879/1000, Ridge Training Loss: 60.4649, Ridge Test MSE: 49.7586\n",
            "Epoch 880/1000, Ridge Training Loss: 60.4467, Ridge Test MSE: 49.7637\n",
            "Epoch 881/1000, Ridge Training Loss: 60.4285, Ridge Test MSE: 49.7689\n",
            "Epoch 882/1000, Ridge Training Loss: 60.4105, Ridge Test MSE: 49.7740\n",
            "Epoch 883/1000, Ridge Training Loss: 60.3925, Ridge Test MSE: 49.7792\n",
            "Epoch 884/1000, Ridge Training Loss: 60.3746, Ridge Test MSE: 49.7844\n",
            "Epoch 885/1000, Ridge Training Loss: 60.3567, Ridge Test MSE: 49.7896\n",
            "Epoch 886/1000, Ridge Training Loss: 60.3390, Ridge Test MSE: 49.7948\n",
            "Epoch 887/1000, Ridge Training Loss: 60.3213, Ridge Test MSE: 49.8001\n",
            "Epoch 888/1000, Ridge Training Loss: 60.3036, Ridge Test MSE: 49.8054\n",
            "Epoch 889/1000, Ridge Training Loss: 60.2861, Ridge Test MSE: 49.8107\n",
            "Epoch 890/1000, Ridge Training Loss: 60.2686, Ridge Test MSE: 49.8160\n",
            "Epoch 891/1000, Ridge Training Loss: 60.2512, Ridge Test MSE: 49.8214\n",
            "Epoch 892/1000, Ridge Training Loss: 60.2338, Ridge Test MSE: 49.8267\n",
            "Epoch 893/1000, Ridge Training Loss: 60.2165, Ridge Test MSE: 49.8321\n",
            "Epoch 894/1000, Ridge Training Loss: 60.1993, Ridge Test MSE: 49.8375\n",
            "Epoch 895/1000, Ridge Training Loss: 60.1822, Ridge Test MSE: 49.8429\n",
            "Epoch 896/1000, Ridge Training Loss: 60.1651, Ridge Test MSE: 49.8484\n",
            "Epoch 897/1000, Ridge Training Loss: 60.1480, Ridge Test MSE: 49.8538\n",
            "Epoch 898/1000, Ridge Training Loss: 60.1311, Ridge Test MSE: 49.8593\n",
            "Epoch 899/1000, Ridge Training Loss: 60.1142, Ridge Test MSE: 49.8648\n",
            "Epoch 900/1000, Ridge Training Loss: 60.0974, Ridge Test MSE: 49.8703\n",
            "Epoch 901/1000, Ridge Training Loss: 60.0806, Ridge Test MSE: 49.8758\n",
            "Epoch 902/1000, Ridge Training Loss: 60.0639, Ridge Test MSE: 49.8814\n",
            "Epoch 903/1000, Ridge Training Loss: 60.0473, Ridge Test MSE: 49.8869\n",
            "Epoch 904/1000, Ridge Training Loss: 60.0307, Ridge Test MSE: 49.8925\n",
            "Epoch 905/1000, Ridge Training Loss: 60.0142, Ridge Test MSE: 49.8981\n",
            "Epoch 906/1000, Ridge Training Loss: 59.9977, Ridge Test MSE: 49.9037\n",
            "Epoch 907/1000, Ridge Training Loss: 59.9813, Ridge Test MSE: 49.9093\n",
            "Epoch 908/1000, Ridge Training Loss: 59.9650, Ridge Test MSE: 49.9149\n",
            "Epoch 909/1000, Ridge Training Loss: 59.9488, Ridge Test MSE: 49.9205\n",
            "Epoch 910/1000, Ridge Training Loss: 59.9325, Ridge Test MSE: 49.9262\n",
            "Epoch 911/1000, Ridge Training Loss: 59.9164, Ridge Test MSE: 49.9319\n",
            "Epoch 912/1000, Ridge Training Loss: 59.9003, Ridge Test MSE: 49.9376\n",
            "Epoch 913/1000, Ridge Training Loss: 59.8843, Ridge Test MSE: 49.9432\n",
            "Epoch 914/1000, Ridge Training Loss: 59.8684, Ridge Test MSE: 49.9490\n",
            "Epoch 915/1000, Ridge Training Loss: 59.8525, Ridge Test MSE: 49.9547\n",
            "Epoch 916/1000, Ridge Training Loss: 59.8366, Ridge Test MSE: 49.9604\n",
            "Epoch 917/1000, Ridge Training Loss: 59.8208, Ridge Test MSE: 49.9661\n",
            "Epoch 918/1000, Ridge Training Loss: 59.8051, Ridge Test MSE: 49.9719\n",
            "Epoch 919/1000, Ridge Training Loss: 59.7894, Ridge Test MSE: 49.9776\n",
            "Epoch 920/1000, Ridge Training Loss: 59.7738, Ridge Test MSE: 49.9834\n",
            "Epoch 921/1000, Ridge Training Loss: 59.7583, Ridge Test MSE: 49.9892\n",
            "Epoch 922/1000, Ridge Training Loss: 59.7428, Ridge Test MSE: 49.9950\n",
            "Epoch 923/1000, Ridge Training Loss: 59.7273, Ridge Test MSE: 50.0008\n",
            "Epoch 924/1000, Ridge Training Loss: 59.7119, Ridge Test MSE: 50.0066\n",
            "Epoch 925/1000, Ridge Training Loss: 59.6966, Ridge Test MSE: 50.0125\n",
            "Epoch 926/1000, Ridge Training Loss: 59.6813, Ridge Test MSE: 50.0183\n",
            "Epoch 927/1000, Ridge Training Loss: 59.6661, Ridge Test MSE: 50.0241\n",
            "Epoch 928/1000, Ridge Training Loss: 59.6509, Ridge Test MSE: 50.0300\n",
            "Epoch 929/1000, Ridge Training Loss: 59.6358, Ridge Test MSE: 50.0359\n",
            "Epoch 930/1000, Ridge Training Loss: 59.6208, Ridge Test MSE: 50.0417\n",
            "Epoch 931/1000, Ridge Training Loss: 59.6058, Ridge Test MSE: 50.0476\n",
            "Epoch 932/1000, Ridge Training Loss: 59.5908, Ridge Test MSE: 50.0535\n",
            "Epoch 933/1000, Ridge Training Loss: 59.5759, Ridge Test MSE: 50.0594\n",
            "Epoch 934/1000, Ridge Training Loss: 59.5611, Ridge Test MSE: 50.0653\n",
            "Epoch 935/1000, Ridge Training Loss: 59.5463, Ridge Test MSE: 50.0712\n",
            "Epoch 936/1000, Ridge Training Loss: 59.5316, Ridge Test MSE: 50.0771\n",
            "Epoch 937/1000, Ridge Training Loss: 59.5169, Ridge Test MSE: 50.0830\n",
            "Epoch 938/1000, Ridge Training Loss: 59.5023, Ridge Test MSE: 50.0890\n",
            "Epoch 939/1000, Ridge Training Loss: 59.4877, Ridge Test MSE: 50.0949\n",
            "Epoch 940/1000, Ridge Training Loss: 59.4731, Ridge Test MSE: 50.1008\n",
            "Epoch 941/1000, Ridge Training Loss: 59.4587, Ridge Test MSE: 50.1068\n",
            "Epoch 942/1000, Ridge Training Loss: 59.4442, Ridge Test MSE: 50.1127\n",
            "Epoch 943/1000, Ridge Training Loss: 59.4299, Ridge Test MSE: 50.1187\n",
            "Epoch 944/1000, Ridge Training Loss: 59.4155, Ridge Test MSE: 50.1246\n",
            "Epoch 945/1000, Ridge Training Loss: 59.4012, Ridge Test MSE: 50.1306\n",
            "Epoch 946/1000, Ridge Training Loss: 59.3870, Ridge Test MSE: 50.1366\n",
            "Epoch 947/1000, Ridge Training Loss: 59.3728, Ridge Test MSE: 50.1425\n",
            "Epoch 948/1000, Ridge Training Loss: 59.3587, Ridge Test MSE: 50.1485\n",
            "Epoch 949/1000, Ridge Training Loss: 59.3446, Ridge Test MSE: 50.1545\n",
            "Epoch 950/1000, Ridge Training Loss: 59.3306, Ridge Test MSE: 50.1605\n",
            "Epoch 951/1000, Ridge Training Loss: 59.3166, Ridge Test MSE: 50.1665\n",
            "Epoch 952/1000, Ridge Training Loss: 59.3027, Ridge Test MSE: 50.1725\n",
            "Epoch 953/1000, Ridge Training Loss: 59.2888, Ridge Test MSE: 50.1785\n",
            "Epoch 954/1000, Ridge Training Loss: 59.2749, Ridge Test MSE: 50.1845\n",
            "Epoch 955/1000, Ridge Training Loss: 59.2611, Ridge Test MSE: 50.1905\n",
            "Epoch 956/1000, Ridge Training Loss: 59.2474, Ridge Test MSE: 50.1965\n",
            "Epoch 957/1000, Ridge Training Loss: 59.2337, Ridge Test MSE: 50.2025\n",
            "Epoch 958/1000, Ridge Training Loss: 59.2200, Ridge Test MSE: 50.2085\n",
            "Epoch 959/1000, Ridge Training Loss: 59.2064, Ridge Test MSE: 50.2145\n",
            "Epoch 960/1000, Ridge Training Loss: 59.1928, Ridge Test MSE: 50.2205\n",
            "Epoch 961/1000, Ridge Training Loss: 59.1793, Ridge Test MSE: 50.2265\n",
            "Epoch 962/1000, Ridge Training Loss: 59.1658, Ridge Test MSE: 50.2326\n",
            "Epoch 963/1000, Ridge Training Loss: 59.1524, Ridge Test MSE: 50.2386\n",
            "Epoch 964/1000, Ridge Training Loss: 59.1390, Ridge Test MSE: 50.2446\n",
            "Epoch 965/1000, Ridge Training Loss: 59.1256, Ridge Test MSE: 50.2506\n",
            "Epoch 966/1000, Ridge Training Loss: 59.1123, Ridge Test MSE: 50.2566\n",
            "Epoch 967/1000, Ridge Training Loss: 59.0991, Ridge Test MSE: 50.2626\n",
            "Epoch 968/1000, Ridge Training Loss: 59.0859, Ridge Test MSE: 50.2687\n",
            "Epoch 969/1000, Ridge Training Loss: 59.0727, Ridge Test MSE: 50.2747\n",
            "Epoch 970/1000, Ridge Training Loss: 59.0596, Ridge Test MSE: 50.2807\n",
            "Epoch 971/1000, Ridge Training Loss: 59.0465, Ridge Test MSE: 50.2867\n",
            "Epoch 972/1000, Ridge Training Loss: 59.0334, Ridge Test MSE: 50.2927\n",
            "Epoch 973/1000, Ridge Training Loss: 59.0204, Ridge Test MSE: 50.2988\n",
            "Epoch 974/1000, Ridge Training Loss: 59.0075, Ridge Test MSE: 50.3048\n",
            "Epoch 975/1000, Ridge Training Loss: 58.9945, Ridge Test MSE: 50.3108\n",
            "Epoch 976/1000, Ridge Training Loss: 58.9817, Ridge Test MSE: 50.3168\n",
            "Epoch 977/1000, Ridge Training Loss: 58.9688, Ridge Test MSE: 50.3228\n",
            "Epoch 978/1000, Ridge Training Loss: 58.9560, Ridge Test MSE: 50.3288\n",
            "Epoch 979/1000, Ridge Training Loss: 58.9433, Ridge Test MSE: 50.3348\n",
            "Epoch 980/1000, Ridge Training Loss: 58.9306, Ridge Test MSE: 50.3409\n",
            "Epoch 981/1000, Ridge Training Loss: 58.9179, Ridge Test MSE: 50.3469\n",
            "Epoch 982/1000, Ridge Training Loss: 58.9053, Ridge Test MSE: 50.3529\n",
            "Epoch 983/1000, Ridge Training Loss: 58.8927, Ridge Test MSE: 50.3589\n",
            "Epoch 984/1000, Ridge Training Loss: 58.8801, Ridge Test MSE: 50.3649\n",
            "Epoch 985/1000, Ridge Training Loss: 58.8676, Ridge Test MSE: 50.3709\n",
            "Epoch 986/1000, Ridge Training Loss: 58.8551, Ridge Test MSE: 50.3769\n",
            "Epoch 987/1000, Ridge Training Loss: 58.8427, Ridge Test MSE: 50.3829\n",
            "Epoch 988/1000, Ridge Training Loss: 58.8303, Ridge Test MSE: 50.3889\n",
            "Epoch 989/1000, Ridge Training Loss: 58.8179, Ridge Test MSE: 50.3948\n",
            "Epoch 990/1000, Ridge Training Loss: 58.8056, Ridge Test MSE: 50.4008\n",
            "Epoch 991/1000, Ridge Training Loss: 58.7933, Ridge Test MSE: 50.4068\n",
            "Epoch 992/1000, Ridge Training Loss: 58.7811, Ridge Test MSE: 50.4128\n",
            "Epoch 993/1000, Ridge Training Loss: 58.7689, Ridge Test MSE: 50.4188\n",
            "Epoch 994/1000, Ridge Training Loss: 58.7567, Ridge Test MSE: 50.4247\n",
            "Epoch 995/1000, Ridge Training Loss: 58.7446, Ridge Test MSE: 50.4307\n",
            "Epoch 996/1000, Ridge Training Loss: 58.7325, Ridge Test MSE: 50.4367\n",
            "Epoch 997/1000, Ridge Training Loss: 58.7204, Ridge Test MSE: 50.4426\n",
            "Epoch 998/1000, Ridge Training Loss: 58.7084, Ridge Test MSE: 50.4486\n",
            "Epoch 999/1000, Ridge Training Loss: 58.6964, Ridge Test MSE: 50.4545\n",
            "Epoch 1000/1000, Ridge Training Loss: 58.6844, Ridge Test MSE: 50.4605\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 1000\n",
        "learning_rate = 0.0003\n",
        "\n",
        "class Ridge(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super().__init__()\n",
        "        ## Write your answer here\n",
        "        self.layer = nn.Linear(input_dim, 1)\n",
        "\n",
        "    def forward(self, X):\n",
        "        ## Write your answer here\n",
        "        pred = self.layer(X)\n",
        "        return pred\n",
        "\n",
        "\n",
        "class Lasso(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super().__init__()\n",
        "        ## Write your answer here\n",
        "        self.layer = nn.Linear(input_dim, 1)\n",
        "\n",
        "    def forward(self, X):\n",
        "        ## Write your answer here\n",
        "        pred = self.layer(X)\n",
        "        return pred\n",
        "\n",
        "\n",
        "## Write your answer here (Training code)\n",
        "\n",
        "ridge_lambda = 0.1\n",
        "# Training setup\n",
        "input_dim = X_train.shape[1]\n",
        "ridge_model = Ridge(input_dim)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(ridge_model.parameters(), lr=learning_rate)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "  y_pred = ridge_model(X_train)\n",
        "  mse_loss = criterion(y_pred, y_train)\n",
        "\n",
        "        # (L2 norm squared) loss\n",
        "  ridge_loss = sum(torch.norm(param, 2)**2 for name, param in ridge_model.named_parameters() if 'weight' in name)\n",
        "\n",
        "        # Combine MSE loss and Ridge loss\n",
        "  total_loss = mse_loss + ridge_lambda * ridge_loss\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  total_loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "\n",
        "  ridge_model.eval()\n",
        "  with torch.no_grad():\n",
        "    y_test_pred = ridge_model(X_test)\n",
        "    test_loss = criterion(y_test_pred, y_test)\n",
        "   # test_mse.append(test_loss.item())\n",
        "\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}, Ridge Training Loss: {total_loss.item():.4f}, Ridge Test MSE: {test_loss.item():.4f}')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lasso_lambda = 0.1\n",
        "# Training setup\n",
        "input_dim = X_train.shape[1]\n",
        "lasso_model = Ridge(input_dim)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(lasso_model.parameters(), lr=learning_rate)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "  y_pred = lasso_model(X_train)\n",
        "  lasso_mse_loss = criterion(y_pred, y_train)\n",
        "\n",
        "        # (L1 norm squared) loss\n",
        "  lasso_loss = sum(torch.norm(param, 1) for name, param in ridge_model.named_parameters() if 'weight' in name)\n",
        "\n",
        "        # Combine MSE loss and lasso loss\n",
        "  total_loss = lasso_mse_loss + lasso_lambda * lasso_loss\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  total_loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "\n",
        "  lasso_model.eval()\n",
        "  with torch.no_grad():\n",
        "    y_test_pred1 = lasso_model(X_test)\n",
        "    lasso_test_loss = criterion(y_test_pred1, y_test)\n",
        "\n",
        "\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}, Lasso Training Loss: {total_loss.item():.4f}, Lasso Test MSE: {lasso_test_loss.item():.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pIGB7iWOt2Jo",
        "outputId": "f7d58b5e-57c6-4ad7-c51f-eefc66392f17"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000, Lasso Training Loss: 4185.4033, Lasso Test MSE: 4666.4141\n",
            "Epoch 2/1000, Lasso Training Loss: 4157.4219, Lasso Test MSE: 4635.4517\n",
            "Epoch 3/1000, Lasso Training Loss: 4129.5991, Lasso Test MSE: 4604.6582\n",
            "Epoch 4/1000, Lasso Training Loss: 4101.9360, Lasso Test MSE: 4574.0386\n",
            "Epoch 5/1000, Lasso Training Loss: 4074.4358, Lasso Test MSE: 4543.5938\n",
            "Epoch 6/1000, Lasso Training Loss: 4047.1018, Lasso Test MSE: 4513.3281\n",
            "Epoch 7/1000, Lasso Training Loss: 4019.9353, Lasso Test MSE: 4483.2422\n",
            "Epoch 8/1000, Lasso Training Loss: 3992.9380, Lasso Test MSE: 4453.3418\n",
            "Epoch 9/1000, Lasso Training Loss: 3966.1140, Lasso Test MSE: 4423.6260\n",
            "Epoch 10/1000, Lasso Training Loss: 3939.4644, Lasso Test MSE: 4394.0991\n",
            "Epoch 11/1000, Lasso Training Loss: 3912.9929, Lasso Test MSE: 4364.7637\n",
            "Epoch 12/1000, Lasso Training Loss: 3886.6992, Lasso Test MSE: 4335.6221\n",
            "Epoch 13/1000, Lasso Training Loss: 3860.5874, Lasso Test MSE: 4306.6738\n",
            "Epoch 14/1000, Lasso Training Loss: 3834.6580, Lasso Test MSE: 4277.9243\n",
            "Epoch 15/1000, Lasso Training Loss: 3808.9136, Lasso Test MSE: 4249.3730\n",
            "Epoch 16/1000, Lasso Training Loss: 3783.3547, Lasso Test MSE: 4221.0220\n",
            "Epoch 17/1000, Lasso Training Loss: 3757.9832, Lasso Test MSE: 4192.8735\n",
            "Epoch 18/1000, Lasso Training Loss: 3732.8010, Lasso Test MSE: 4164.9312\n",
            "Epoch 19/1000, Lasso Training Loss: 3707.8105, Lasso Test MSE: 4137.1904\n",
            "Epoch 20/1000, Lasso Training Loss: 3683.0103, Lasso Test MSE: 4109.6592\n",
            "Epoch 21/1000, Lasso Training Loss: 3658.4038, Lasso Test MSE: 4082.3337\n",
            "Epoch 22/1000, Lasso Training Loss: 3633.9905, Lasso Test MSE: 4055.2180\n",
            "Epoch 23/1000, Lasso Training Loss: 3609.7712, Lasso Test MSE: 4028.3125\n",
            "Epoch 24/1000, Lasso Training Loss: 3585.7488, Lasso Test MSE: 4001.6179\n",
            "Epoch 25/1000, Lasso Training Loss: 3561.9224, Lasso Test MSE: 3975.1326\n",
            "Epoch 26/1000, Lasso Training Loss: 3538.2922, Lasso Test MSE: 3948.8616\n",
            "Epoch 27/1000, Lasso Training Loss: 3514.8599, Lasso Test MSE: 3922.8020\n",
            "Epoch 28/1000, Lasso Training Loss: 3491.6255, Lasso Test MSE: 3896.9546\n",
            "Epoch 29/1000, Lasso Training Loss: 3468.5874, Lasso Test MSE: 3871.3206\n",
            "Epoch 30/1000, Lasso Training Loss: 3445.7483, Lasso Test MSE: 3845.8999\n",
            "Epoch 31/1000, Lasso Training Loss: 3423.1079, Lasso Test MSE: 3820.6931\n",
            "Epoch 32/1000, Lasso Training Loss: 3400.6658, Lasso Test MSE: 3795.6995\n",
            "Epoch 33/1000, Lasso Training Loss: 3378.4216, Lasso Test MSE: 3770.9197\n",
            "Epoch 34/1000, Lasso Training Loss: 3356.3755, Lasso Test MSE: 3746.3525\n",
            "Epoch 35/1000, Lasso Training Loss: 3334.5278, Lasso Test MSE: 3721.9990\n",
            "Epoch 36/1000, Lasso Training Loss: 3312.8779, Lasso Test MSE: 3697.8584\n",
            "Epoch 37/1000, Lasso Training Loss: 3291.4253, Lasso Test MSE: 3673.9294\n",
            "Epoch 38/1000, Lasso Training Loss: 3270.1692, Lasso Test MSE: 3650.2139\n",
            "Epoch 39/1000, Lasso Training Loss: 3249.1104, Lasso Test MSE: 3626.7083\n",
            "Epoch 40/1000, Lasso Training Loss: 3228.2466, Lasso Test MSE: 3603.4143\n",
            "Epoch 41/1000, Lasso Training Loss: 3207.5786, Lasso Test MSE: 3580.3306\n",
            "Epoch 42/1000, Lasso Training Loss: 3187.1062, Lasso Test MSE: 3557.4568\n",
            "Epoch 43/1000, Lasso Training Loss: 3166.8274, Lasso Test MSE: 3534.7920\n",
            "Epoch 44/1000, Lasso Training Loss: 3146.7412, Lasso Test MSE: 3512.3345\n",
            "Epoch 45/1000, Lasso Training Loss: 3126.8486, Lasso Test MSE: 3490.0854\n",
            "Epoch 46/1000, Lasso Training Loss: 3107.1475, Lasso Test MSE: 3468.0430\n",
            "Epoch 47/1000, Lasso Training Loss: 3087.6379, Lasso Test MSE: 3446.2053\n",
            "Epoch 48/1000, Lasso Training Loss: 3068.3176, Lasso Test MSE: 3424.5725\n",
            "Epoch 49/1000, Lasso Training Loss: 3049.1873, Lasso Test MSE: 3403.1443\n",
            "Epoch 50/1000, Lasso Training Loss: 3030.2451, Lasso Test MSE: 3381.9185\n",
            "Epoch 51/1000, Lasso Training Loss: 3011.4905, Lasso Test MSE: 3360.8953\n",
            "Epoch 52/1000, Lasso Training Loss: 2992.9214, Lasso Test MSE: 3340.0723\n",
            "Epoch 53/1000, Lasso Training Loss: 2974.5386, Lasso Test MSE: 3319.4473\n",
            "Epoch 54/1000, Lasso Training Loss: 2956.3384, Lasso Test MSE: 3299.0229\n",
            "Epoch 55/1000, Lasso Training Loss: 2938.3230, Lasso Test MSE: 3278.7954\n",
            "Epoch 56/1000, Lasso Training Loss: 2920.4888, Lasso Test MSE: 3258.7632\n",
            "Epoch 57/1000, Lasso Training Loss: 2902.8357, Lasso Test MSE: 3238.9275\n",
            "Epoch 58/1000, Lasso Training Loss: 2885.3625, Lasso Test MSE: 3219.2834\n",
            "Epoch 59/1000, Lasso Training Loss: 2868.0669, Lasso Test MSE: 3199.8340\n",
            "Epoch 60/1000, Lasso Training Loss: 2850.9502, Lasso Test MSE: 3180.5759\n",
            "Epoch 61/1000, Lasso Training Loss: 2834.0093, Lasso Test MSE: 3161.5068\n",
            "Epoch 62/1000, Lasso Training Loss: 2817.2432, Lasso Test MSE: 3142.6274\n",
            "Epoch 63/1000, Lasso Training Loss: 2800.6514, Lasso Test MSE: 3123.9351\n",
            "Epoch 64/1000, Lasso Training Loss: 2784.2317, Lasso Test MSE: 3105.4302\n",
            "Epoch 65/1000, Lasso Training Loss: 2767.9841, Lasso Test MSE: 3087.1101\n",
            "Epoch 66/1000, Lasso Training Loss: 2751.9062, Lasso Test MSE: 3068.9736\n",
            "Epoch 67/1000, Lasso Training Loss: 2735.9980, Lasso Test MSE: 3051.0203\n",
            "Epoch 68/1000, Lasso Training Loss: 2720.2573, Lasso Test MSE: 3033.2473\n",
            "Epoch 69/1000, Lasso Training Loss: 2704.6821, Lasso Test MSE: 3015.6548\n",
            "Epoch 70/1000, Lasso Training Loss: 2689.2734, Lasso Test MSE: 2998.2402\n",
            "Epoch 71/1000, Lasso Training Loss: 2674.0281, Lasso Test MSE: 2981.0027\n",
            "Epoch 72/1000, Lasso Training Loss: 2658.9453, Lasso Test MSE: 2963.9431\n",
            "Epoch 73/1000, Lasso Training Loss: 2644.0244, Lasso Test MSE: 2947.0564\n",
            "Epoch 74/1000, Lasso Training Loss: 2629.2637, Lasso Test MSE: 2930.3435\n",
            "Epoch 75/1000, Lasso Training Loss: 2614.6609, Lasso Test MSE: 2913.8015\n",
            "Epoch 76/1000, Lasso Training Loss: 2600.2158, Lasso Test MSE: 2897.4319\n",
            "Epoch 77/1000, Lasso Training Loss: 2585.9282, Lasso Test MSE: 2881.2305\n",
            "Epoch 78/1000, Lasso Training Loss: 2571.7944, Lasso Test MSE: 2865.1970\n",
            "Epoch 79/1000, Lasso Training Loss: 2557.8147, Lasso Test MSE: 2849.3306\n",
            "Epoch 80/1000, Lasso Training Loss: 2543.9883, Lasso Test MSE: 2833.6287\n",
            "Epoch 81/1000, Lasso Training Loss: 2530.3115, Lasso Test MSE: 2818.0903\n",
            "Epoch 82/1000, Lasso Training Loss: 2516.7852, Lasso Test MSE: 2802.7153\n",
            "Epoch 83/1000, Lasso Training Loss: 2503.4072, Lasso Test MSE: 2787.5022\n",
            "Epoch 84/1000, Lasso Training Loss: 2490.1775, Lasso Test MSE: 2772.4480\n",
            "Epoch 85/1000, Lasso Training Loss: 2477.0930, Lasso Test MSE: 2757.5520\n",
            "Epoch 86/1000, Lasso Training Loss: 2464.1528, Lasso Test MSE: 2742.8132\n",
            "Epoch 87/1000, Lasso Training Loss: 2451.3564, Lasso Test MSE: 2728.2300\n",
            "Epoch 88/1000, Lasso Training Loss: 2438.7019, Lasso Test MSE: 2713.8020\n",
            "Epoch 89/1000, Lasso Training Loss: 2426.1885, Lasso Test MSE: 2699.5254\n",
            "Epoch 90/1000, Lasso Training Loss: 2413.8140, Lasso Test MSE: 2685.4019\n",
            "Epoch 91/1000, Lasso Training Loss: 2401.5784, Lasso Test MSE: 2671.4287\n",
            "Epoch 92/1000, Lasso Training Loss: 2389.4795, Lasso Test MSE: 2657.6035\n",
            "Epoch 93/1000, Lasso Training Loss: 2377.5156, Lasso Test MSE: 2643.9263\n",
            "Epoch 94/1000, Lasso Training Loss: 2365.6863, Lasso Test MSE: 2630.3962\n",
            "Epoch 95/1000, Lasso Training Loss: 2353.9907, Lasso Test MSE: 2617.0100\n",
            "Epoch 96/1000, Lasso Training Loss: 2342.4263, Lasso Test MSE: 2603.7681\n",
            "Epoch 97/1000, Lasso Training Loss: 2330.9927, Lasso Test MSE: 2590.6685\n",
            "Epoch 98/1000, Lasso Training Loss: 2319.6887, Lasso Test MSE: 2577.7092\n",
            "Epoch 99/1000, Lasso Training Loss: 2308.5120, Lasso Test MSE: 2564.8899\n",
            "Epoch 100/1000, Lasso Training Loss: 2297.4622, Lasso Test MSE: 2552.2092\n",
            "Epoch 101/1000, Lasso Training Loss: 2286.5381, Lasso Test MSE: 2539.6653\n",
            "Epoch 102/1000, Lasso Training Loss: 2275.7380, Lasso Test MSE: 2527.2573\n",
            "Epoch 103/1000, Lasso Training Loss: 2265.0613, Lasso Test MSE: 2514.9827\n",
            "Epoch 104/1000, Lasso Training Loss: 2254.5054, Lasso Test MSE: 2502.8423\n",
            "Epoch 105/1000, Lasso Training Loss: 2244.0706, Lasso Test MSE: 2490.8328\n",
            "Epoch 106/1000, Lasso Training Loss: 2233.7544, Lasso Test MSE: 2478.9548\n",
            "Epoch 107/1000, Lasso Training Loss: 2223.5574, Lasso Test MSE: 2467.2051\n",
            "Epoch 108/1000, Lasso Training Loss: 2213.4761, Lasso Test MSE: 2455.5825\n",
            "Epoch 109/1000, Lasso Training Loss: 2203.5098, Lasso Test MSE: 2444.0869\n",
            "Epoch 110/1000, Lasso Training Loss: 2193.6582, Lasso Test MSE: 2432.7175\n",
            "Epoch 111/1000, Lasso Training Loss: 2183.9202, Lasso Test MSE: 2421.4717\n",
            "Epoch 112/1000, Lasso Training Loss: 2174.2937, Lasso Test MSE: 2410.3481\n",
            "Epoch 113/1000, Lasso Training Loss: 2164.7776, Lasso Test MSE: 2399.3452\n",
            "Epoch 114/1000, Lasso Training Loss: 2155.3706, Lasso Test MSE: 2388.4636\n",
            "Epoch 115/1000, Lasso Training Loss: 2146.0723, Lasso Test MSE: 2377.7009\n",
            "Epoch 116/1000, Lasso Training Loss: 2136.8806, Lasso Test MSE: 2367.0557\n",
            "Epoch 117/1000, Lasso Training Loss: 2127.7954, Lasso Test MSE: 2356.5266\n",
            "Epoch 118/1000, Lasso Training Loss: 2118.8142, Lasso Test MSE: 2346.1125\n",
            "Epoch 119/1000, Lasso Training Loss: 2109.9363, Lasso Test MSE: 2335.8118\n",
            "Epoch 120/1000, Lasso Training Loss: 2101.1602, Lasso Test MSE: 2325.6245\n",
            "Epoch 121/1000, Lasso Training Loss: 2092.4861, Lasso Test MSE: 2315.5483\n",
            "Epoch 122/1000, Lasso Training Loss: 2083.9111, Lasso Test MSE: 2305.5818\n",
            "Epoch 123/1000, Lasso Training Loss: 2075.4346, Lasso Test MSE: 2295.7251\n",
            "Epoch 124/1000, Lasso Training Loss: 2067.0562, Lasso Test MSE: 2285.9758\n",
            "Epoch 125/1000, Lasso Training Loss: 2058.7744, Lasso Test MSE: 2276.3325\n",
            "Epoch 126/1000, Lasso Training Loss: 2050.5872, Lasso Test MSE: 2266.7942\n",
            "Epoch 127/1000, Lasso Training Loss: 2042.4943, Lasso Test MSE: 2257.3611\n",
            "Epoch 128/1000, Lasso Training Loss: 2034.4944, Lasso Test MSE: 2248.0308\n",
            "Epoch 129/1000, Lasso Training Loss: 2026.5869, Lasso Test MSE: 2238.8018\n",
            "Epoch 130/1000, Lasso Training Loss: 2018.7694, Lasso Test MSE: 2229.6731\n",
            "Epoch 131/1000, Lasso Training Loss: 2011.0414, Lasso Test MSE: 2220.6445\n",
            "Epoch 132/1000, Lasso Training Loss: 2003.4026, Lasso Test MSE: 2211.7136\n",
            "Epoch 133/1000, Lasso Training Loss: 1995.8505, Lasso Test MSE: 2202.8796\n",
            "Epoch 134/1000, Lasso Training Loss: 1988.3850, Lasso Test MSE: 2194.1421\n",
            "Epoch 135/1000, Lasso Training Loss: 1981.0048, Lasso Test MSE: 2185.4988\n",
            "Epoch 136/1000, Lasso Training Loss: 1973.7086, Lasso Test MSE: 2176.9492\n",
            "Epoch 137/1000, Lasso Training Loss: 1966.4954, Lasso Test MSE: 2168.4927\n",
            "Epoch 138/1000, Lasso Training Loss: 1959.3646, Lasso Test MSE: 2160.1265\n",
            "Epoch 139/1000, Lasso Training Loss: 1952.3140, Lasso Test MSE: 2151.8516\n",
            "Epoch 140/1000, Lasso Training Loss: 1945.3439, Lasso Test MSE: 2143.6643\n",
            "Epoch 141/1000, Lasso Training Loss: 1938.4514, Lasso Test MSE: 2135.5662\n",
            "Epoch 142/1000, Lasso Training Loss: 1931.6381, Lasso Test MSE: 2127.5549\n",
            "Epoch 143/1000, Lasso Training Loss: 1924.9014, Lasso Test MSE: 2119.6287\n",
            "Epoch 144/1000, Lasso Training Loss: 1918.2394, Lasso Test MSE: 2111.7881\n",
            "Epoch 145/1000, Lasso Training Loss: 1911.6526, Lasso Test MSE: 2104.0310\n",
            "Epoch 146/1000, Lasso Training Loss: 1905.1398, Lasso Test MSE: 2096.3564\n",
            "Epoch 147/1000, Lasso Training Loss: 1898.6993, Lasso Test MSE: 2088.7634\n",
            "Epoch 148/1000, Lasso Training Loss: 1892.3306, Lasso Test MSE: 2081.2510\n",
            "Epoch 149/1000, Lasso Training Loss: 1886.0326, Lasso Test MSE: 2073.8174\n",
            "Epoch 150/1000, Lasso Training Loss: 1879.8041, Lasso Test MSE: 2066.4629\n",
            "Epoch 151/1000, Lasso Training Loss: 1873.6444, Lasso Test MSE: 2059.1855\n",
            "Epoch 152/1000, Lasso Training Loss: 1867.5532, Lasso Test MSE: 2051.9841\n",
            "Epoch 153/1000, Lasso Training Loss: 1861.5273, Lasso Test MSE: 2044.8586\n",
            "Epoch 154/1000, Lasso Training Loss: 1855.5686, Lasso Test MSE: 2037.8070\n",
            "Epoch 155/1000, Lasso Training Loss: 1849.6738, Lasso Test MSE: 2030.8291\n",
            "Epoch 156/1000, Lasso Training Loss: 1843.8438, Lasso Test MSE: 2023.9235\n",
            "Epoch 157/1000, Lasso Training Loss: 1838.0765, Lasso Test MSE: 2017.0891\n",
            "Epoch 158/1000, Lasso Training Loss: 1832.3716, Lasso Test MSE: 2010.3257\n",
            "Epoch 159/1000, Lasso Training Loss: 1826.7277, Lasso Test MSE: 2003.6305\n",
            "Epoch 160/1000, Lasso Training Loss: 1821.1440, Lasso Test MSE: 1997.0052\n",
            "Epoch 161/1000, Lasso Training Loss: 1815.6200, Lasso Test MSE: 1990.4469\n",
            "Epoch 162/1000, Lasso Training Loss: 1810.1547, Lasso Test MSE: 1983.9554\n",
            "Epoch 163/1000, Lasso Training Loss: 1804.7471, Lasso Test MSE: 1977.5288\n",
            "Epoch 164/1000, Lasso Training Loss: 1799.3956, Lasso Test MSE: 1971.1678\n",
            "Epoch 165/1000, Lasso Training Loss: 1794.1008, Lasso Test MSE: 1964.8701\n",
            "Epoch 166/1000, Lasso Training Loss: 1788.8605, Lasso Test MSE: 1958.6353\n",
            "Epoch 167/1000, Lasso Training Loss: 1783.6750, Lasso Test MSE: 1952.4633\n",
            "Epoch 168/1000, Lasso Training Loss: 1778.5430, Lasso Test MSE: 1946.3522\n",
            "Epoch 169/1000, Lasso Training Loss: 1773.4636, Lasso Test MSE: 1940.3005\n",
            "Epoch 170/1000, Lasso Training Loss: 1768.4352, Lasso Test MSE: 1934.3091\n",
            "Epoch 171/1000, Lasso Training Loss: 1763.4586, Lasso Test MSE: 1928.3768\n",
            "Epoch 172/1000, Lasso Training Loss: 1758.5326, Lasso Test MSE: 1922.5012\n",
            "Epoch 173/1000, Lasso Training Loss: 1753.6548, Lasso Test MSE: 1916.6835\n",
            "Epoch 174/1000, Lasso Training Loss: 1748.8269, Lasso Test MSE: 1910.9207\n",
            "Epoch 175/1000, Lasso Training Loss: 1744.0459, Lasso Test MSE: 1905.2137\n",
            "Epoch 176/1000, Lasso Training Loss: 1739.3120, Lasso Test MSE: 1899.5603\n",
            "Epoch 177/1000, Lasso Training Loss: 1734.6245, Lasso Test MSE: 1893.9619\n",
            "Epoch 178/1000, Lasso Training Loss: 1729.9832, Lasso Test MSE: 1888.4152\n",
            "Epoch 179/1000, Lasso Training Loss: 1725.3860, Lasso Test MSE: 1882.9207\n",
            "Epoch 180/1000, Lasso Training Loss: 1720.8331, Lasso Test MSE: 1877.4779\n",
            "Epoch 181/1000, Lasso Training Loss: 1716.3242, Lasso Test MSE: 1872.0858\n",
            "Epoch 182/1000, Lasso Training Loss: 1711.8578, Lasso Test MSE: 1866.7428\n",
            "Epoch 183/1000, Lasso Training Loss: 1707.4330, Lasso Test MSE: 1861.4490\n",
            "Epoch 184/1000, Lasso Training Loss: 1703.0496, Lasso Test MSE: 1856.2030\n",
            "Epoch 185/1000, Lasso Training Loss: 1698.7068, Lasso Test MSE: 1851.0046\n",
            "Epoch 186/1000, Lasso Training Loss: 1694.4041, Lasso Test MSE: 1845.8529\n",
            "Epoch 187/1000, Lasso Training Loss: 1690.1404, Lasso Test MSE: 1840.7477\n",
            "Epoch 188/1000, Lasso Training Loss: 1685.9155, Lasso Test MSE: 1835.6868\n",
            "Epoch 189/1000, Lasso Training Loss: 1681.7280, Lasso Test MSE: 1830.6713\n",
            "Epoch 190/1000, Lasso Training Loss: 1677.5778, Lasso Test MSE: 1825.6995\n",
            "Epoch 191/1000, Lasso Training Loss: 1673.4650, Lasso Test MSE: 1820.7703\n",
            "Epoch 192/1000, Lasso Training Loss: 1669.3872, Lasso Test MSE: 1815.8846\n",
            "Epoch 193/1000, Lasso Training Loss: 1665.3461, Lasso Test MSE: 1811.0402\n",
            "Epoch 194/1000, Lasso Training Loss: 1661.3385, Lasso Test MSE: 1806.2369\n",
            "Epoch 195/1000, Lasso Training Loss: 1657.3658, Lasso Test MSE: 1801.4744\n",
            "Epoch 196/1000, Lasso Training Loss: 1653.4263, Lasso Test MSE: 1796.7516\n",
            "Epoch 197/1000, Lasso Training Loss: 1649.5199, Lasso Test MSE: 1792.0681\n",
            "Epoch 198/1000, Lasso Training Loss: 1645.6464, Lasso Test MSE: 1787.4236\n",
            "Epoch 199/1000, Lasso Training Loss: 1641.8041, Lasso Test MSE: 1782.8163\n",
            "Epoch 200/1000, Lasso Training Loss: 1637.9932, Lasso Test MSE: 1778.2466\n",
            "Epoch 201/1000, Lasso Training Loss: 1634.2128, Lasso Test MSE: 1773.7137\n",
            "Epoch 202/1000, Lasso Training Loss: 1630.4626, Lasso Test MSE: 1769.2172\n",
            "Epoch 203/1000, Lasso Training Loss: 1626.7424, Lasso Test MSE: 1764.7562\n",
            "Epoch 204/1000, Lasso Training Loss: 1623.0509, Lasso Test MSE: 1760.3304\n",
            "Epoch 205/1000, Lasso Training Loss: 1619.3884, Lasso Test MSE: 1755.9386\n",
            "Epoch 206/1000, Lasso Training Loss: 1615.7535, Lasso Test MSE: 1751.5811\n",
            "Epoch 207/1000, Lasso Training Loss: 1612.1465, Lasso Test MSE: 1747.2568\n",
            "Epoch 208/1000, Lasso Training Loss: 1608.5665, Lasso Test MSE: 1742.9651\n",
            "Epoch 209/1000, Lasso Training Loss: 1605.0127, Lasso Test MSE: 1738.7061\n",
            "Epoch 210/1000, Lasso Training Loss: 1601.4852, Lasso Test MSE: 1734.4783\n",
            "Epoch 211/1000, Lasso Training Loss: 1597.9833, Lasso Test MSE: 1730.2816\n",
            "Epoch 212/1000, Lasso Training Loss: 1594.5063, Lasso Test MSE: 1726.1158\n",
            "Epoch 213/1000, Lasso Training Loss: 1591.0541, Lasso Test MSE: 1721.9803\n",
            "Epoch 214/1000, Lasso Training Loss: 1587.6259, Lasso Test MSE: 1717.8740\n",
            "Epoch 215/1000, Lasso Training Loss: 1584.2214, Lasso Test MSE: 1713.7972\n",
            "Epoch 216/1000, Lasso Training Loss: 1580.8406, Lasso Test MSE: 1709.7489\n",
            "Epoch 217/1000, Lasso Training Loss: 1577.4823, Lasso Test MSE: 1705.7289\n",
            "Epoch 218/1000, Lasso Training Loss: 1574.1465, Lasso Test MSE: 1701.7362\n",
            "Epoch 219/1000, Lasso Training Loss: 1570.8323, Lasso Test MSE: 1697.7710\n",
            "Epoch 220/1000, Lasso Training Loss: 1567.5400, Lasso Test MSE: 1693.8323\n",
            "Epoch 221/1000, Lasso Training Loss: 1564.2690, Lasso Test MSE: 1689.9202\n",
            "Epoch 222/1000, Lasso Training Loss: 1561.0186, Lasso Test MSE: 1686.0338\n",
            "Epoch 223/1000, Lasso Training Loss: 1557.7886, Lasso Test MSE: 1682.1735\n",
            "Epoch 224/1000, Lasso Training Loss: 1554.5787, Lasso Test MSE: 1678.3373\n",
            "Epoch 225/1000, Lasso Training Loss: 1551.3884, Lasso Test MSE: 1674.5259\n",
            "Epoch 226/1000, Lasso Training Loss: 1548.2172, Lasso Test MSE: 1670.7386\n",
            "Epoch 227/1000, Lasso Training Loss: 1545.0645, Lasso Test MSE: 1666.9753\n",
            "Epoch 228/1000, Lasso Training Loss: 1541.9312, Lasso Test MSE: 1663.2355\n",
            "Epoch 229/1000, Lasso Training Loss: 1538.8152, Lasso Test MSE: 1659.5184\n",
            "Epoch 230/1000, Lasso Training Loss: 1535.7173, Lasso Test MSE: 1655.8232\n",
            "Epoch 231/1000, Lasso Training Loss: 1532.6367, Lasso Test MSE: 1652.1510\n",
            "Epoch 232/1000, Lasso Training Loss: 1529.5736, Lasso Test MSE: 1648.5001\n",
            "Epoch 233/1000, Lasso Training Loss: 1526.5270, Lasso Test MSE: 1644.8713\n",
            "Epoch 234/1000, Lasso Training Loss: 1523.4968, Lasso Test MSE: 1641.2631\n",
            "Epoch 235/1000, Lasso Training Loss: 1520.4829, Lasso Test MSE: 1637.6755\n",
            "Epoch 236/1000, Lasso Training Loss: 1517.4847, Lasso Test MSE: 1634.1084\n",
            "Epoch 237/1000, Lasso Training Loss: 1514.5023, Lasso Test MSE: 1630.5609\n",
            "Epoch 238/1000, Lasso Training Loss: 1511.5344, Lasso Test MSE: 1627.0332\n",
            "Epoch 239/1000, Lasso Training Loss: 1508.5818, Lasso Test MSE: 1623.5247\n",
            "Epoch 240/1000, Lasso Training Loss: 1505.6438, Lasso Test MSE: 1620.0355\n",
            "Epoch 241/1000, Lasso Training Loss: 1502.7202, Lasso Test MSE: 1616.5643\n",
            "Epoch 242/1000, Lasso Training Loss: 1499.8104, Lasso Test MSE: 1613.1119\n",
            "Epoch 243/1000, Lasso Training Loss: 1496.9149, Lasso Test MSE: 1609.6775\n",
            "Epoch 244/1000, Lasso Training Loss: 1494.0327, Lasso Test MSE: 1606.2612\n",
            "Epoch 245/1000, Lasso Training Loss: 1491.1638, Lasso Test MSE: 1602.8617\n",
            "Epoch 246/1000, Lasso Training Loss: 1488.3076, Lasso Test MSE: 1599.4794\n",
            "Epoch 247/1000, Lasso Training Loss: 1485.4644, Lasso Test MSE: 1596.1138\n",
            "Epoch 248/1000, Lasso Training Loss: 1482.6333, Lasso Test MSE: 1592.7649\n",
            "Epoch 249/1000, Lasso Training Loss: 1479.8152, Lasso Test MSE: 1589.4321\n",
            "Epoch 250/1000, Lasso Training Loss: 1477.0083, Lasso Test MSE: 1586.1155\n",
            "Epoch 251/1000, Lasso Training Loss: 1474.2137, Lasso Test MSE: 1582.8142\n",
            "Epoch 252/1000, Lasso Training Loss: 1471.4303, Lasso Test MSE: 1579.5284\n",
            "Epoch 253/1000, Lasso Training Loss: 1468.6582, Lasso Test MSE: 1576.2582\n",
            "Epoch 254/1000, Lasso Training Loss: 1465.8976, Lasso Test MSE: 1573.0023\n",
            "Epoch 255/1000, Lasso Training Loss: 1463.1473, Lasso Test MSE: 1569.7609\n",
            "Epoch 256/1000, Lasso Training Loss: 1460.4082, Lasso Test MSE: 1566.5344\n",
            "Epoch 257/1000, Lasso Training Loss: 1457.6791, Lasso Test MSE: 1563.3219\n",
            "Epoch 258/1000, Lasso Training Loss: 1454.9604, Lasso Test MSE: 1560.1230\n",
            "Epoch 259/1000, Lasso Training Loss: 1452.2518, Lasso Test MSE: 1556.9381\n",
            "Epoch 260/1000, Lasso Training Loss: 1449.5530, Lasso Test MSE: 1553.7667\n",
            "Epoch 261/1000, Lasso Training Loss: 1446.8640, Lasso Test MSE: 1550.6082\n",
            "Epoch 262/1000, Lasso Training Loss: 1444.1843, Lasso Test MSE: 1547.4629\n",
            "Epoch 263/1000, Lasso Training Loss: 1441.5140, Lasso Test MSE: 1544.3304\n",
            "Epoch 264/1000, Lasso Training Loss: 1438.8528, Lasso Test MSE: 1541.2100\n",
            "Epoch 265/1000, Lasso Training Loss: 1436.2006, Lasso Test MSE: 1538.1025\n",
            "Epoch 266/1000, Lasso Training Loss: 1433.5569, Lasso Test MSE: 1535.0073\n",
            "Epoch 267/1000, Lasso Training Loss: 1430.9226, Lasso Test MSE: 1531.9235\n",
            "Epoch 268/1000, Lasso Training Loss: 1428.2957, Lasso Test MSE: 1528.8519\n",
            "Epoch 269/1000, Lasso Training Loss: 1425.6776, Lasso Test MSE: 1525.7915\n",
            "Epoch 270/1000, Lasso Training Loss: 1423.0677, Lasso Test MSE: 1522.7426\n",
            "Epoch 271/1000, Lasso Training Loss: 1420.4656, Lasso Test MSE: 1519.7048\n",
            "Epoch 272/1000, Lasso Training Loss: 1417.8713, Lasso Test MSE: 1516.6783\n",
            "Epoch 273/1000, Lasso Training Loss: 1415.2848, Lasso Test MSE: 1513.6625\n",
            "Epoch 274/1000, Lasso Training Loss: 1412.7061, Lasso Test MSE: 1510.6572\n",
            "Epoch 275/1000, Lasso Training Loss: 1410.1343, Lasso Test MSE: 1507.6624\n",
            "Epoch 276/1000, Lasso Training Loss: 1407.5701, Lasso Test MSE: 1504.6781\n",
            "Epoch 277/1000, Lasso Training Loss: 1405.0129, Lasso Test MSE: 1501.7032\n",
            "Epoch 278/1000, Lasso Training Loss: 1402.4625, Lasso Test MSE: 1498.7391\n",
            "Epoch 279/1000, Lasso Training Loss: 1399.9192, Lasso Test MSE: 1495.7848\n",
            "Epoch 280/1000, Lasso Training Loss: 1397.3827, Lasso Test MSE: 1492.8400\n",
            "Epoch 281/1000, Lasso Training Loss: 1394.8528, Lasso Test MSE: 1489.9043\n",
            "Epoch 282/1000, Lasso Training Loss: 1392.3292, Lasso Test MSE: 1486.9789\n",
            "Epoch 283/1000, Lasso Training Loss: 1389.8125, Lasso Test MSE: 1484.0619\n",
            "Epoch 284/1000, Lasso Training Loss: 1387.3018, Lasso Test MSE: 1481.1544\n",
            "Epoch 285/1000, Lasso Training Loss: 1384.7971, Lasso Test MSE: 1478.2560\n",
            "Epoch 286/1000, Lasso Training Loss: 1382.2987, Lasso Test MSE: 1475.3656\n",
            "Epoch 287/1000, Lasso Training Loss: 1379.8059, Lasso Test MSE: 1472.4847\n",
            "Epoch 288/1000, Lasso Training Loss: 1377.3196, Lasso Test MSE: 1469.6122\n",
            "Epoch 289/1000, Lasso Training Loss: 1374.8387, Lasso Test MSE: 1466.7480\n",
            "Epoch 290/1000, Lasso Training Loss: 1372.3634, Lasso Test MSE: 1463.8920\n",
            "Epoch 291/1000, Lasso Training Loss: 1369.8937, Lasso Test MSE: 1461.0443\n",
            "Epoch 292/1000, Lasso Training Loss: 1367.4297, Lasso Test MSE: 1458.2047\n",
            "Epoch 293/1000, Lasso Training Loss: 1364.9711, Lasso Test MSE: 1455.3728\n",
            "Epoch 294/1000, Lasso Training Loss: 1362.5175, Lasso Test MSE: 1452.5491\n",
            "Epoch 295/1000, Lasso Training Loss: 1360.0692, Lasso Test MSE: 1449.7328\n",
            "Epoch 296/1000, Lasso Training Loss: 1357.6262, Lasso Test MSE: 1446.9243\n",
            "Epoch 297/1000, Lasso Training Loss: 1355.1882, Lasso Test MSE: 1444.1233\n",
            "Epoch 298/1000, Lasso Training Loss: 1352.7549, Lasso Test MSE: 1441.3297\n",
            "Epoch 299/1000, Lasso Training Loss: 1350.3269, Lasso Test MSE: 1438.5427\n",
            "Epoch 300/1000, Lasso Training Loss: 1347.9034, Lasso Test MSE: 1435.7638\n",
            "Epoch 301/1000, Lasso Training Loss: 1345.4850, Lasso Test MSE: 1432.9917\n",
            "Epoch 302/1000, Lasso Training Loss: 1343.0709, Lasso Test MSE: 1430.2266\n",
            "Epoch 303/1000, Lasso Training Loss: 1340.6617, Lasso Test MSE: 1427.4681\n",
            "Epoch 304/1000, Lasso Training Loss: 1338.2570, Lasso Test MSE: 1424.7169\n",
            "Epoch 305/1000, Lasso Training Loss: 1335.8567, Lasso Test MSE: 1421.9718\n",
            "Epoch 306/1000, Lasso Training Loss: 1333.4609, Lasso Test MSE: 1419.2339\n",
            "Epoch 307/1000, Lasso Training Loss: 1331.0692, Lasso Test MSE: 1416.5024\n",
            "Epoch 308/1000, Lasso Training Loss: 1328.6823, Lasso Test MSE: 1413.7772\n",
            "Epoch 309/1000, Lasso Training Loss: 1326.2992, Lasso Test MSE: 1411.0585\n",
            "Epoch 310/1000, Lasso Training Loss: 1323.9203, Lasso Test MSE: 1408.3462\n",
            "Epoch 311/1000, Lasso Training Loss: 1321.5459, Lasso Test MSE: 1405.6399\n",
            "Epoch 312/1000, Lasso Training Loss: 1319.1750, Lasso Test MSE: 1402.9398\n",
            "Epoch 313/1000, Lasso Training Loss: 1316.8088, Lasso Test MSE: 1400.2460\n",
            "Epoch 314/1000, Lasso Training Loss: 1314.4462, Lasso Test MSE: 1397.5579\n",
            "Epoch 315/1000, Lasso Training Loss: 1312.0875, Lasso Test MSE: 1394.8756\n",
            "Epoch 316/1000, Lasso Training Loss: 1309.7324, Lasso Test MSE: 1392.1993\n",
            "Epoch 317/1000, Lasso Training Loss: 1307.3815, Lasso Test MSE: 1389.5284\n",
            "Epoch 318/1000, Lasso Training Loss: 1305.0342, Lasso Test MSE: 1386.8638\n",
            "Epoch 319/1000, Lasso Training Loss: 1302.6904, Lasso Test MSE: 1384.2048\n",
            "Epoch 320/1000, Lasso Training Loss: 1300.3508, Lasso Test MSE: 1381.5515\n",
            "Epoch 321/1000, Lasso Training Loss: 1298.0148, Lasso Test MSE: 1378.9033\n",
            "Epoch 322/1000, Lasso Training Loss: 1295.6823, Lasso Test MSE: 1376.2609\n",
            "Epoch 323/1000, Lasso Training Loss: 1293.3533, Lasso Test MSE: 1373.6240\n",
            "Epoch 324/1000, Lasso Training Loss: 1291.0281, Lasso Test MSE: 1370.9923\n",
            "Epoch 325/1000, Lasso Training Loss: 1288.7063, Lasso Test MSE: 1368.3660\n",
            "Epoch 326/1000, Lasso Training Loss: 1286.3878, Lasso Test MSE: 1365.7446\n",
            "Epoch 327/1000, Lasso Training Loss: 1284.0726, Lasso Test MSE: 1363.1287\n",
            "Epoch 328/1000, Lasso Training Loss: 1281.7612, Lasso Test MSE: 1360.5179\n",
            "Epoch 329/1000, Lasso Training Loss: 1279.4531, Lasso Test MSE: 1357.9121\n",
            "Epoch 330/1000, Lasso Training Loss: 1277.1481, Lasso Test MSE: 1355.3114\n",
            "Epoch 331/1000, Lasso Training Loss: 1274.8467, Lasso Test MSE: 1352.7158\n",
            "Epoch 332/1000, Lasso Training Loss: 1272.5483, Lasso Test MSE: 1350.1251\n",
            "Epoch 333/1000, Lasso Training Loss: 1270.2535, Lasso Test MSE: 1347.5394\n",
            "Epoch 334/1000, Lasso Training Loss: 1267.9618, Lasso Test MSE: 1344.9581\n",
            "Epoch 335/1000, Lasso Training Loss: 1265.6731, Lasso Test MSE: 1342.3817\n",
            "Epoch 336/1000, Lasso Training Loss: 1263.3875, Lasso Test MSE: 1339.8103\n",
            "Epoch 337/1000, Lasso Training Loss: 1261.1053, Lasso Test MSE: 1337.2435\n",
            "Epoch 338/1000, Lasso Training Loss: 1258.8262, Lasso Test MSE: 1334.6816\n",
            "Epoch 339/1000, Lasso Training Loss: 1256.5500, Lasso Test MSE: 1332.1243\n",
            "Epoch 340/1000, Lasso Training Loss: 1254.2772, Lasso Test MSE: 1329.5717\n",
            "Epoch 341/1000, Lasso Training Loss: 1252.0073, Lasso Test MSE: 1327.0233\n",
            "Epoch 342/1000, Lasso Training Loss: 1249.7405, Lasso Test MSE: 1324.4796\n",
            "Epoch 343/1000, Lasso Training Loss: 1247.4766, Lasso Test MSE: 1321.9406\n",
            "Epoch 344/1000, Lasso Training Loss: 1245.2158, Lasso Test MSE: 1319.4056\n",
            "Epoch 345/1000, Lasso Training Loss: 1242.9580, Lasso Test MSE: 1316.8755\n",
            "Epoch 346/1000, Lasso Training Loss: 1240.7031, Lasso Test MSE: 1314.3492\n",
            "Epoch 347/1000, Lasso Training Loss: 1238.4510, Lasso Test MSE: 1311.8278\n",
            "Epoch 348/1000, Lasso Training Loss: 1236.2019, Lasso Test MSE: 1309.3107\n",
            "Epoch 349/1000, Lasso Training Loss: 1233.9559, Lasso Test MSE: 1306.7975\n",
            "Epoch 350/1000, Lasso Training Loss: 1231.7126, Lasso Test MSE: 1304.2887\n",
            "Epoch 351/1000, Lasso Training Loss: 1229.4723, Lasso Test MSE: 1301.7843\n",
            "Epoch 352/1000, Lasso Training Loss: 1227.2350, Lasso Test MSE: 1299.2841\n",
            "Epoch 353/1000, Lasso Training Loss: 1225.0002, Lasso Test MSE: 1296.7881\n",
            "Epoch 354/1000, Lasso Training Loss: 1222.7686, Lasso Test MSE: 1294.2959\n",
            "Epoch 355/1000, Lasso Training Loss: 1220.5396, Lasso Test MSE: 1291.8081\n",
            "Epoch 356/1000, Lasso Training Loss: 1218.3132, Lasso Test MSE: 1289.3245\n",
            "Epoch 357/1000, Lasso Training Loss: 1216.0902, Lasso Test MSE: 1286.8448\n",
            "Epoch 358/1000, Lasso Training Loss: 1213.8698, Lasso Test MSE: 1284.3691\n",
            "Epoch 359/1000, Lasso Training Loss: 1211.6519, Lasso Test MSE: 1281.8978\n",
            "Epoch 360/1000, Lasso Training Loss: 1209.4371, Lasso Test MSE: 1279.4301\n",
            "Epoch 361/1000, Lasso Training Loss: 1207.2249, Lasso Test MSE: 1276.9666\n",
            "Epoch 362/1000, Lasso Training Loss: 1205.0156, Lasso Test MSE: 1274.5070\n",
            "Epoch 363/1000, Lasso Training Loss: 1202.8087, Lasso Test MSE: 1272.0515\n",
            "Epoch 364/1000, Lasso Training Loss: 1200.6050, Lasso Test MSE: 1269.5997\n",
            "Epoch 365/1000, Lasso Training Loss: 1198.4037, Lasso Test MSE: 1267.1520\n",
            "Epoch 366/1000, Lasso Training Loss: 1196.2054, Lasso Test MSE: 1264.7081\n",
            "Epoch 367/1000, Lasso Training Loss: 1194.0096, Lasso Test MSE: 1262.2678\n",
            "Epoch 368/1000, Lasso Training Loss: 1191.8167, Lasso Test MSE: 1259.8315\n",
            "Epoch 369/1000, Lasso Training Loss: 1189.6262, Lasso Test MSE: 1257.3990\n",
            "Epoch 370/1000, Lasso Training Loss: 1187.4386, Lasso Test MSE: 1254.9703\n",
            "Epoch 371/1000, Lasso Training Loss: 1185.2538, Lasso Test MSE: 1252.5455\n",
            "Epoch 372/1000, Lasso Training Loss: 1183.0715, Lasso Test MSE: 1250.1245\n",
            "Epoch 373/1000, Lasso Training Loss: 1180.8920, Lasso Test MSE: 1247.7073\n",
            "Epoch 374/1000, Lasso Training Loss: 1178.7151, Lasso Test MSE: 1245.2936\n",
            "Epoch 375/1000, Lasso Training Loss: 1176.5410, Lasso Test MSE: 1242.8838\n",
            "Epoch 376/1000, Lasso Training Loss: 1174.3695, Lasso Test MSE: 1240.4775\n",
            "Epoch 377/1000, Lasso Training Loss: 1172.2004, Lasso Test MSE: 1238.0750\n",
            "Epoch 378/1000, Lasso Training Loss: 1170.0343, Lasso Test MSE: 1235.6761\n",
            "Epoch 379/1000, Lasso Training Loss: 1167.8706, Lasso Test MSE: 1233.2808\n",
            "Epoch 380/1000, Lasso Training Loss: 1165.7097, Lasso Test MSE: 1230.8893\n",
            "Epoch 381/1000, Lasso Training Loss: 1163.5515, Lasso Test MSE: 1228.5012\n",
            "Epoch 382/1000, Lasso Training Loss: 1161.3955, Lasso Test MSE: 1226.1172\n",
            "Epoch 383/1000, Lasso Training Loss: 1159.2426, Lasso Test MSE: 1223.7366\n",
            "Epoch 384/1000, Lasso Training Loss: 1157.0925, Lasso Test MSE: 1221.3594\n",
            "Epoch 385/1000, Lasso Training Loss: 1154.9447, Lasso Test MSE: 1218.9861\n",
            "Epoch 386/1000, Lasso Training Loss: 1152.7998, Lasso Test MSE: 1216.6162\n",
            "Epoch 387/1000, Lasso Training Loss: 1150.6573, Lasso Test MSE: 1214.2496\n",
            "Epoch 388/1000, Lasso Training Loss: 1148.5175, Lasso Test MSE: 1211.8872\n",
            "Epoch 389/1000, Lasso Training Loss: 1146.3805, Lasso Test MSE: 1209.5278\n",
            "Epoch 390/1000, Lasso Training Loss: 1144.2457, Lasso Test MSE: 1207.1725\n",
            "Epoch 391/1000, Lasso Training Loss: 1142.1143, Lasso Test MSE: 1204.8199\n",
            "Epoch 392/1000, Lasso Training Loss: 1139.9847, Lasso Test MSE: 1202.4717\n",
            "Epoch 393/1000, Lasso Training Loss: 1137.8584, Lasso Test MSE: 1200.1263\n",
            "Epoch 394/1000, Lasso Training Loss: 1135.7341, Lasso Test MSE: 1197.7850\n",
            "Epoch 395/1000, Lasso Training Loss: 1133.6129, Lasso Test MSE: 1195.4470\n",
            "Epoch 396/1000, Lasso Training Loss: 1131.4943, Lasso Test MSE: 1193.1123\n",
            "Epoch 397/1000, Lasso Training Loss: 1129.3782, Lasso Test MSE: 1190.7814\n",
            "Epoch 398/1000, Lasso Training Loss: 1127.2648, Lasso Test MSE: 1188.4535\n",
            "Epoch 399/1000, Lasso Training Loss: 1125.1539, Lasso Test MSE: 1186.1294\n",
            "Epoch 400/1000, Lasso Training Loss: 1123.0459, Lasso Test MSE: 1183.8083\n",
            "Epoch 401/1000, Lasso Training Loss: 1120.9402, Lasso Test MSE: 1181.4915\n",
            "Epoch 402/1000, Lasso Training Loss: 1118.8375, Lasso Test MSE: 1179.1775\n",
            "Epoch 403/1000, Lasso Training Loss: 1116.7371, Lasso Test MSE: 1176.8671\n",
            "Epoch 404/1000, Lasso Training Loss: 1114.6396, Lasso Test MSE: 1174.5598\n",
            "Epoch 405/1000, Lasso Training Loss: 1112.5444, Lasso Test MSE: 1172.2562\n",
            "Epoch 406/1000, Lasso Training Loss: 1110.4520, Lasso Test MSE: 1169.9561\n",
            "Epoch 407/1000, Lasso Training Loss: 1108.3621, Lasso Test MSE: 1167.6592\n",
            "Epoch 408/1000, Lasso Training Loss: 1106.2750, Lasso Test MSE: 1165.3658\n",
            "Epoch 409/1000, Lasso Training Loss: 1104.1906, Lasso Test MSE: 1163.0757\n",
            "Epoch 410/1000, Lasso Training Loss: 1102.1088, Lasso Test MSE: 1160.7893\n",
            "Epoch 411/1000, Lasso Training Loss: 1100.0297, Lasso Test MSE: 1158.5060\n",
            "Epoch 412/1000, Lasso Training Loss: 1097.9529, Lasso Test MSE: 1156.2260\n",
            "Epoch 413/1000, Lasso Training Loss: 1095.8788, Lasso Test MSE: 1153.9496\n",
            "Epoch 414/1000, Lasso Training Loss: 1093.8076, Lasso Test MSE: 1151.6763\n",
            "Epoch 415/1000, Lasso Training Loss: 1091.7390, Lasso Test MSE: 1149.4067\n",
            "Epoch 416/1000, Lasso Training Loss: 1089.6731, Lasso Test MSE: 1147.1403\n",
            "Epoch 417/1000, Lasso Training Loss: 1087.6097, Lasso Test MSE: 1144.8770\n",
            "Epoch 418/1000, Lasso Training Loss: 1085.5488, Lasso Test MSE: 1142.6174\n",
            "Epoch 419/1000, Lasso Training Loss: 1083.4911, Lasso Test MSE: 1140.3611\n",
            "Epoch 420/1000, Lasso Training Loss: 1081.4354, Lasso Test MSE: 1138.1080\n",
            "Epoch 421/1000, Lasso Training Loss: 1079.3826, Lasso Test MSE: 1135.8583\n",
            "Epoch 422/1000, Lasso Training Loss: 1077.3323, Lasso Test MSE: 1133.6121\n",
            "Epoch 423/1000, Lasso Training Loss: 1075.2850, Lasso Test MSE: 1131.3690\n",
            "Epoch 424/1000, Lasso Training Loss: 1073.2402, Lasso Test MSE: 1129.1294\n",
            "Epoch 425/1000, Lasso Training Loss: 1071.1984, Lasso Test MSE: 1126.8929\n",
            "Epoch 426/1000, Lasso Training Loss: 1069.1588, Lasso Test MSE: 1124.6598\n",
            "Epoch 427/1000, Lasso Training Loss: 1067.1221, Lasso Test MSE: 1122.4299\n",
            "Epoch 428/1000, Lasso Training Loss: 1065.0878, Lasso Test MSE: 1120.2035\n",
            "Epoch 429/1000, Lasso Training Loss: 1063.0562, Lasso Test MSE: 1117.9805\n",
            "Epoch 430/1000, Lasso Training Loss: 1061.0275, Lasso Test MSE: 1115.7607\n",
            "Epoch 431/1000, Lasso Training Loss: 1059.0012, Lasso Test MSE: 1113.5441\n",
            "Epoch 432/1000, Lasso Training Loss: 1056.9778, Lasso Test MSE: 1111.3308\n",
            "Epoch 433/1000, Lasso Training Loss: 1054.9569, Lasso Test MSE: 1109.1208\n",
            "Epoch 434/1000, Lasso Training Loss: 1052.9391, Lasso Test MSE: 1106.9142\n",
            "Epoch 435/1000, Lasso Training Loss: 1050.9236, Lasso Test MSE: 1104.7108\n",
            "Epoch 436/1000, Lasso Training Loss: 1048.9106, Lasso Test MSE: 1102.5110\n",
            "Epoch 437/1000, Lasso Training Loss: 1046.9010, Lasso Test MSE: 1100.3143\n",
            "Epoch 438/1000, Lasso Training Loss: 1044.8937, Lasso Test MSE: 1098.1206\n",
            "Epoch 439/1000, Lasso Training Loss: 1042.8887, Lasso Test MSE: 1095.9305\n",
            "Epoch 440/1000, Lasso Training Loss: 1040.8868, Lasso Test MSE: 1093.7438\n",
            "Epoch 441/1000, Lasso Training Loss: 1038.8876, Lasso Test MSE: 1091.5601\n",
            "Epoch 442/1000, Lasso Training Loss: 1036.8909, Lasso Test MSE: 1089.3796\n",
            "Epoch 443/1000, Lasso Training Loss: 1034.8972, Lasso Test MSE: 1087.2025\n",
            "Epoch 444/1000, Lasso Training Loss: 1032.9059, Lasso Test MSE: 1085.0288\n",
            "Epoch 445/1000, Lasso Training Loss: 1030.9174, Lasso Test MSE: 1082.8583\n",
            "Epoch 446/1000, Lasso Training Loss: 1028.9316, Lasso Test MSE: 1080.6910\n",
            "Epoch 447/1000, Lasso Training Loss: 1026.9485, Lasso Test MSE: 1078.5272\n",
            "Epoch 448/1000, Lasso Training Loss: 1024.9683, Lasso Test MSE: 1076.3665\n",
            "Epoch 449/1000, Lasso Training Loss: 1022.9907, Lasso Test MSE: 1074.2091\n",
            "Epoch 450/1000, Lasso Training Loss: 1021.0157, Lasso Test MSE: 1072.0547\n",
            "Epoch 451/1000, Lasso Training Loss: 1019.0435, Lasso Test MSE: 1069.9039\n",
            "Epoch 452/1000, Lasso Training Loss: 1017.0741, Lasso Test MSE: 1067.7565\n",
            "Epoch 453/1000, Lasso Training Loss: 1015.1072, Lasso Test MSE: 1065.6121\n",
            "Epoch 454/1000, Lasso Training Loss: 1013.1432, Lasso Test MSE: 1063.4709\n",
            "Epoch 455/1000, Lasso Training Loss: 1011.1819, Lasso Test MSE: 1061.3329\n",
            "Epoch 456/1000, Lasso Training Loss: 1009.2234, Lasso Test MSE: 1059.1985\n",
            "Epoch 457/1000, Lasso Training Loss: 1007.2675, Lasso Test MSE: 1057.0674\n",
            "Epoch 458/1000, Lasso Training Loss: 1005.3145, Lasso Test MSE: 1054.9392\n",
            "Epoch 459/1000, Lasso Training Loss: 1003.3640, Lasso Test MSE: 1052.8145\n",
            "Epoch 460/1000, Lasso Training Loss: 1001.4166, Lasso Test MSE: 1050.6927\n",
            "Epoch 461/1000, Lasso Training Loss: 999.4716, Lasso Test MSE: 1048.5743\n",
            "Epoch 462/1000, Lasso Training Loss: 997.5292, Lasso Test MSE: 1046.4592\n",
            "Epoch 463/1000, Lasso Training Loss: 995.5898, Lasso Test MSE: 1044.3473\n",
            "Epoch 464/1000, Lasso Training Loss: 993.6531, Lasso Test MSE: 1042.2390\n",
            "Epoch 465/1000, Lasso Training Loss: 991.7193, Lasso Test MSE: 1040.1337\n",
            "Epoch 466/1000, Lasso Training Loss: 989.7880, Lasso Test MSE: 1038.0315\n",
            "Epoch 467/1000, Lasso Training Loss: 987.8597, Lasso Test MSE: 1035.9326\n",
            "Epoch 468/1000, Lasso Training Loss: 985.9341, Lasso Test MSE: 1033.8370\n",
            "Epoch 469/1000, Lasso Training Loss: 984.0110, Lasso Test MSE: 1031.7450\n",
            "Epoch 470/1000, Lasso Training Loss: 982.0908, Lasso Test MSE: 1029.6558\n",
            "Epoch 471/1000, Lasso Training Loss: 980.1735, Lasso Test MSE: 1027.5698\n",
            "Epoch 472/1000, Lasso Training Loss: 978.2587, Lasso Test MSE: 1025.4872\n",
            "Epoch 473/1000, Lasso Training Loss: 976.3469, Lasso Test MSE: 1023.4078\n",
            "Epoch 474/1000, Lasso Training Loss: 974.4376, Lasso Test MSE: 1021.3317\n",
            "Epoch 475/1000, Lasso Training Loss: 972.5312, Lasso Test MSE: 1019.2587\n",
            "Epoch 476/1000, Lasso Training Loss: 970.6276, Lasso Test MSE: 1017.1891\n",
            "Epoch 477/1000, Lasso Training Loss: 968.7268, Lasso Test MSE: 1015.1227\n",
            "Epoch 478/1000, Lasso Training Loss: 966.8287, Lasso Test MSE: 1013.0596\n",
            "Epoch 479/1000, Lasso Training Loss: 964.9335, Lasso Test MSE: 1010.9995\n",
            "Epoch 480/1000, Lasso Training Loss: 963.0408, Lasso Test MSE: 1008.9429\n",
            "Epoch 481/1000, Lasso Training Loss: 961.1511, Lasso Test MSE: 1006.8893\n",
            "Epoch 482/1000, Lasso Training Loss: 959.2641, Lasso Test MSE: 1004.8393\n",
            "Epoch 483/1000, Lasso Training Loss: 957.3799, Lasso Test MSE: 1002.7921\n",
            "Epoch 484/1000, Lasso Training Loss: 955.4985, Lasso Test MSE: 1000.7485\n",
            "Epoch 485/1000, Lasso Training Loss: 953.6200, Lasso Test MSE: 998.7079\n",
            "Epoch 486/1000, Lasso Training Loss: 951.7439, Lasso Test MSE: 996.6705\n",
            "Epoch 487/1000, Lasso Training Loss: 949.8708, Lasso Test MSE: 994.6367\n",
            "Epoch 488/1000, Lasso Training Loss: 948.0006, Lasso Test MSE: 992.6057\n",
            "Epoch 489/1000, Lasso Training Loss: 946.1331, Lasso Test MSE: 990.5781\n",
            "Epoch 490/1000, Lasso Training Loss: 944.2685, Lasso Test MSE: 988.5538\n",
            "Epoch 491/1000, Lasso Training Loss: 942.4067, Lasso Test MSE: 986.5327\n",
            "Epoch 492/1000, Lasso Training Loss: 940.5475, Lasso Test MSE: 984.5148\n",
            "Epoch 493/1000, Lasso Training Loss: 938.6912, Lasso Test MSE: 982.4999\n",
            "Epoch 494/1000, Lasso Training Loss: 936.8376, Lasso Test MSE: 980.4886\n",
            "Epoch 495/1000, Lasso Training Loss: 934.9869, Lasso Test MSE: 978.4802\n",
            "Epoch 496/1000, Lasso Training Loss: 933.1388, Lasso Test MSE: 976.4754\n",
            "Epoch 497/1000, Lasso Training Loss: 931.2938, Lasso Test MSE: 974.4733\n",
            "Epoch 498/1000, Lasso Training Loss: 929.4511, Lasso Test MSE: 972.4750\n",
            "Epoch 499/1000, Lasso Training Loss: 927.6117, Lasso Test MSE: 970.4795\n",
            "Epoch 500/1000, Lasso Training Loss: 925.7750, Lasso Test MSE: 968.4874\n",
            "Epoch 501/1000, Lasso Training Loss: 923.9410, Lasso Test MSE: 966.4985\n",
            "Epoch 502/1000, Lasso Training Loss: 922.1099, Lasso Test MSE: 964.5129\n",
            "Epoch 503/1000, Lasso Training Loss: 920.2817, Lasso Test MSE: 962.5305\n",
            "Epoch 504/1000, Lasso Training Loss: 918.4561, Lasso Test MSE: 960.5513\n",
            "Epoch 505/1000, Lasso Training Loss: 916.6334, Lasso Test MSE: 958.5754\n",
            "Epoch 506/1000, Lasso Training Loss: 914.8134, Lasso Test MSE: 956.6024\n",
            "Epoch 507/1000, Lasso Training Loss: 912.9964, Lasso Test MSE: 954.6332\n",
            "Epoch 508/1000, Lasso Training Loss: 911.1822, Lasso Test MSE: 952.6665\n",
            "Epoch 509/1000, Lasso Training Loss: 909.3705, Lasso Test MSE: 950.7036\n",
            "Epoch 510/1000, Lasso Training Loss: 907.5619, Lasso Test MSE: 948.7437\n",
            "Epoch 511/1000, Lasso Training Loss: 905.7562, Lasso Test MSE: 946.7870\n",
            "Epoch 512/1000, Lasso Training Loss: 903.9529, Lasso Test MSE: 944.8336\n",
            "Epoch 513/1000, Lasso Training Loss: 902.1528, Lasso Test MSE: 942.8833\n",
            "Epoch 514/1000, Lasso Training Loss: 900.3553, Lasso Test MSE: 940.9362\n",
            "Epoch 515/1000, Lasso Training Loss: 898.5607, Lasso Test MSE: 938.9924\n",
            "Epoch 516/1000, Lasso Training Loss: 896.7690, Lasso Test MSE: 937.0519\n",
            "Epoch 517/1000, Lasso Training Loss: 894.9800, Lasso Test MSE: 935.1147\n",
            "Epoch 518/1000, Lasso Training Loss: 893.1939, Lasso Test MSE: 933.1803\n",
            "Epoch 519/1000, Lasso Training Loss: 891.4103, Lasso Test MSE: 931.2493\n",
            "Epoch 520/1000, Lasso Training Loss: 889.6301, Lasso Test MSE: 929.3216\n",
            "Epoch 521/1000, Lasso Training Loss: 887.8524, Lasso Test MSE: 927.3970\n",
            "Epoch 522/1000, Lasso Training Loss: 886.0773, Lasso Test MSE: 925.4758\n",
            "Epoch 523/1000, Lasso Training Loss: 884.3054, Lasso Test MSE: 923.5577\n",
            "Epoch 524/1000, Lasso Training Loss: 882.5361, Lasso Test MSE: 921.6428\n",
            "Epoch 525/1000, Lasso Training Loss: 880.7697, Lasso Test MSE: 919.7310\n",
            "Epoch 526/1000, Lasso Training Loss: 879.0061, Lasso Test MSE: 917.8224\n",
            "Epoch 527/1000, Lasso Training Loss: 877.2453, Lasso Test MSE: 915.9171\n",
            "Epoch 528/1000, Lasso Training Loss: 875.4872, Lasso Test MSE: 914.0150\n",
            "Epoch 529/1000, Lasso Training Loss: 873.7322, Lasso Test MSE: 912.1160\n",
            "Epoch 530/1000, Lasso Training Loss: 871.9799, Lasso Test MSE: 910.2202\n",
            "Epoch 531/1000, Lasso Training Loss: 870.2303, Lasso Test MSE: 908.3276\n",
            "Epoch 532/1000, Lasso Training Loss: 868.4835, Lasso Test MSE: 906.4384\n",
            "Epoch 533/1000, Lasso Training Loss: 866.7398, Lasso Test MSE: 904.5525\n",
            "Epoch 534/1000, Lasso Training Loss: 864.9988, Lasso Test MSE: 902.6697\n",
            "Epoch 535/1000, Lasso Training Loss: 863.2606, Lasso Test MSE: 900.7897\n",
            "Epoch 536/1000, Lasso Training Loss: 861.5251, Lasso Test MSE: 898.9132\n",
            "Epoch 537/1000, Lasso Training Loss: 859.7925, Lasso Test MSE: 897.0397\n",
            "Epoch 538/1000, Lasso Training Loss: 858.0627, Lasso Test MSE: 895.1696\n",
            "Epoch 539/1000, Lasso Training Loss: 856.3359, Lasso Test MSE: 893.3028\n",
            "Epoch 540/1000, Lasso Training Loss: 854.6119, Lasso Test MSE: 891.4388\n",
            "Epoch 541/1000, Lasso Training Loss: 852.8903, Lasso Test MSE: 889.5784\n",
            "Epoch 542/1000, Lasso Training Loss: 851.1721, Lasso Test MSE: 887.7209\n",
            "Epoch 543/1000, Lasso Training Loss: 849.4562, Lasso Test MSE: 885.8667\n",
            "Epoch 544/1000, Lasso Training Loss: 847.7435, Lasso Test MSE: 884.0158\n",
            "Epoch 545/1000, Lasso Training Loss: 846.0336, Lasso Test MSE: 882.1679\n",
            "Epoch 546/1000, Lasso Training Loss: 844.3264, Lasso Test MSE: 880.3232\n",
            "Epoch 547/1000, Lasso Training Loss: 842.6219, Lasso Test MSE: 878.4818\n",
            "Epoch 548/1000, Lasso Training Loss: 840.9204, Lasso Test MSE: 876.6436\n",
            "Epoch 549/1000, Lasso Training Loss: 839.2219, Lasso Test MSE: 874.8084\n",
            "Epoch 550/1000, Lasso Training Loss: 837.5259, Lasso Test MSE: 872.9764\n",
            "Epoch 551/1000, Lasso Training Loss: 835.8328, Lasso Test MSE: 871.1478\n",
            "Epoch 552/1000, Lasso Training Loss: 834.1426, Lasso Test MSE: 869.3221\n",
            "Epoch 553/1000, Lasso Training Loss: 832.4551, Lasso Test MSE: 867.5000\n",
            "Epoch 554/1000, Lasso Training Loss: 830.7707, Lasso Test MSE: 865.6808\n",
            "Epoch 555/1000, Lasso Training Loss: 829.0888, Lasso Test MSE: 863.8647\n",
            "Epoch 556/1000, Lasso Training Loss: 827.4099, Lasso Test MSE: 862.0518\n",
            "Epoch 557/1000, Lasso Training Loss: 825.7337, Lasso Test MSE: 860.2421\n",
            "Epoch 558/1000, Lasso Training Loss: 824.0604, Lasso Test MSE: 858.4357\n",
            "Epoch 559/1000, Lasso Training Loss: 822.3900, Lasso Test MSE: 856.6321\n",
            "Epoch 560/1000, Lasso Training Loss: 820.7222, Lasso Test MSE: 854.8321\n",
            "Epoch 561/1000, Lasso Training Loss: 819.0573, Lasso Test MSE: 853.0350\n",
            "Epoch 562/1000, Lasso Training Loss: 817.3953, Lasso Test MSE: 851.2411\n",
            "Epoch 563/1000, Lasso Training Loss: 815.7360, Lasso Test MSE: 849.4505\n",
            "Epoch 564/1000, Lasso Training Loss: 814.0797, Lasso Test MSE: 847.6630\n",
            "Epoch 565/1000, Lasso Training Loss: 812.4262, Lasso Test MSE: 845.8786\n",
            "Epoch 566/1000, Lasso Training Loss: 810.7753, Lasso Test MSE: 844.0974\n",
            "Epoch 567/1000, Lasso Training Loss: 809.1273, Lasso Test MSE: 842.3192\n",
            "Epoch 568/1000, Lasso Training Loss: 807.4822, Lasso Test MSE: 840.5444\n",
            "Epoch 569/1000, Lasso Training Loss: 805.8397, Lasso Test MSE: 838.7726\n",
            "Epoch 570/1000, Lasso Training Loss: 804.2002, Lasso Test MSE: 837.0041\n",
            "Epoch 571/1000, Lasso Training Loss: 802.5635, Lasso Test MSE: 835.2386\n",
            "Epoch 572/1000, Lasso Training Loss: 800.9296, Lasso Test MSE: 833.4762\n",
            "Epoch 573/1000, Lasso Training Loss: 799.2985, Lasso Test MSE: 831.7172\n",
            "Epoch 574/1000, Lasso Training Loss: 797.6703, Lasso Test MSE: 829.9612\n",
            "Epoch 575/1000, Lasso Training Loss: 796.0447, Lasso Test MSE: 828.2083\n",
            "Epoch 576/1000, Lasso Training Loss: 794.4221, Lasso Test MSE: 826.4586\n",
            "Epoch 577/1000, Lasso Training Loss: 792.8022, Lasso Test MSE: 824.7120\n",
            "Epoch 578/1000, Lasso Training Loss: 791.1851, Lasso Test MSE: 822.9685\n",
            "Epoch 579/1000, Lasso Training Loss: 789.5709, Lasso Test MSE: 821.2283\n",
            "Epoch 580/1000, Lasso Training Loss: 787.9594, Lasso Test MSE: 819.4911\n",
            "Epoch 581/1000, Lasso Training Loss: 786.3507, Lasso Test MSE: 817.7572\n",
            "Epoch 582/1000, Lasso Training Loss: 784.7450, Lasso Test MSE: 816.0264\n",
            "Epoch 583/1000, Lasso Training Loss: 783.1419, Lasso Test MSE: 814.2986\n",
            "Epoch 584/1000, Lasso Training Loss: 781.5416, Lasso Test MSE: 812.5739\n",
            "Epoch 585/1000, Lasso Training Loss: 779.9441, Lasso Test MSE: 810.8522\n",
            "Epoch 586/1000, Lasso Training Loss: 778.3495, Lasso Test MSE: 809.1340\n",
            "Epoch 587/1000, Lasso Training Loss: 776.7576, Lasso Test MSE: 807.4186\n",
            "Epoch 588/1000, Lasso Training Loss: 775.1684, Lasso Test MSE: 805.7064\n",
            "Epoch 589/1000, Lasso Training Loss: 773.5820, Lasso Test MSE: 803.9974\n",
            "Epoch 590/1000, Lasso Training Loss: 771.9985, Lasso Test MSE: 802.2914\n",
            "Epoch 591/1000, Lasso Training Loss: 770.4178, Lasso Test MSE: 800.5889\n",
            "Epoch 592/1000, Lasso Training Loss: 768.8400, Lasso Test MSE: 798.8890\n",
            "Epoch 593/1000, Lasso Training Loss: 767.2649, Lasso Test MSE: 797.1925\n",
            "Epoch 594/1000, Lasso Training Loss: 765.6926, Lasso Test MSE: 795.4988\n",
            "Epoch 595/1000, Lasso Training Loss: 764.1229, Lasso Test MSE: 793.8084\n",
            "Epoch 596/1000, Lasso Training Loss: 762.5560, Lasso Test MSE: 792.1213\n",
            "Epoch 597/1000, Lasso Training Loss: 760.9919, Lasso Test MSE: 790.4372\n",
            "Epoch 598/1000, Lasso Training Loss: 759.4308, Lasso Test MSE: 788.7560\n",
            "Epoch 599/1000, Lasso Training Loss: 757.8724, Lasso Test MSE: 787.0781\n",
            "Epoch 600/1000, Lasso Training Loss: 756.3168, Lasso Test MSE: 785.4033\n",
            "Epoch 601/1000, Lasso Training Loss: 754.7638, Lasso Test MSE: 783.7314\n",
            "Epoch 602/1000, Lasso Training Loss: 753.2137, Lasso Test MSE: 782.0627\n",
            "Epoch 603/1000, Lasso Training Loss: 751.6663, Lasso Test MSE: 780.3972\n",
            "Epoch 604/1000, Lasso Training Loss: 750.1217, Lasso Test MSE: 778.7347\n",
            "Epoch 605/1000, Lasso Training Loss: 748.5801, Lasso Test MSE: 777.0754\n",
            "Epoch 606/1000, Lasso Training Loss: 747.0411, Lasso Test MSE: 775.4189\n",
            "Epoch 607/1000, Lasso Training Loss: 745.5046, Lasso Test MSE: 773.7657\n",
            "Epoch 608/1000, Lasso Training Loss: 743.9712, Lasso Test MSE: 772.1155\n",
            "Epoch 609/1000, Lasso Training Loss: 742.4404, Lasso Test MSE: 770.4683\n",
            "Epoch 610/1000, Lasso Training Loss: 740.9124, Lasso Test MSE: 768.8244\n",
            "Epoch 611/1000, Lasso Training Loss: 739.3871, Lasso Test MSE: 767.1833\n",
            "Epoch 612/1000, Lasso Training Loss: 737.8646, Lasso Test MSE: 765.5455\n",
            "Epoch 613/1000, Lasso Training Loss: 736.3450, Lasso Test MSE: 763.9105\n",
            "Epoch 614/1000, Lasso Training Loss: 734.8280, Lasso Test MSE: 762.2789\n",
            "Epoch 615/1000, Lasso Training Loss: 733.3138, Lasso Test MSE: 760.6503\n",
            "Epoch 616/1000, Lasso Training Loss: 731.8024, Lasso Test MSE: 759.0246\n",
            "Epoch 617/1000, Lasso Training Loss: 730.2936, Lasso Test MSE: 757.4019\n",
            "Epoch 618/1000, Lasso Training Loss: 728.7878, Lasso Test MSE: 755.7824\n",
            "Epoch 619/1000, Lasso Training Loss: 727.2845, Lasso Test MSE: 754.1661\n",
            "Epoch 620/1000, Lasso Training Loss: 725.7842, Lasso Test MSE: 752.5525\n",
            "Epoch 621/1000, Lasso Training Loss: 724.2863, Lasso Test MSE: 750.9421\n",
            "Epoch 622/1000, Lasso Training Loss: 722.7914, Lasso Test MSE: 749.3348\n",
            "Epoch 623/1000, Lasso Training Loss: 721.2992, Lasso Test MSE: 747.7305\n",
            "Epoch 624/1000, Lasso Training Loss: 719.8098, Lasso Test MSE: 746.1293\n",
            "Epoch 625/1000, Lasso Training Loss: 718.3229, Lasso Test MSE: 744.5312\n",
            "Epoch 626/1000, Lasso Training Loss: 716.8391, Lasso Test MSE: 742.9359\n",
            "Epoch 627/1000, Lasso Training Loss: 715.3577, Lasso Test MSE: 741.3438\n",
            "Epoch 628/1000, Lasso Training Loss: 713.8791, Lasso Test MSE: 739.7546\n",
            "Epoch 629/1000, Lasso Training Loss: 712.4033, Lasso Test MSE: 738.1686\n",
            "Epoch 630/1000, Lasso Training Loss: 710.9302, Lasso Test MSE: 736.5856\n",
            "Epoch 631/1000, Lasso Training Loss: 709.4598, Lasso Test MSE: 735.0055\n",
            "Epoch 632/1000, Lasso Training Loss: 707.9922, Lasso Test MSE: 733.4286\n",
            "Epoch 633/1000, Lasso Training Loss: 706.5272, Lasso Test MSE: 731.8545\n",
            "Epoch 634/1000, Lasso Training Loss: 705.0649, Lasso Test MSE: 730.2836\n",
            "Epoch 635/1000, Lasso Training Loss: 703.6053, Lasso Test MSE: 728.7155\n",
            "Epoch 636/1000, Lasso Training Loss: 702.1486, Lasso Test MSE: 727.1506\n",
            "Epoch 637/1000, Lasso Training Loss: 700.6945, Lasso Test MSE: 725.5886\n",
            "Epoch 638/1000, Lasso Training Loss: 699.2431, Lasso Test MSE: 724.0297\n",
            "Epoch 639/1000, Lasso Training Loss: 697.7945, Lasso Test MSE: 722.4735\n",
            "Epoch 640/1000, Lasso Training Loss: 696.3483, Lasso Test MSE: 720.9206\n",
            "Epoch 641/1000, Lasso Training Loss: 694.9050, Lasso Test MSE: 719.3705\n",
            "Epoch 642/1000, Lasso Training Loss: 693.4644, Lasso Test MSE: 717.8237\n",
            "Epoch 643/1000, Lasso Training Loss: 692.0267, Lasso Test MSE: 716.2795\n",
            "Epoch 644/1000, Lasso Training Loss: 690.5914, Lasso Test MSE: 714.7385\n",
            "Epoch 645/1000, Lasso Training Loss: 689.1589, Lasso Test MSE: 713.2005\n",
            "Epoch 646/1000, Lasso Training Loss: 687.7292, Lasso Test MSE: 711.6653\n",
            "Epoch 647/1000, Lasso Training Loss: 686.3020, Lasso Test MSE: 710.1334\n",
            "Epoch 648/1000, Lasso Training Loss: 684.8776, Lasso Test MSE: 708.6042\n",
            "Epoch 649/1000, Lasso Training Loss: 683.4557, Lasso Test MSE: 707.0782\n",
            "Epoch 650/1000, Lasso Training Loss: 682.0369, Lasso Test MSE: 705.5551\n",
            "Epoch 651/1000, Lasso Training Loss: 680.6205, Lasso Test MSE: 704.0347\n",
            "Epoch 652/1000, Lasso Training Loss: 679.2067, Lasso Test MSE: 702.5176\n",
            "Epoch 653/1000, Lasso Training Loss: 677.7957, Lasso Test MSE: 701.0033\n",
            "Epoch 654/1000, Lasso Training Loss: 676.3873, Lasso Test MSE: 699.4921\n",
            "Epoch 655/1000, Lasso Training Loss: 674.9818, Lasso Test MSE: 697.9836\n",
            "Epoch 656/1000, Lasso Training Loss: 673.5786, Lasso Test MSE: 696.4781\n",
            "Epoch 657/1000, Lasso Training Loss: 672.1782, Lasso Test MSE: 694.9756\n",
            "Epoch 658/1000, Lasso Training Loss: 670.7805, Lasso Test MSE: 693.4762\n",
            "Epoch 659/1000, Lasso Training Loss: 669.3854, Lasso Test MSE: 691.9796\n",
            "Epoch 660/1000, Lasso Training Loss: 667.9931, Lasso Test MSE: 690.4859\n",
            "Epoch 661/1000, Lasso Training Loss: 666.6033, Lasso Test MSE: 688.9953\n",
            "Epoch 662/1000, Lasso Training Loss: 665.2163, Lasso Test MSE: 687.5074\n",
            "Epoch 663/1000, Lasso Training Loss: 663.8318, Lasso Test MSE: 686.0225\n",
            "Epoch 664/1000, Lasso Training Loss: 662.4501, Lasso Test MSE: 684.5406\n",
            "Epoch 665/1000, Lasso Training Loss: 661.0710, Lasso Test MSE: 683.0619\n",
            "Epoch 666/1000, Lasso Training Loss: 659.6947, Lasso Test MSE: 681.5858\n",
            "Epoch 667/1000, Lasso Training Loss: 658.3208, Lasso Test MSE: 680.1125\n",
            "Epoch 668/1000, Lasso Training Loss: 656.9495, Lasso Test MSE: 678.6423\n",
            "Epoch 669/1000, Lasso Training Loss: 655.5809, Lasso Test MSE: 677.1749\n",
            "Epoch 670/1000, Lasso Training Loss: 654.2149, Lasso Test MSE: 675.7104\n",
            "Epoch 671/1000, Lasso Training Loss: 652.8517, Lasso Test MSE: 674.2489\n",
            "Epoch 672/1000, Lasso Training Loss: 651.4910, Lasso Test MSE: 672.7905\n",
            "Epoch 673/1000, Lasso Training Loss: 650.1330, Lasso Test MSE: 671.3347\n",
            "Epoch 674/1000, Lasso Training Loss: 648.7775, Lasso Test MSE: 669.8819\n",
            "Epoch 675/1000, Lasso Training Loss: 647.4248, Lasso Test MSE: 668.4320\n",
            "Epoch 676/1000, Lasso Training Loss: 646.0746, Lasso Test MSE: 666.9852\n",
            "Epoch 677/1000, Lasso Training Loss: 644.7272, Lasso Test MSE: 665.5409\n",
            "Epoch 678/1000, Lasso Training Loss: 643.3822, Lasso Test MSE: 664.0997\n",
            "Epoch 679/1000, Lasso Training Loss: 642.0400, Lasso Test MSE: 662.6611\n",
            "Epoch 680/1000, Lasso Training Loss: 640.7001, Lasso Test MSE: 661.2256\n",
            "Epoch 681/1000, Lasso Training Loss: 639.3629, Lasso Test MSE: 659.7930\n",
            "Epoch 682/1000, Lasso Training Loss: 638.0283, Lasso Test MSE: 658.3631\n",
            "Epoch 683/1000, Lasso Training Loss: 636.6962, Lasso Test MSE: 656.9361\n",
            "Epoch 684/1000, Lasso Training Loss: 635.3669, Lasso Test MSE: 655.5122\n",
            "Epoch 685/1000, Lasso Training Loss: 634.0403, Lasso Test MSE: 654.0910\n",
            "Epoch 686/1000, Lasso Training Loss: 632.7161, Lasso Test MSE: 652.6727\n",
            "Epoch 687/1000, Lasso Training Loss: 631.3945, Lasso Test MSE: 651.2573\n",
            "Epoch 688/1000, Lasso Training Loss: 630.0756, Lasso Test MSE: 649.8446\n",
            "Epoch 689/1000, Lasso Training Loss: 628.7592, Lasso Test MSE: 648.4348\n",
            "Epoch 690/1000, Lasso Training Loss: 627.4454, Lasso Test MSE: 647.0279\n",
            "Epoch 691/1000, Lasso Training Loss: 626.1341, Lasso Test MSE: 645.6238\n",
            "Epoch 692/1000, Lasso Training Loss: 624.8255, Lasso Test MSE: 644.2225\n",
            "Epoch 693/1000, Lasso Training Loss: 623.5194, Lasso Test MSE: 642.8242\n",
            "Epoch 694/1000, Lasso Training Loss: 622.2158, Lasso Test MSE: 641.4284\n",
            "Epoch 695/1000, Lasso Training Loss: 620.9149, Lasso Test MSE: 640.0356\n",
            "Epoch 696/1000, Lasso Training Loss: 619.6164, Lasso Test MSE: 638.6456\n",
            "Epoch 697/1000, Lasso Training Loss: 618.3204, Lasso Test MSE: 637.2584\n",
            "Epoch 698/1000, Lasso Training Loss: 617.0272, Lasso Test MSE: 635.8741\n",
            "Epoch 699/1000, Lasso Training Loss: 615.7364, Lasso Test MSE: 634.4926\n",
            "Epoch 700/1000, Lasso Training Loss: 614.4482, Lasso Test MSE: 633.1139\n",
            "Epoch 701/1000, Lasso Training Loss: 613.1626, Lasso Test MSE: 631.7380\n",
            "Epoch 702/1000, Lasso Training Loss: 611.8795, Lasso Test MSE: 630.3646\n",
            "Epoch 703/1000, Lasso Training Loss: 610.5988, Lasso Test MSE: 628.9944\n",
            "Epoch 704/1000, Lasso Training Loss: 609.3209, Lasso Test MSE: 627.6270\n",
            "Epoch 705/1000, Lasso Training Loss: 608.0453, Lasso Test MSE: 626.2622\n",
            "Epoch 706/1000, Lasso Training Loss: 606.7724, Lasso Test MSE: 624.9002\n",
            "Epoch 707/1000, Lasso Training Loss: 605.5019, Lasso Test MSE: 623.5410\n",
            "Epoch 708/1000, Lasso Training Loss: 604.2339, Lasso Test MSE: 622.1847\n",
            "Epoch 709/1000, Lasso Training Loss: 602.9687, Lasso Test MSE: 620.8311\n",
            "Epoch 710/1000, Lasso Training Loss: 601.7059, Lasso Test MSE: 619.4802\n",
            "Epoch 711/1000, Lasso Training Loss: 600.4454, Lasso Test MSE: 618.1320\n",
            "Epoch 712/1000, Lasso Training Loss: 599.1876, Lasso Test MSE: 616.7869\n",
            "Epoch 713/1000, Lasso Training Loss: 597.9323, Lasso Test MSE: 615.4443\n",
            "Epoch 714/1000, Lasso Training Loss: 596.6795, Lasso Test MSE: 614.1044\n",
            "Epoch 715/1000, Lasso Training Loss: 595.4292, Lasso Test MSE: 612.7673\n",
            "Epoch 716/1000, Lasso Training Loss: 594.1813, Lasso Test MSE: 611.4331\n",
            "Epoch 717/1000, Lasso Training Loss: 592.9360, Lasso Test MSE: 610.1016\n",
            "Epoch 718/1000, Lasso Training Loss: 591.6933, Lasso Test MSE: 608.7728\n",
            "Epoch 719/1000, Lasso Training Loss: 590.4529, Lasso Test MSE: 607.4468\n",
            "Epoch 720/1000, Lasso Training Loss: 589.2151, Lasso Test MSE: 606.1234\n",
            "Epoch 721/1000, Lasso Training Loss: 587.9798, Lasso Test MSE: 604.8028\n",
            "Epoch 722/1000, Lasso Training Loss: 586.7469, Lasso Test MSE: 603.4849\n",
            "Epoch 723/1000, Lasso Training Loss: 585.5165, Lasso Test MSE: 602.1697\n",
            "Epoch 724/1000, Lasso Training Loss: 584.2887, Lasso Test MSE: 600.8574\n",
            "Epoch 725/1000, Lasso Training Loss: 583.0632, Lasso Test MSE: 599.5476\n",
            "Epoch 726/1000, Lasso Training Loss: 581.8403, Lasso Test MSE: 598.2408\n",
            "Epoch 727/1000, Lasso Training Loss: 580.6199, Lasso Test MSE: 596.9364\n",
            "Epoch 728/1000, Lasso Training Loss: 579.4019, Lasso Test MSE: 595.6348\n",
            "Epoch 729/1000, Lasso Training Loss: 578.1863, Lasso Test MSE: 594.3361\n",
            "Epoch 730/1000, Lasso Training Loss: 576.9733, Lasso Test MSE: 593.0399\n",
            "Epoch 731/1000, Lasso Training Loss: 575.7626, Lasso Test MSE: 591.7463\n",
            "Epoch 732/1000, Lasso Training Loss: 574.5544, Lasso Test MSE: 590.4556\n",
            "Epoch 733/1000, Lasso Training Loss: 573.3486, Lasso Test MSE: 589.1674\n",
            "Epoch 734/1000, Lasso Training Loss: 572.1454, Lasso Test MSE: 587.8821\n",
            "Epoch 735/1000, Lasso Training Loss: 570.9446, Lasso Test MSE: 586.5994\n",
            "Epoch 736/1000, Lasso Training Loss: 569.7462, Lasso Test MSE: 585.3193\n",
            "Epoch 737/1000, Lasso Training Loss: 568.5503, Lasso Test MSE: 584.0419\n",
            "Epoch 738/1000, Lasso Training Loss: 567.3568, Lasso Test MSE: 582.7672\n",
            "Epoch 739/1000, Lasso Training Loss: 566.1656, Lasso Test MSE: 581.4951\n",
            "Epoch 740/1000, Lasso Training Loss: 564.9770, Lasso Test MSE: 580.2258\n",
            "Epoch 741/1000, Lasso Training Loss: 563.7908, Lasso Test MSE: 578.9590\n",
            "Epoch 742/1000, Lasso Training Loss: 562.6071, Lasso Test MSE: 577.6949\n",
            "Epoch 743/1000, Lasso Training Loss: 561.4255, Lasso Test MSE: 576.4337\n",
            "Epoch 744/1000, Lasso Training Loss: 560.2466, Lasso Test MSE: 575.1747\n",
            "Epoch 745/1000, Lasso Training Loss: 559.0700, Lasso Test MSE: 573.9187\n",
            "Epoch 746/1000, Lasso Training Loss: 557.8958, Lasso Test MSE: 572.6652\n",
            "Epoch 747/1000, Lasso Training Loss: 556.7241, Lasso Test MSE: 571.4144\n",
            "Epoch 748/1000, Lasso Training Loss: 555.5548, Lasso Test MSE: 570.1660\n",
            "Epoch 749/1000, Lasso Training Loss: 554.3878, Lasso Test MSE: 568.9205\n",
            "Epoch 750/1000, Lasso Training Loss: 553.2233, Lasso Test MSE: 567.6775\n",
            "Epoch 751/1000, Lasso Training Loss: 552.0610, Lasso Test MSE: 566.4371\n",
            "Epoch 752/1000, Lasso Training Loss: 550.9012, Lasso Test MSE: 565.1993\n",
            "Epoch 753/1000, Lasso Training Loss: 549.7438, Lasso Test MSE: 563.9642\n",
            "Epoch 754/1000, Lasso Training Loss: 548.5889, Lasso Test MSE: 562.7318\n",
            "Epoch 755/1000, Lasso Training Loss: 547.4362, Lasso Test MSE: 561.5019\n",
            "Epoch 756/1000, Lasso Training Loss: 546.2860, Lasso Test MSE: 560.2745\n",
            "Epoch 757/1000, Lasso Training Loss: 545.1381, Lasso Test MSE: 559.0499\n",
            "Epoch 758/1000, Lasso Training Loss: 543.9926, Lasso Test MSE: 557.8276\n",
            "Epoch 759/1000, Lasso Training Loss: 542.8494, Lasso Test MSE: 556.6080\n",
            "Epoch 760/1000, Lasso Training Loss: 541.7086, Lasso Test MSE: 555.3911\n",
            "Epoch 761/1000, Lasso Training Loss: 540.5701, Lasso Test MSE: 554.1766\n",
            "Epoch 762/1000, Lasso Training Loss: 539.4340, Lasso Test MSE: 552.9650\n",
            "Epoch 763/1000, Lasso Training Loss: 538.3004, Lasso Test MSE: 551.7558\n",
            "Epoch 764/1000, Lasso Training Loss: 537.1690, Lasso Test MSE: 550.5491\n",
            "Epoch 765/1000, Lasso Training Loss: 536.0400, Lasso Test MSE: 549.3451\n",
            "Epoch 766/1000, Lasso Training Loss: 534.9135, Lasso Test MSE: 548.1436\n",
            "Epoch 767/1000, Lasso Training Loss: 533.7890, Lasso Test MSE: 546.9445\n",
            "Epoch 768/1000, Lasso Training Loss: 532.6670, Lasso Test MSE: 545.7481\n",
            "Epoch 769/1000, Lasso Training Loss: 531.5473, Lasso Test MSE: 544.5543\n",
            "Epoch 770/1000, Lasso Training Loss: 530.4300, Lasso Test MSE: 543.3629\n",
            "Epoch 771/1000, Lasso Training Loss: 529.3149, Lasso Test MSE: 542.1743\n",
            "Epoch 772/1000, Lasso Training Loss: 528.2024, Lasso Test MSE: 540.9879\n",
            "Epoch 773/1000, Lasso Training Loss: 527.0919, Lasso Test MSE: 539.8043\n",
            "Epoch 774/1000, Lasso Training Loss: 525.9839, Lasso Test MSE: 538.6230\n",
            "Epoch 775/1000, Lasso Training Loss: 524.8781, Lasso Test MSE: 537.4445\n",
            "Epoch 776/1000, Lasso Training Loss: 523.7747, Lasso Test MSE: 536.2683\n",
            "Epoch 777/1000, Lasso Training Loss: 522.6735, Lasso Test MSE: 535.0947\n",
            "Epoch 778/1000, Lasso Training Loss: 521.5748, Lasso Test MSE: 533.9237\n",
            "Epoch 779/1000, Lasso Training Loss: 520.4783, Lasso Test MSE: 532.7551\n",
            "Epoch 780/1000, Lasso Training Loss: 519.3840, Lasso Test MSE: 531.5891\n",
            "Epoch 781/1000, Lasso Training Loss: 518.2921, Lasso Test MSE: 530.4255\n",
            "Epoch 782/1000, Lasso Training Loss: 517.2025, Lasso Test MSE: 529.2645\n",
            "Epoch 783/1000, Lasso Training Loss: 516.1152, Lasso Test MSE: 528.1060\n",
            "Epoch 784/1000, Lasso Training Loss: 515.0301, Lasso Test MSE: 526.9499\n",
            "Epoch 785/1000, Lasso Training Loss: 513.9473, Lasso Test MSE: 525.7963\n",
            "Epoch 786/1000, Lasso Training Loss: 512.8668, Lasso Test MSE: 524.6451\n",
            "Epoch 787/1000, Lasso Training Loss: 511.7886, Lasso Test MSE: 523.4966\n",
            "Epoch 788/1000, Lasso Training Loss: 510.7126, Lasso Test MSE: 522.3503\n",
            "Epoch 789/1000, Lasso Training Loss: 509.6389, Lasso Test MSE: 521.2068\n",
            "Epoch 790/1000, Lasso Training Loss: 508.5675, Lasso Test MSE: 520.0656\n",
            "Epoch 791/1000, Lasso Training Loss: 507.4983, Lasso Test MSE: 518.9268\n",
            "Epoch 792/1000, Lasso Training Loss: 506.4315, Lasso Test MSE: 517.7905\n",
            "Epoch 793/1000, Lasso Training Loss: 505.3668, Lasso Test MSE: 516.6568\n",
            "Epoch 794/1000, Lasso Training Loss: 504.3043, Lasso Test MSE: 515.5254\n",
            "Epoch 795/1000, Lasso Training Loss: 503.2441, Lasso Test MSE: 514.3964\n",
            "Epoch 796/1000, Lasso Training Loss: 502.1862, Lasso Test MSE: 513.2700\n",
            "Epoch 797/1000, Lasso Training Loss: 501.1306, Lasso Test MSE: 512.1460\n",
            "Epoch 798/1000, Lasso Training Loss: 500.0772, Lasso Test MSE: 511.0244\n",
            "Epoch 799/1000, Lasso Training Loss: 499.0259, Lasso Test MSE: 509.9050\n",
            "Epoch 800/1000, Lasso Training Loss: 497.9768, Lasso Test MSE: 508.7885\n",
            "Epoch 801/1000, Lasso Training Loss: 496.9302, Lasso Test MSE: 507.6742\n",
            "Epoch 802/1000, Lasso Training Loss: 495.8857, Lasso Test MSE: 506.5622\n",
            "Epoch 803/1000, Lasso Training Loss: 494.8432, Lasso Test MSE: 505.4529\n",
            "Epoch 804/1000, Lasso Training Loss: 493.8032, Lasso Test MSE: 504.3458\n",
            "Epoch 805/1000, Lasso Training Loss: 492.7654, Lasso Test MSE: 503.2410\n",
            "Epoch 806/1000, Lasso Training Loss: 491.7296, Lasso Test MSE: 502.1388\n",
            "Epoch 807/1000, Lasso Training Loss: 490.6961, Lasso Test MSE: 501.0390\n",
            "Epoch 808/1000, Lasso Training Loss: 489.6649, Lasso Test MSE: 499.9417\n",
            "Epoch 809/1000, Lasso Training Loss: 488.6359, Lasso Test MSE: 498.8466\n",
            "Epoch 810/1000, Lasso Training Loss: 487.6090, Lasso Test MSE: 497.7539\n",
            "Epoch 811/1000, Lasso Training Loss: 486.5843, Lasso Test MSE: 496.6637\n",
            "Epoch 812/1000, Lasso Training Loss: 485.5619, Lasso Test MSE: 495.5756\n",
            "Epoch 813/1000, Lasso Training Loss: 484.5415, Lasso Test MSE: 494.4902\n",
            "Epoch 814/1000, Lasso Training Loss: 483.5233, Lasso Test MSE: 493.4070\n",
            "Epoch 815/1000, Lasso Training Loss: 482.5073, Lasso Test MSE: 492.3263\n",
            "Epoch 816/1000, Lasso Training Loss: 481.4936, Lasso Test MSE: 491.2479\n",
            "Epoch 817/1000, Lasso Training Loss: 480.4820, Lasso Test MSE: 490.1719\n",
            "Epoch 818/1000, Lasso Training Loss: 479.4726, Lasso Test MSE: 489.0981\n",
            "Epoch 819/1000, Lasso Training Loss: 478.4652, Lasso Test MSE: 488.0269\n",
            "Epoch 820/1000, Lasso Training Loss: 477.4603, Lasso Test MSE: 486.9579\n",
            "Epoch 821/1000, Lasso Training Loss: 476.4573, Lasso Test MSE: 485.8912\n",
            "Epoch 822/1000, Lasso Training Loss: 475.4565, Lasso Test MSE: 484.8269\n",
            "Epoch 823/1000, Lasso Training Loss: 474.4578, Lasso Test MSE: 483.7650\n",
            "Epoch 824/1000, Lasso Training Loss: 473.4613, Lasso Test MSE: 482.7054\n",
            "Epoch 825/1000, Lasso Training Loss: 472.4670, Lasso Test MSE: 481.6479\n",
            "Epoch 826/1000, Lasso Training Loss: 471.4747, Lasso Test MSE: 480.5930\n",
            "Epoch 827/1000, Lasso Training Loss: 470.4847, Lasso Test MSE: 479.5405\n",
            "Epoch 828/1000, Lasso Training Loss: 469.4968, Lasso Test MSE: 478.4902\n",
            "Epoch 829/1000, Lasso Training Loss: 468.5110, Lasso Test MSE: 477.4421\n",
            "Epoch 830/1000, Lasso Training Loss: 467.5273, Lasso Test MSE: 476.3964\n",
            "Epoch 831/1000, Lasso Training Loss: 466.5457, Lasso Test MSE: 475.3531\n",
            "Epoch 832/1000, Lasso Training Loss: 465.5663, Lasso Test MSE: 474.3119\n",
            "Epoch 833/1000, Lasso Training Loss: 464.5890, Lasso Test MSE: 473.2731\n",
            "Epoch 834/1000, Lasso Training Loss: 463.6137, Lasso Test MSE: 472.2367\n",
            "Epoch 835/1000, Lasso Training Loss: 462.6407, Lasso Test MSE: 471.2024\n",
            "Epoch 836/1000, Lasso Training Loss: 461.6697, Lasso Test MSE: 470.1706\n",
            "Epoch 837/1000, Lasso Training Loss: 460.7008, Lasso Test MSE: 469.1409\n",
            "Epoch 838/1000, Lasso Training Loss: 459.7340, Lasso Test MSE: 468.1136\n",
            "Epoch 839/1000, Lasso Training Loss: 458.7693, Lasso Test MSE: 467.0885\n",
            "Epoch 840/1000, Lasso Training Loss: 457.8067, Lasso Test MSE: 466.0658\n",
            "Epoch 841/1000, Lasso Training Loss: 456.8463, Lasso Test MSE: 465.0452\n",
            "Epoch 842/1000, Lasso Training Loss: 455.8879, Lasso Test MSE: 464.0269\n",
            "Epoch 843/1000, Lasso Training Loss: 454.9315, Lasso Test MSE: 463.0109\n",
            "Epoch 844/1000, Lasso Training Loss: 453.9773, Lasso Test MSE: 461.9972\n",
            "Epoch 845/1000, Lasso Training Loss: 453.0252, Lasso Test MSE: 460.9856\n",
            "Epoch 846/1000, Lasso Training Loss: 452.0751, Lasso Test MSE: 459.9765\n",
            "Epoch 847/1000, Lasso Training Loss: 451.1271, Lasso Test MSE: 458.9695\n",
            "Epoch 848/1000, Lasso Training Loss: 450.1811, Lasso Test MSE: 457.9648\n",
            "Epoch 849/1000, Lasso Training Loss: 449.2373, Lasso Test MSE: 456.9622\n",
            "Epoch 850/1000, Lasso Training Loss: 448.2955, Lasso Test MSE: 455.9619\n",
            "Epoch 851/1000, Lasso Training Loss: 447.3557, Lasso Test MSE: 454.9639\n",
            "Epoch 852/1000, Lasso Training Loss: 446.4179, Lasso Test MSE: 453.9681\n",
            "Epoch 853/1000, Lasso Training Loss: 445.4823, Lasso Test MSE: 452.9743\n",
            "Epoch 854/1000, Lasso Training Loss: 444.5486, Lasso Test MSE: 451.9830\n",
            "Epoch 855/1000, Lasso Training Loss: 443.6171, Lasso Test MSE: 450.9937\n",
            "Epoch 856/1000, Lasso Training Loss: 442.6875, Lasso Test MSE: 450.0068\n",
            "Epoch 857/1000, Lasso Training Loss: 441.7600, Lasso Test MSE: 449.0219\n",
            "Epoch 858/1000, Lasso Training Loss: 440.8345, Lasso Test MSE: 448.0394\n",
            "Epoch 859/1000, Lasso Training Loss: 439.9111, Lasso Test MSE: 447.0591\n",
            "Epoch 860/1000, Lasso Training Loss: 438.9897, Lasso Test MSE: 446.0808\n",
            "Epoch 861/1000, Lasso Training Loss: 438.0702, Lasso Test MSE: 445.1049\n",
            "Epoch 862/1000, Lasso Training Loss: 437.1529, Lasso Test MSE: 444.1311\n",
            "Epoch 863/1000, Lasso Training Loss: 436.2375, Lasso Test MSE: 443.1594\n",
            "Epoch 864/1000, Lasso Training Loss: 435.3241, Lasso Test MSE: 442.1899\n",
            "Epoch 865/1000, Lasso Training Loss: 434.4128, Lasso Test MSE: 441.2225\n",
            "Epoch 866/1000, Lasso Training Loss: 433.5034, Lasso Test MSE: 440.2575\n",
            "Epoch 867/1000, Lasso Training Loss: 432.5960, Lasso Test MSE: 439.2945\n",
            "Epoch 868/1000, Lasso Training Loss: 431.6907, Lasso Test MSE: 438.3336\n",
            "Epoch 869/1000, Lasso Training Loss: 430.7874, Lasso Test MSE: 437.3750\n",
            "Epoch 870/1000, Lasso Training Loss: 429.8860, Lasso Test MSE: 436.4187\n",
            "Epoch 871/1000, Lasso Training Loss: 428.9867, Lasso Test MSE: 435.4643\n",
            "Epoch 872/1000, Lasso Training Loss: 428.0893, Lasso Test MSE: 434.5121\n",
            "Epoch 873/1000, Lasso Training Loss: 427.1939, Lasso Test MSE: 433.5621\n",
            "Epoch 874/1000, Lasso Training Loss: 426.3005, Lasso Test MSE: 432.6140\n",
            "Epoch 875/1000, Lasso Training Loss: 425.4089, Lasso Test MSE: 431.6684\n",
            "Epoch 876/1000, Lasso Training Loss: 424.5196, Lasso Test MSE: 430.7248\n",
            "Epoch 877/1000, Lasso Training Loss: 423.6320, Lasso Test MSE: 429.7832\n",
            "Epoch 878/1000, Lasso Training Loss: 422.7465, Lasso Test MSE: 428.8439\n",
            "Epoch 879/1000, Lasso Training Loss: 421.8629, Lasso Test MSE: 427.9066\n",
            "Epoch 880/1000, Lasso Training Loss: 420.9813, Lasso Test MSE: 426.9714\n",
            "Epoch 881/1000, Lasso Training Loss: 420.1015, Lasso Test MSE: 426.0383\n",
            "Epoch 882/1000, Lasso Training Loss: 419.2238, Lasso Test MSE: 425.1074\n",
            "Epoch 883/1000, Lasso Training Loss: 418.3481, Lasso Test MSE: 424.1786\n",
            "Epoch 884/1000, Lasso Training Loss: 417.4743, Lasso Test MSE: 423.2519\n",
            "Epoch 885/1000, Lasso Training Loss: 416.6024, Lasso Test MSE: 422.3273\n",
            "Epoch 886/1000, Lasso Training Loss: 415.7325, Lasso Test MSE: 421.4047\n",
            "Epoch 887/1000, Lasso Training Loss: 414.8644, Lasso Test MSE: 420.4843\n",
            "Epoch 888/1000, Lasso Training Loss: 413.9984, Lasso Test MSE: 419.5660\n",
            "Epoch 889/1000, Lasso Training Loss: 413.1343, Lasso Test MSE: 418.6497\n",
            "Epoch 890/1000, Lasso Training Loss: 412.2721, Lasso Test MSE: 417.7354\n",
            "Epoch 891/1000, Lasso Training Loss: 411.4117, Lasso Test MSE: 416.8234\n",
            "Epoch 892/1000, Lasso Training Loss: 410.5534, Lasso Test MSE: 415.9132\n",
            "Epoch 893/1000, Lasso Training Loss: 409.6969, Lasso Test MSE: 415.0053\n",
            "Epoch 894/1000, Lasso Training Loss: 408.8424, Lasso Test MSE: 414.0993\n",
            "Epoch 895/1000, Lasso Training Loss: 407.9897, Lasso Test MSE: 413.1954\n",
            "Epoch 896/1000, Lasso Training Loss: 407.1389, Lasso Test MSE: 412.2936\n",
            "Epoch 897/1000, Lasso Training Loss: 406.2902, Lasso Test MSE: 411.3940\n",
            "Epoch 898/1000, Lasso Training Loss: 405.4433, Lasso Test MSE: 410.4962\n",
            "Epoch 899/1000, Lasso Training Loss: 404.5982, Lasso Test MSE: 409.6006\n",
            "Epoch 900/1000, Lasso Training Loss: 403.7551, Lasso Test MSE: 408.7069\n",
            "Epoch 901/1000, Lasso Training Loss: 402.9138, Lasso Test MSE: 407.8153\n",
            "Epoch 902/1000, Lasso Training Loss: 402.0744, Lasso Test MSE: 406.9257\n",
            "Epoch 903/1000, Lasso Training Loss: 401.2369, Lasso Test MSE: 406.0382\n",
            "Epoch 904/1000, Lasso Training Loss: 400.4014, Lasso Test MSE: 405.1526\n",
            "Epoch 905/1000, Lasso Training Loss: 399.5676, Lasso Test MSE: 404.2692\n",
            "Epoch 906/1000, Lasso Training Loss: 398.7357, Lasso Test MSE: 403.3878\n",
            "Epoch 907/1000, Lasso Training Loss: 397.9058, Lasso Test MSE: 402.5083\n",
            "Epoch 908/1000, Lasso Training Loss: 397.0776, Lasso Test MSE: 401.6309\n",
            "Epoch 909/1000, Lasso Training Loss: 396.2514, Lasso Test MSE: 400.7555\n",
            "Epoch 910/1000, Lasso Training Loss: 395.4270, Lasso Test MSE: 399.8821\n",
            "Epoch 911/1000, Lasso Training Loss: 394.6045, Lasso Test MSE: 399.0105\n",
            "Epoch 912/1000, Lasso Training Loss: 393.7838, Lasso Test MSE: 398.1412\n",
            "Epoch 913/1000, Lasso Training Loss: 392.9649, Lasso Test MSE: 397.2736\n",
            "Epoch 914/1000, Lasso Training Loss: 392.1479, Lasso Test MSE: 396.4082\n",
            "Epoch 915/1000, Lasso Training Loss: 391.3328, Lasso Test MSE: 395.5448\n",
            "Epoch 916/1000, Lasso Training Loss: 390.5195, Lasso Test MSE: 394.6833\n",
            "Epoch 917/1000, Lasso Training Loss: 389.7080, Lasso Test MSE: 393.8238\n",
            "Epoch 918/1000, Lasso Training Loss: 388.8984, Lasso Test MSE: 392.9662\n",
            "Epoch 919/1000, Lasso Training Loss: 388.0906, Lasso Test MSE: 392.1106\n",
            "Epoch 920/1000, Lasso Training Loss: 387.2846, Lasso Test MSE: 391.2570\n",
            "Epoch 921/1000, Lasso Training Loss: 386.4804, Lasso Test MSE: 390.4054\n",
            "Epoch 922/1000, Lasso Training Loss: 385.6781, Lasso Test MSE: 389.5556\n",
            "Epoch 923/1000, Lasso Training Loss: 384.8776, Lasso Test MSE: 388.7080\n",
            "Epoch 924/1000, Lasso Training Loss: 384.0789, Lasso Test MSE: 387.8622\n",
            "Epoch 925/1000, Lasso Training Loss: 383.2820, Lasso Test MSE: 387.0183\n",
            "Epoch 926/1000, Lasso Training Loss: 382.4869, Lasso Test MSE: 386.1764\n",
            "Epoch 927/1000, Lasso Training Loss: 381.6936, Lasso Test MSE: 385.3365\n",
            "Epoch 928/1000, Lasso Training Loss: 380.9022, Lasso Test MSE: 384.4985\n",
            "Epoch 929/1000, Lasso Training Loss: 380.1125, Lasso Test MSE: 383.6623\n",
            "Epoch 930/1000, Lasso Training Loss: 379.3246, Lasso Test MSE: 382.8283\n",
            "Epoch 931/1000, Lasso Training Loss: 378.5385, Lasso Test MSE: 381.9959\n",
            "Epoch 932/1000, Lasso Training Loss: 377.7542, Lasso Test MSE: 381.1657\n",
            "Epoch 933/1000, Lasso Training Loss: 376.9717, Lasso Test MSE: 380.3373\n",
            "Epoch 934/1000, Lasso Training Loss: 376.1909, Lasso Test MSE: 379.5108\n",
            "Epoch 935/1000, Lasso Training Loss: 375.4120, Lasso Test MSE: 378.6863\n",
            "Epoch 936/1000, Lasso Training Loss: 374.6348, Lasso Test MSE: 377.8635\n",
            "Epoch 937/1000, Lasso Training Loss: 373.8593, Lasso Test MSE: 377.0428\n",
            "Epoch 938/1000, Lasso Training Loss: 373.0858, Lasso Test MSE: 376.2240\n",
            "Epoch 939/1000, Lasso Training Loss: 372.3139, Lasso Test MSE: 375.4070\n",
            "Epoch 940/1000, Lasso Training Loss: 371.5438, Lasso Test MSE: 374.5919\n",
            "Epoch 941/1000, Lasso Training Loss: 370.7754, Lasso Test MSE: 373.7788\n",
            "Epoch 942/1000, Lasso Training Loss: 370.0089, Lasso Test MSE: 372.9677\n",
            "Epoch 943/1000, Lasso Training Loss: 369.2441, Lasso Test MSE: 372.1582\n",
            "Epoch 944/1000, Lasso Training Loss: 368.4810, Lasso Test MSE: 371.3506\n",
            "Epoch 945/1000, Lasso Training Loss: 367.7196, Lasso Test MSE: 370.5449\n",
            "Epoch 946/1000, Lasso Training Loss: 366.9600, Lasso Test MSE: 369.7411\n",
            "Epoch 947/1000, Lasso Training Loss: 366.2021, Lasso Test MSE: 368.9392\n",
            "Epoch 948/1000, Lasso Training Loss: 365.4460, Lasso Test MSE: 368.1393\n",
            "Epoch 949/1000, Lasso Training Loss: 364.6917, Lasso Test MSE: 367.3411\n",
            "Epoch 950/1000, Lasso Training Loss: 363.9391, Lasso Test MSE: 366.5446\n",
            "Epoch 951/1000, Lasso Training Loss: 363.1881, Lasso Test MSE: 365.7502\n",
            "Epoch 952/1000, Lasso Training Loss: 362.4389, Lasso Test MSE: 364.9576\n",
            "Epoch 953/1000, Lasso Training Loss: 361.6915, Lasso Test MSE: 364.1668\n",
            "Epoch 954/1000, Lasso Training Loss: 360.9457, Lasso Test MSE: 363.3779\n",
            "Epoch 955/1000, Lasso Training Loss: 360.2016, Lasso Test MSE: 362.5908\n",
            "Epoch 956/1000, Lasso Training Loss: 359.4594, Lasso Test MSE: 361.8055\n",
            "Epoch 957/1000, Lasso Training Loss: 358.7187, Lasso Test MSE: 361.0221\n",
            "Epoch 958/1000, Lasso Training Loss: 357.9798, Lasso Test MSE: 360.2405\n",
            "Epoch 959/1000, Lasso Training Loss: 357.2426, Lasso Test MSE: 359.4606\n",
            "Epoch 960/1000, Lasso Training Loss: 356.5070, Lasso Test MSE: 358.6827\n",
            "Epoch 961/1000, Lasso Training Loss: 355.7733, Lasso Test MSE: 357.9065\n",
            "Epoch 962/1000, Lasso Training Loss: 355.0412, Lasso Test MSE: 357.1323\n",
            "Epoch 963/1000, Lasso Training Loss: 354.3107, Lasso Test MSE: 356.3597\n",
            "Epoch 964/1000, Lasso Training Loss: 353.5821, Lasso Test MSE: 355.5890\n",
            "Epoch 965/1000, Lasso Training Loss: 352.8550, Lasso Test MSE: 354.8201\n",
            "Epoch 966/1000, Lasso Training Loss: 352.1296, Lasso Test MSE: 354.0530\n",
            "Epoch 967/1000, Lasso Training Loss: 351.4059, Lasso Test MSE: 353.2877\n",
            "Epoch 968/1000, Lasso Training Loss: 350.6839, Lasso Test MSE: 352.5241\n",
            "Epoch 969/1000, Lasso Training Loss: 349.9635, Lasso Test MSE: 351.7625\n",
            "Epoch 970/1000, Lasso Training Loss: 349.2449, Lasso Test MSE: 351.0025\n",
            "Epoch 971/1000, Lasso Training Loss: 348.5279, Lasso Test MSE: 350.2444\n",
            "Epoch 972/1000, Lasso Training Loss: 347.8126, Lasso Test MSE: 349.4881\n",
            "Epoch 973/1000, Lasso Training Loss: 347.0989, Lasso Test MSE: 348.7335\n",
            "Epoch 974/1000, Lasso Training Loss: 346.3869, Lasso Test MSE: 347.9806\n",
            "Epoch 975/1000, Lasso Training Loss: 345.6765, Lasso Test MSE: 347.2296\n",
            "Epoch 976/1000, Lasso Training Loss: 344.9678, Lasso Test MSE: 346.4803\n",
            "Epoch 977/1000, Lasso Training Loss: 344.2607, Lasso Test MSE: 345.7328\n",
            "Epoch 978/1000, Lasso Training Loss: 343.5554, Lasso Test MSE: 344.9870\n",
            "Epoch 979/1000, Lasso Training Loss: 342.8516, Lasso Test MSE: 344.2430\n",
            "Epoch 980/1000, Lasso Training Loss: 342.1494, Lasso Test MSE: 343.5007\n",
            "Epoch 981/1000, Lasso Training Loss: 341.4489, Lasso Test MSE: 342.7602\n",
            "Epoch 982/1000, Lasso Training Loss: 340.7500, Lasso Test MSE: 342.0215\n",
            "Epoch 983/1000, Lasso Training Loss: 340.0528, Lasso Test MSE: 341.2844\n",
            "Epoch 984/1000, Lasso Training Loss: 339.3572, Lasso Test MSE: 340.5491\n",
            "Epoch 985/1000, Lasso Training Loss: 338.6631, Lasso Test MSE: 339.8155\n",
            "Epoch 986/1000, Lasso Training Loss: 337.9708, Lasso Test MSE: 339.0837\n",
            "Epoch 987/1000, Lasso Training Loss: 337.2800, Lasso Test MSE: 338.3537\n",
            "Epoch 988/1000, Lasso Training Loss: 336.5909, Lasso Test MSE: 337.6253\n",
            "Epoch 989/1000, Lasso Training Loss: 335.9034, Lasso Test MSE: 336.8986\n",
            "Epoch 990/1000, Lasso Training Loss: 335.2174, Lasso Test MSE: 336.1737\n",
            "Epoch 991/1000, Lasso Training Loss: 334.5331, Lasso Test MSE: 335.4504\n",
            "Epoch 992/1000, Lasso Training Loss: 333.8504, Lasso Test MSE: 334.7289\n",
            "Epoch 993/1000, Lasso Training Loss: 333.1692, Lasso Test MSE: 334.0092\n",
            "Epoch 994/1000, Lasso Training Loss: 332.4898, Lasso Test MSE: 333.2910\n",
            "Epoch 995/1000, Lasso Training Loss: 331.8118, Lasso Test MSE: 332.5747\n",
            "Epoch 996/1000, Lasso Training Loss: 331.1355, Lasso Test MSE: 331.8600\n",
            "Epoch 997/1000, Lasso Training Loss: 330.4607, Lasso Test MSE: 331.1469\n",
            "Epoch 998/1000, Lasso Training Loss: 329.7875, Lasso Test MSE: 330.4356\n",
            "Epoch 999/1000, Lasso Training Loss: 329.1160, Lasso Test MSE: 329.7261\n",
            "Epoch 1000/1000, Lasso Training Loss: 328.4461, Lasso Test MSE: 329.0182\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BqjXy5HBg320"
      },
      "source": [
        "# 2. Autoencoder (50pt)\n",
        "**Autoencoder is an unsupervised neural network model for learning representations of the input. In the figure below, you can see the structure of an autoencoder network. Given the original input image, we first encode the image using ``Encoder`` to a compressed representation, and reconstruct the image by using ``Decoder`` given the compressed representation. The compressed represesntation can be used as the dimension reduced representation of the original input. In this regard, autoencoder is also known as a model for dimensionality reduction (Recall PCA was also a method for dimensionality reduction). Note that the encoder and the decoder can be any neural network model such as MLP, CNN, MLP, etc.**\n",
        "\n",
        "**For this question, you will use MNIST dataset to implement two versions of autoencoders: 1) An MLP-based autoencoder, and 2) A CNN-based autoencoder. The figure below shows an example of the MLP-based autoencoder. For the MLP-based autoencoder, you should follow the structure of the autoencoder shown in the figure below. For the CNN-based autoencoder, you are free to choose the architecture. You only need to implement ``Autoencoder_MLP`` class and ``Autoencoder_CNN`` class. Note that for ``Autoencoder_MLP``, you should flatten the original image into a vector, whereas for ``Autoencoder_CNN``, you can use the original image without any modification. After implementing these two classes, save the figures and observe the results. Write a few sentences to describe your findings. You do not need to submit the saved figure and the dataset for your final submission.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCT8Q4Lvg320"
      },
      "source": [
        "<div>\n",
        "<img src=\"figures/autoencoder.png\" width=\"700\"/>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWb2OYsyg321",
        "outputId": "c6075a03-38f5-4fce-fda9-1ee3cf85eaf4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch [1/100], loss:0.1862\n",
            "epoch [2/100], loss:0.1730\n",
            "epoch [3/100], loss:0.1608\n",
            "epoch [4/100], loss:0.1637\n",
            "epoch [5/100], loss:0.1420\n",
            "epoch [6/100], loss:0.1640\n",
            "epoch [7/100], loss:0.1513\n",
            "epoch [8/100], loss:0.1333\n",
            "epoch [9/100], loss:0.1437\n",
            "epoch [10/100], loss:0.1464\n",
            "epoch [11/100], loss:0.1441\n",
            "epoch [12/100], loss:0.1376\n",
            "epoch [13/100], loss:0.1233\n",
            "epoch [14/100], loss:0.1300\n",
            "epoch [15/100], loss:0.1418\n",
            "epoch [16/100], loss:0.1284\n",
            "epoch [17/100], loss:0.1278\n",
            "epoch [18/100], loss:0.1340\n",
            "epoch [19/100], loss:0.1278\n",
            "epoch [20/100], loss:0.1285\n",
            "epoch [21/100], loss:0.1380\n",
            "epoch [22/100], loss:0.1305\n",
            "epoch [23/100], loss:0.1377\n",
            "epoch [24/100], loss:0.1282\n",
            "epoch [25/100], loss:0.1351\n",
            "epoch [26/100], loss:0.1367\n",
            "epoch [27/100], loss:0.1338\n",
            "epoch [28/100], loss:0.1344\n",
            "epoch [29/100], loss:0.1312\n",
            "epoch [30/100], loss:0.1294\n",
            "epoch [31/100], loss:0.1214\n",
            "epoch [32/100], loss:0.1275\n",
            "epoch [33/100], loss:0.1235\n",
            "epoch [34/100], loss:0.1331\n",
            "epoch [35/100], loss:0.1425\n",
            "epoch [36/100], loss:0.1281\n",
            "epoch [37/100], loss:0.1280\n",
            "epoch [38/100], loss:0.1174\n",
            "epoch [39/100], loss:0.1193\n",
            "epoch [40/100], loss:0.1256\n",
            "epoch [41/100], loss:0.1319\n",
            "epoch [42/100], loss:0.1285\n",
            "epoch [43/100], loss:0.1318\n",
            "epoch [44/100], loss:0.1210\n",
            "epoch [45/100], loss:0.1242\n",
            "epoch [46/100], loss:0.1328\n",
            "epoch [47/100], loss:0.1239\n",
            "epoch [48/100], loss:0.1302\n",
            "epoch [49/100], loss:0.1245\n",
            "epoch [50/100], loss:0.1322\n",
            "epoch [51/100], loss:0.1103\n",
            "epoch [52/100], loss:0.1344\n",
            "epoch [53/100], loss:0.1212\n",
            "epoch [54/100], loss:0.1300\n",
            "epoch [55/100], loss:0.1198\n",
            "epoch [56/100], loss:0.1249\n",
            "epoch [57/100], loss:0.1205\n",
            "epoch [58/100], loss:0.1151\n",
            "epoch [59/100], loss:0.1233\n",
            "epoch [60/100], loss:0.1341\n",
            "epoch [61/100], loss:0.1266\n",
            "epoch [62/100], loss:0.1253\n",
            "epoch [63/100], loss:0.1316\n",
            "epoch [64/100], loss:0.1289\n",
            "epoch [65/100], loss:0.1259\n",
            "epoch [66/100], loss:0.1339\n",
            "epoch [67/100], loss:0.1189\n",
            "epoch [68/100], loss:0.1250\n",
            "epoch [69/100], loss:0.1239\n",
            "epoch [70/100], loss:0.1367\n",
            "epoch [71/100], loss:0.1177\n",
            "epoch [72/100], loss:0.1105\n",
            "epoch [73/100], loss:0.1182\n",
            "epoch [74/100], loss:0.1291\n",
            "epoch [75/100], loss:0.1317\n",
            "epoch [76/100], loss:0.1240\n",
            "epoch [77/100], loss:0.1316\n",
            "epoch [78/100], loss:0.1296\n",
            "epoch [79/100], loss:0.1191\n",
            "epoch [80/100], loss:0.1264\n",
            "epoch [81/100], loss:0.1285\n",
            "epoch [82/100], loss:0.1268\n",
            "epoch [83/100], loss:0.1296\n",
            "epoch [84/100], loss:0.1257\n",
            "epoch [85/100], loss:0.1256\n",
            "epoch [86/100], loss:0.1327\n",
            "epoch [87/100], loss:0.1293\n",
            "epoch [88/100], loss:0.1336\n",
            "epoch [89/100], loss:0.1209\n",
            "epoch [90/100], loss:0.1200\n",
            "epoch [91/100], loss:0.1254\n",
            "epoch [92/100], loss:0.1320\n",
            "epoch [93/100], loss:0.1128\n",
            "epoch [94/100], loss:0.1177\n",
            "epoch [95/100], loss:0.1281\n",
            "epoch [96/100], loss:0.1361\n",
            "epoch [97/100], loss:0.1255\n",
            "epoch [98/100], loss:0.1243\n",
            "epoch [99/100], loss:0.1139\n",
            "epoch [100/100], loss:0.1170\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "# Make a directory \"saved_img\" if it does not exist\n",
        "if not os.path.exists('./saved_img'):\n",
        "    os.mkdir('./saved_img')\n",
        "\n",
        "\n",
        "def to_img(x):\n",
        "    x = 0.5 * (x + 1)\n",
        "    x = x.clamp(0, 1)\n",
        "    x = x.view(x.size(0), 1, 28, 28)\n",
        "    return x\n",
        "\n",
        "\n",
        "num_epochs = 100\n",
        "batch_size = 128\n",
        "learning_rate = 1e-3\n",
        "\n",
        "img_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5], [0.5])\n",
        "])\n",
        "\n",
        "dataset = MNIST('drive/MyDrive/data', transform=img_transform)\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "\n",
        "class Autoencoder_MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Autoencoder_MLP, self).__init__()\n",
        "        ## Write your answer here\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(28 * 28, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 12),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(12, 3)\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(3, 12),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(12, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 28 * 28),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        ## Write your answer here\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Uncomment below correspondingly\n",
        "\n",
        "model = Autoencoder_MLP().cuda()\n",
        "# model = Autoencoder_CNN().cuda()\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
        "\n",
        "\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for data in dataloader:\n",
        "        img, _ = data\n",
        "        img = img.cuda()  # Move your images to GPU here\n",
        "\n",
        "        # Flatten the image for Autoencoder_MLP (You can remove this line for Autoencoder_CNN)\n",
        "        img = img.view(img.size(0), -1)\n",
        "\n",
        "        # forward pass\n",
        "        output = model(img)\n",
        "        loss = criterion(output, img)\n",
        "        # backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Print log and save images\n",
        "    print('epoch [{}/{}], loss:{:.4f}'.format(epoch + 1, num_epochs, loss.item()))\n",
        "    if epoch % 10 == 0:\n",
        "        pic = to_img(output.cpu().data)\n",
        "        save_image(pic, './saved_img/image_{}.png'.format(epoch))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Autoencoder_CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Autoencoder_CNN, self).__init__()\n",
        "\n",
        "        # Encoder\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(1, 16, 3, stride=3, padding=1),\n",
        "            nn.ReLU(True),\n",
        "            nn.MaxPool2d(2, stride=2),\n",
        "            nn.Conv2d(16, 8, 3, stride=2, padding=1),\n",
        "            nn.ReLU(True),\n",
        "            nn.MaxPool2d(2, stride=1)\n",
        "        )\n",
        "\n",
        "        # Decoder\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.ConvTranspose2d(8, 16, 3, stride=2),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(16, 8, 5, stride=3, padding=1),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(8, 1, 2, stride=2, padding=1),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "        return x\n",
        "\n",
        "model = Autoencoder_CNN().cuda()\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for data in dataloader:\n",
        "        img, _ = data\n",
        "        img = img.cuda()  # Move your images to GPU here\n",
        "\n",
        "        # forward pass\n",
        "        output = model(img)\n",
        "        loss = criterion(output, img)\n",
        "        # backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Print log and save images\n",
        "    print('epoch [{}/{}], loss:{:.4f}'.format(epoch + 1, num_epochs, loss.item()))\n",
        "    if epoch % 10 == 0:\n",
        "        pic = to_img(output.cpu().data)\n",
        "        save_image(pic, './saved_img/CNN_image_{}.png'.format(epoch))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJ9FniT5RFSo",
        "outputId": "3102134b-f61e-406b-b841-584601e589f1"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch [1/100], loss:0.2236\n",
            "epoch [2/100], loss:0.1839\n",
            "epoch [3/100], loss:0.1597\n",
            "epoch [4/100], loss:0.1388\n",
            "epoch [5/100], loss:0.1349\n",
            "epoch [6/100], loss:0.1249\n",
            "epoch [7/100], loss:0.1336\n",
            "epoch [8/100], loss:0.1320\n",
            "epoch [9/100], loss:0.1282\n",
            "epoch [10/100], loss:0.1157\n",
            "epoch [11/100], loss:0.1182\n",
            "epoch [12/100], loss:0.1171\n",
            "epoch [13/100], loss:0.1183\n",
            "epoch [14/100], loss:0.1178\n",
            "epoch [15/100], loss:0.1139\n",
            "epoch [16/100], loss:0.1176\n",
            "epoch [17/100], loss:0.1209\n",
            "epoch [18/100], loss:0.1136\n",
            "epoch [19/100], loss:0.1077\n",
            "epoch [20/100], loss:0.1137\n",
            "epoch [21/100], loss:0.1102\n",
            "epoch [22/100], loss:0.1033\n",
            "epoch [23/100], loss:0.1082\n",
            "epoch [24/100], loss:0.1077\n",
            "epoch [25/100], loss:0.1152\n",
            "epoch [26/100], loss:0.1083\n",
            "epoch [27/100], loss:0.1165\n",
            "epoch [28/100], loss:0.1133\n",
            "epoch [29/100], loss:0.1011\n",
            "epoch [30/100], loss:0.1057\n",
            "epoch [31/100], loss:0.1152\n",
            "epoch [32/100], loss:0.1127\n",
            "epoch [33/100], loss:0.1041\n",
            "epoch [34/100], loss:0.1047\n",
            "epoch [35/100], loss:0.0985\n",
            "epoch [36/100], loss:0.0978\n",
            "epoch [37/100], loss:0.1028\n",
            "epoch [38/100], loss:0.1038\n",
            "epoch [39/100], loss:0.1031\n",
            "epoch [40/100], loss:0.1030\n",
            "epoch [41/100], loss:0.1001\n",
            "epoch [42/100], loss:0.1131\n",
            "epoch [43/100], loss:0.1057\n",
            "epoch [44/100], loss:0.1116\n",
            "epoch [45/100], loss:0.0926\n",
            "epoch [46/100], loss:0.0966\n",
            "epoch [47/100], loss:0.1039\n",
            "epoch [48/100], loss:0.1063\n",
            "epoch [49/100], loss:0.1076\n",
            "epoch [50/100], loss:0.0995\n",
            "epoch [51/100], loss:0.1076\n",
            "epoch [52/100], loss:0.1018\n",
            "epoch [53/100], loss:0.0975\n",
            "epoch [54/100], loss:0.1048\n",
            "epoch [55/100], loss:0.0941\n",
            "epoch [56/100], loss:0.1022\n",
            "epoch [57/100], loss:0.0968\n",
            "epoch [58/100], loss:0.1045\n",
            "epoch [59/100], loss:0.1022\n",
            "epoch [60/100], loss:0.1039\n",
            "epoch [61/100], loss:0.1040\n",
            "epoch [62/100], loss:0.1063\n",
            "epoch [63/100], loss:0.0976\n",
            "epoch [64/100], loss:0.1059\n",
            "epoch [65/100], loss:0.0974\n",
            "epoch [66/100], loss:0.0982\n",
            "epoch [67/100], loss:0.1056\n",
            "epoch [68/100], loss:0.1003\n",
            "epoch [69/100], loss:0.0903\n",
            "epoch [70/100], loss:0.0987\n",
            "epoch [71/100], loss:0.0978\n",
            "epoch [72/100], loss:0.1079\n",
            "epoch [73/100], loss:0.1037\n",
            "epoch [74/100], loss:0.0954\n",
            "epoch [75/100], loss:0.0980\n",
            "epoch [76/100], loss:0.0940\n",
            "epoch [77/100], loss:0.0919\n",
            "epoch [78/100], loss:0.0955\n",
            "epoch [79/100], loss:0.0954\n",
            "epoch [80/100], loss:0.0922\n",
            "epoch [81/100], loss:0.0953\n",
            "epoch [82/100], loss:0.0972\n",
            "epoch [83/100], loss:0.0944\n",
            "epoch [84/100], loss:0.1009\n",
            "epoch [85/100], loss:0.1029\n",
            "epoch [86/100], loss:0.1011\n",
            "epoch [87/100], loss:0.0990\n",
            "epoch [88/100], loss:0.0891\n",
            "epoch [89/100], loss:0.1040\n",
            "epoch [90/100], loss:0.0980\n",
            "epoch [91/100], loss:0.0928\n",
            "epoch [92/100], loss:0.0951\n",
            "epoch [93/100], loss:0.0944\n",
            "epoch [94/100], loss:0.0903\n",
            "epoch [95/100], loss:0.0863\n",
            "epoch [96/100], loss:0.0898\n",
            "epoch [97/100], loss:0.0967\n",
            "epoch [98/100], loss:0.0918\n",
            "epoch [99/100], loss:0.0931\n",
            "epoch [100/100], loss:0.0957\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have noticed that as the number of epochs increases, the reconstructed images become clearer. However, the improvement is not consistent. The loss decreases initially, but then starts to fluctuate, sometimes increasing instead of continuously decreasing. This might be due as the model trains, it might start to overfit the training data, capturing noise rather than the underlying pattern, which can cause the loss to fluctuate."
      ],
      "metadata": {
        "id": "8uSXeI1AXZRU"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OU5Eo-Y8ZCRx"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}